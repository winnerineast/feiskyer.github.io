<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Cloud, Container, Kubernetes, SDN, Docker" />





  <link rel="alternate" href="/atom.xml" title="Feisky's Blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="Machine LearningWhat is machine learningMachine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”. It’s a computer program le">
<meta property="og:type" content="website">
<meta property="og:title" content="Feisky's Blog">
<meta property="og:url" content="http://feisky.xyz/ml/basic/index.html">
<meta property="og:site_name" content="Feisky's Blog">
<meta property="og:description" content="Machine LearningWhat is machine learningMachine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”. It’s a computer program le">
<meta property="og:updated_time" content="2016-11-29T14:09:53.004Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Feisky's Blog">
<meta name="twitter:description" content="Machine LearningWhat is machine learningMachine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”. It’s a computer program le">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://feisky.xyz/ml/basic/"/>


  <title>
  

  
     | Feisky's Blog
  
</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  


<!-- hexo-inject:begin --><!-- hexo-inject:end --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-69699206-1', 'auto');
  ga('send', 'pageview');
</script>









  
  
    
  

  <div class="container one-collumn sidebar-position-left  ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Feisky's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Notes about anything.</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-pages">
          <a href="/pages" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            笔记
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
      <h1 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h1><h2 id="What-is-machine-learning"><a href="#What-is-machine-learning" class="headerlink" title="What is machine learning"></a>What is machine learning</h2><p>Machine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”. It’s a computer program learning from experience $E$ with respect to some task $T$ and some performance measure $P$, if its performance on $T$ as measured by $P$, improves with $E$ : Tom Mitchell 1998</p>
<p>Machine learning tasks are typically classified into three broad categories:</p>
<ul>
<li>Supervised learning: The computer is presented with example inputs and their desired outputs, given by a “teacher”, and the goal is to learn a general rule that maps inputs to outputs.<ul>
<li>Regression - algorithms that predict continuous outputs</li>
<li>Categorization - algorithms that predict discrete outputs</li>
</ul>
</li>
<li>Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).</li>
<li>Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle), without a teacher explicitly telling it whether it has come close to its goal. Another example is learning to play a game by playing against an opponent</li>
</ul>
<p>There are a lot approaches to achieve machine learning:</p>
<ul>
<li>Decision tree learning</li>
<li>Association rule learning</li>
<li>Artificial neural networks</li>
<li>Deep Learning</li>
<li>Inductive logic programming</li>
<li>Support vector machines</li>
<li>Clustering</li>
<li>Bayesian networks</li>
<li>Reinforcement learning</li>
<li>Representation learning</li>
<li>Similarity and metric learning</li>
<li>Sparse dictionary learning</li>
<li>Genetic algorithms</li>
<li>Rule-based machine learning</li>
<li><a href="https://en.wikipedia.org/wiki/List_of_machine_learning_concepts" target="_blank" rel="external">More</a></li>
</ul>
<h2 id="A-Little-Probability"><a href="#A-Little-Probability" class="headerlink" title="A Little Probability"></a>A Little Probability</h2><p>Assume we have a random variable (RV) $X$. In the case where $X$ is a discrete random variable, the probability that $X$ takes some particular value $x$ is $p(X=x)=p_X(x)$ where $p_X$ is the <em>probability distribution function</em> of the RV $X$. For simplicity, we will usually drop the $X$ subscript when using the probability distribution function, i.e.</p>
<p>$p(x)=p_X(x)$ and $p(x,y)=p_{X,Y}(x,y)$.</p>
<p>Now assume we have a second RV, $Y$. The probability that $X$ and $Y$ together take some particular value $(x,y)$ is the <em>joint probability</em> $p_{X,Y}(x,y)=p(X=x, Y=y)$. The<br>joint probability can be defined in terms of conditional and marginal probabilities as follows:</p>
<ul>
<li><strong>product rule</strong> $p(X,Y) = p_Y\left(Y|X\right)p_X\left(X\right) = p(Y,X) = p_X\left(X|Y\right)p_Y\left(Y\right)$</li>
<li><strong>sum rule</strong> $p(X)=\sum_Yp\left(X,Y\right)$</li>
</ul>
<p>where the <em>conditional probability</em>, $p_X(X|Y)$ , is the probability distribution of X given that Y has taken some specific value and $p_X(x)$ is the <em>marginal probability</em>. Note<br>that the marginal probability is simply the probability distribution of $X$ as described above, but when considered as part of a larger set of RVs, as in $(X,Y)$ in this case, the<br>probability distribution of an isolated RV is referred to as the marginal probability. If $X$ and $Y$ are independent events, then<br>$p(X,Y)=p(X)p(Y)$. </p>
<p>If $X$ is a continuous RV, then the probability distribution gives way to a <em>probability density function</em>, $p_X(x)$. What’s the difference? In the case of a discrete RV, we think of $p_X(x)$<br>as being a finite value in $[0,1]$ representing the probability that $X=x$. In the case of a continuous RV, we can only think of the probability that $X$ is in some range $(a,b)$ defined by</p>
<p>$P(X\in (a,b)) = \int_a^b p_X(x)dx$</p>
<p>From this definition, one sees that the $P(X=a)=\int_a^a p_X(x)dx = 0$. The <em>product</em> rule remains the same rules for continuous RVs, however the <em>sum</em> rule becomes: </p>
<p><strong>sum rule</strong> $p(X) = \int p_{X,Y}(x,y) dy = \int p_X(X|Y=y) p_Y(y) dy = E_Y[p(X|Y)]$ </p>
<p>where $E_{\Phi}[X]$ is the <strong>expected value</strong> of $X$ under the distribution $\Phi$. Normally, $\Phi$ is the marginal distribution of $X$ so that $E_X[X] = \int x p_X(x) dx$ for the RV $X$. </p>
<p>The following definition of a <strong>compound distribution</strong> will also be useful. Let $t$ be a RV with distribution $F$ paramaterized by $\mathbf{w}$ and let $\mathbf{w}$ be a RV distributed by $G$<br>parameterized by $\mathbf{t}$, then the compound distribution $H$ parameterized by $\mathbf{t}$ for the random variable $t$ is defined by:</p>
<p>$p_H(t|\mathbf{t}) = \int_{\mathbf{w}} P_F(t|\mathbf{w}) P_G(\mathbf{w}|\mathbf{t})d\mathbf{w}$ </p>
<h2 id="Bayesian-Modeling"><a href="#Bayesian-Modeling" class="headerlink" title="Bayesian Modeling"></a>Bayesian Modeling</h2><p>Using the probability rules above, it is possible to obtain the following, known as <em>Bayes’ theorem</em>, </p>
<p>$p(Y|X) = \frac{p\left(X|Y\right)p\left(Y\right)}{p\left(X\right)}$</p>
<p>Bayes’ theorem will appear repeatadly in the discussion of machine learning.<br>Not surprisingly, Bayes’ theorem plays a fundamental role in Bayesian modelling. Assume, that we model some process where the model has free parameters contained in the vector $\mathbf{w}$. Now assume that we have some notion of the probability distribution of these parameters, $p(\mathbf{w})$, called the <em>prior</em>. That is, we assume that <strong>any</strong> set of values from some space (e.g. the real numbers) is a possible best choice for $\mathbf{w}$ with some probability $p(\mathbf{w})$. Finally, assume that we observe a set of data, $\mathbf{D}$, for the output we are attempting to predict with our model. Our objective is to find the <em>best</em> set of parameters $\mathbf{w}$ given the observed data. How we choose the <em>best</em> set is the challenge and is where Bayesian modeling departs from frequentist modeling. In the Bayesian approach we attempt to maximize the <em>the probability of the parameters given the data</em>, $p(\mathbf{w}|D)$, known as the <em>posterior</em>. Using Bayes’ theorem we can express the <em>posterior</em> as </p>
<p>$p(\mathbf{w}|D) = \frac{p(D|\mathbf{w})p(\mathbf{w})}{p(D)}$ </p>
<p>In order to apply a fully Bayesian approach, we must formulate models for both the <em>prior</em>, $p(\mathbf{w})$, and the <em>likelihood function</em>, $p(D|\mathbf{w})$. Given these models and a set of data we can compute appropriate values for our free parameter vector $\mathbf{w}$ by maximizing<br>$p(\mathbf{w}|D) \propto p(D|\mathbf{w})p(\mathbf{w})$. How does this differ from frequentist modeling?<br>The frequentist approach, or <em>maximum likelihood</em> approach, ignores the formulation of a <em>prior</em>, and goes directly to maximizing the likelihood function to find the model parameters. Thus, the frequentist approach can be described as <em>maximizing the probability of the data given the parameters</em>. Under certain conditions the results of Bayesian and frequentist modeling will conincide, but this is not true in general. </p>
<p>One could obtain a point estimate for $\mathbf{w}$ by maximizing the <em>posterior probability</em> model, but this not typical. Instead a <em>predictive distribution</em> of the value of the target variable, $t$, is formed based on the compound distribution definition provided above. Taking the mean of this distribution provides a point estimate of $t$ while distribution itself provides a measure of the uncertainty in the estimate, say by considering the standard deviation.</p>
<p>Note: A simple example illustrating the difference can found (here)[<a href="http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html" target="_blank" rel="external">http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html</a>].</p>
<h2 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h2><p>A maximum likelihood approach does not attempt to formulate models for the parameter <em>priors</em>, $p(\mathbf{w})$, or the parameter <em>posterior probabilities</em>, $p(\mathbf{w}|D)$. Rather it views the data, $D$, as fixed and<br>attempts to determine the model parameters, $\mathbf{w}$, by maximizing the likelihood function. As we will frequently use this approach, it is useful to understand the likelihood function. </p>
<p>We assume we have specified a probability density model, $p_{\mathbf{w}}(d)$ for the observed data elements, ${d \in D}$ that is parameterized by $\mathbf{w}$, i.e. $p$ is a parametric model for the distribution of $D$. As<br>an example, if $D$ ahs a normal distribution with mean $\mu$ and variance $\sigma^2$, then </p>
<p>$\mathbf{w} = (\mu, \sigma^2)$ </p>
<p>and </p>
<p>$p_{\mathbf{w}}(d) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-(d-\mu)^2/2\sigma^2}$ </p>
<p>The likelihood function, regardless of our choice of model $p$, is defined by </p>
<p>$L(\mathbf{w}; D) = \prod_{i=1}^N p_{\mathbf{w}}(d_i)$ </p>
<p>where $N$ is the number of elements in $D$. Thus the likelihood function is simply the product of the probability of all the individual data points, $d_i \in D$, under the probability model, $p_{\mathbf{w}}$. Note that this<br>definition implicitly assumes these data points are independent events. </p>
<p>Out of mathematical convenience, we will most often work with the <em>log-likelihood</em> function (which turns the product into a sum by properties of the log function), i.e. the logarithm of $L(\mathbf{w}; D)$, defined as </p>
<script type="math/tex; mode=display">l(\mathbf{w};D) = \sum_{i=1}^N l(\mathbf{w};d_i) = \sum_{i=1}^N \log p_{\mathbf{w}}(d_i)</script><p>where we recall that $\log(ab) = \log(a) + \log(b)$. </p>
<p>The method of maximum likelihood chooses the value $\mathbf{w} = \widehat{\mathbf{w}}$ that maximizes the <em>log-likelihood</em> function. We will also often work with an <strong>error function</strong>, $E(\mathbf{w})$, defined as the<br>negative of the log-likelihood function </p>
<script type="math/tex; mode=display">E(\mathbf{w}) = -l(\mathbf{w};D)</script><p>where we note $-\log(a) = \log(1/a)$.</p>

    
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/qrcode.jpg"
               alt="Feisky" />
          <p class="site-author-name" itemprop="name">Feisky</p>
          <p class="site-description motion-element" itemprop="description">Notes about anything.</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">90</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/feiskyer" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/feisky" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/371069890" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.cnblogs.com/feisky/" target="_blank" title="博客园">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  博客园
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Machine-Learning"><span class="nav-number">1.</span> <span class="nav-text">Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#What-is-machine-learning"><span class="nav-number">1.1.</span> <span class="nav-text">What is machine learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#A-Little-Probability"><span class="nav-number">1.2.</span> <span class="nav-text">A Little Probability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bayesian-Modeling"><span class="nav-number">1.3.</span> <span class="nav-text">Bayesian Modeling</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Maximum-Likelihood"><span class="nav-number">1.4.</span> <span class="nav-text">Maximum Likelihood</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Feisky</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.2"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


  


</body>
</html>
