<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Feisky&#39;s Blog</title>
  <subtitle>Notes about anything.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://feisky.xyz/"/>
  <updated>2016-12-15T00:14:54.373Z</updated>
  <id>http://feisky.xyz/</id>
  
  <author>
    <name>Feisky</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kubernetes v1.5.0 release</title>
    <link href="http://feisky.xyz/2016/12/13/Kubernetes-v1-5-0-release/"/>
    <id>http://feisky.xyz/2016/12/13/Kubernetes-v1-5-0-release/</id>
    <published>2016-12-13T03:51:29.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Update on 2016.12.14:</strong></p>
<p>Due to a serious security problem, kubernetes v1.5.0 is not recommanded. Kubernetes v1.5.1 has just released, so we should upgrade to v1.5.1 directly.</p>
<blockquote>
<p>The <code>--anonymous-auth=</code> flag in v1.5.0 is true by default (which may result in any users being able to access kubernetes API), but v1.5.1 turns it to false.</p>
</blockquote>
<h2 id="Kubernetes-v1-5-0"><a href="#Kubernetes-v1-5-0" class="headerlink" title="Kubernetes v1.5.0"></a>Kubernetes v1.5.0</h2><ul>
<li>StatefulSets (ex-PetSets)<ul>
<li>StatefulSets are beta now (fixes and stabilization)</li>
</ul>
</li>
<li>Improved Federation Support<ul>
<li>New command: <code>kubefed</code></li>
<li>DaemonSets</li>
<li>Deployments</li>
<li>ConfigMaps</li>
</ul>
</li>
<li>Simplified Cluster Deployment<ul>
<li>Improvements to <code>kubeadm</code></li>
<li>HA Setup for Master</li>
</ul>
</li>
<li>Node Robustness and Extensibility<ul>
<li>Windows Server Container support</li>
<li>CRI for pluggable container runtimes</li>
<li><code>kubelet</code> API supports authentication and authorization</li>
</ul>
</li>
</ul>
<h2 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h2><p>Features for this release were tracked via the use of the <a href="https://github.com/kubernetes/features" target="_blank" rel="external">kubernetes/features</a> issues repo.  Each Feature issue is owned by a Special Interest Group from <a href="https://github.com/kubernetes/community" target="_blank" rel="external">kubernetes/community</a></p>
<ul>
<li><strong>API Machinery</strong><ul>
<li>[beta] <code>kube-apiserver</code> support for the OpenAPI spec is moving from alpha to beta. The first <a href="https://github.com/kubernetes-incubator/client-python" target="_blank" rel="external">non-go client</a> is based on it (<a href="https://github.com/kubernetes/features/issues/53" target="_blank" rel="external">kubernetes/features#53</a>)</li>
</ul>
</li>
<li><strong>Apps</strong><ul>
<li>[stable] When replica sets cannot create pods, they will now report detail via the API about the underlying reason (<a href="https://github.com/kubernetes/features/issues/120" target="_blank" rel="external">kubernetes/features#120</a>)</li>
<li>[stable] <code>kubectl apply</code> is now able to delete resources you no longer need with <code>--prune</code> (<a href="https://github.com/kubernetes/features/issues/128" target="_blank" rel="external">kubernetes/features#128</a>)</li>
<li>[beta] Deployments that cannot make progress in rolling out the newest version will now indicate via the API they are blocked (<a href="http://kubernetes.io/docs/user-guide/deployments/#failed-deployment" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/122" target="_blank" rel="external">kubernetes/features#122</a>)</li>
<li>[beta] StatefulSets allow workloads that require persistent identity or per-instance storage to be created and managed on Kubernetes. (<a href="http://kubernetes.io/docs/concepts/abstractions/controllers/statefulsets/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/137" target="_blank" rel="external">kubernetes/features#137</a>)</li>
<li>[beta] In order to preserve safety guarantees the cluster no longer force deletes pods on un-responsive nodes and users are now warned if they try to force delete pods via the CLI. (<a href="http://kubernetes.io/docs/tasks/manage-stateful-set/scale-stateful-set/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/119" target="_blank" rel="external">kubernetes/features#119</a>)</li>
</ul>
</li>
<li><strong>Auth</strong><ul>
<li>[alpha] Further polishing of the Role-based access control alpha API including a default set of cluster roles. (<a href="http://kubernetes.io/docs/admin/authorization/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/2" target="_blank" rel="external">kubernetes/features#2</a>)</li>
<li>[beta] Added ability to authenticate/authorize access to the Kubelet API (<a href="http://kubernetes.io/docs/admin/kubelet-authentication-authorization/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/89" target="_blank" rel="external">kubernetes/features#89</a>)</li>
</ul>
</li>
<li><strong>AWS</strong><ul>
<li>[stable] Roles should appear in kubectl get nodes (<a href="https://github.com/kubernetes/features/issues/113" target="_blank" rel="external">kubernetes/features#113</a>)</li>
</ul>
</li>
<li><strong>Cluster Lifecycle</strong><ul>
<li>[alpha] Improved UX and usability for the kubeadm binary that makes it easy to get a new cluster running. (<a href="http://kubernetes.io/docs/getting-started-guides/kubeadm/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/11" target="_blank" rel="external">kubernetes/features#11</a>)</li>
</ul>
</li>
<li><strong>Cluster Ops</strong><ul>
<li>[alpha] Added ability to create/remove clusters w/highly available (replicated) masters on GCE using kube-up/kube-down scripts. (<a href="http://kubernetes.io/docs/admin/ha-master-gce/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/48" target="_blank" rel="external">kubernetes/features#48</a>)</li>
</ul>
</li>
<li><strong>Federation</strong><ul>
<li>[alpha] Support for ConfigMaps in federation. (<a href="http://kubernetes.io/docs/user-guide/federation/configmap/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/105" target="_blank" rel="external">kubernetes/features#105</a>)</li>
<li>[alpha] Alpha level support for DaemonSets in federation. (<a href="http://kubernetes.io/docs/user-guide/federation/daemonsets/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/101" target="_blank" rel="external">kubernetes/features#101</a>)</li>
<li>[alpha] Alpha level support for Deployments in federation. (<a href="http://kubernetes.io/docs/user-guide/federation/deployment/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/100" target="_blank" rel="external">kubernetes/features#100</a>)</li>
<li>[alpha] Cluster federation: Added support for DeleteOptions.OrphanDependents for federation resources. (<a href="http://kubernetes.io/docs/user-guide/federation/#cascading-deletion" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/99" target="_blank" rel="external">kubernetes/features#99</a>)</li>
<li>[alpha] Introducing <code>kubefed</code>, a new command line tool to simplify federation control plane kubernetes.io/docs/admin/federation/kubefed/)) (<a href="https://github.com/kubernetes/features/issues/97" target="_blank" rel="external">kubernetes/features#97</a>)</li>
</ul>
</li>
<li><strong>Network</strong><ul>
<li>[stable] Services can reference another service by DNS name, rather than being hosted in pods (<a href="https://github.com/kubernetes/features/issues/33" target="_blank" rel="external">kubernetes/features#33</a>)</li>
<li>[beta] Opt in source ip preservation for Services with Type NodePort or LoadBalancer (<a href="http://kubernetes.io/docs/tutorials/services/source-ip/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/27" target="_blank" rel="external">kubernetes/features#27</a>)</li>
<li>[stable] Enable DNS Horizontal Autoscaling with beta ConfigMap parameters support (<a href="http://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/" target="_blank" rel="external">docs</a>)</li>
</ul>
</li>
<li><strong>Node</strong><ul>
<li>[alpha] Added ability to preserve access to host userns when userns remapping is enabled in container runtime (<a href="https://github.com/kubernetes/features/issues/127" target="_blank" rel="external">kubernetes/features#127</a>)</li>
<li>[alpha] Introducing the v1alpha1 CRI API to allow pluggable container runtimes; an experimental docker-CRI integration is ready for testing and feedback. (<a href="https://github.com/kubernetes/community/blob/master/contributors/devel/container-runtime-interface.md" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/54" target="_blank" rel="external">kubernetes/features#54</a>)</li>
<li>[alpha] Kubelet launches container in a per pod cgroup hiearchy based on quality of service tier (<a href="https://github.com/kubernetes/features/issues/126" target="_blank" rel="external">kubernetes/features#126</a>)</li>
<li>[beta] Kubelet integrates with memcg notification API to detect when a hard eviction threshold is crossed (<a href="https://github.com/kubernetes/features/issues/125" target="_blank" rel="external">kubernetes/features#125</a>)</li>
<li>[beta] Introducing the beta version containerized node conformance test gcr.io/google_containers/node-test:0.2 for users to verify node setup. (<a href="http://kubernetes.io/docs/admin/node-conformance/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/84" target="_blank" rel="external">kubernetes/features#84</a>)</li>
</ul>
</li>
<li><strong>Scheduling</strong><ul>
<li>[alpha] Added support for accounting opaque integer resources. (<a href="http://kubernetes.io/docs/user-guide/compute-resources/#opaque-integer-resources-alpha-feature" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/76" target="_blank" rel="external">kubernetes/features#76</a>)</li>
<li>[beta] PodDisruptionBudget has been promoted to beta, can be used to safely drain nodes while respecting application SLO’s (<a href="http://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/85" target="_blank" rel="external">kubernetes/features#85</a>)</li>
</ul>
</li>
<li><strong>UI</strong><ul>
<li>[stable] Dashboard UI now shows all user facing objects and their resource usage. (<a href="http://kubernetes.io/docs/user-guide/ui/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/136" target="_blank" rel="external">kubernetes/features#136</a>)</li>
</ul>
</li>
<li><strong>Windows</strong><ul>
<li>[alpha] Added support for Windows Server 2016 nodes and scheduling Windows Server Containers (<a href="http://kubernetes.io/docs/getting-started-guides/windows/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/features/issues/116" target="_blank" rel="external">kubernetes/features#116</a>)</li>
</ul>
</li>
</ul>
<h2 id="Known-Issues"><a href="#Known-Issues" class="headerlink" title="Known Issues"></a>Known Issues</h2><p>Populated via <a href="https://github.com/kubernetes/kubernetes/issues/37134" target="_blank" rel="external">v1.5.0 known issues / FAQ accumulator</a></p>
<ul>
<li>CRI <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/container-runtime-interface.md#kubernetes-v15-release-cri-v1alpha1" target="_blank" rel="external">known issues and<br>limitations</a></li>
<li>getDeviceNameFromMount() function doesn’t return the volume path correctly when the volume path contains spaces <a href="https://github.com/kubernetes/kubernetes/issues/37712" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/37712" target="_blank" rel="external">#37712</a></a></li>
<li>Federation alpha features do not have feature gates defined and<br>are hence enabled by default. This will be fixed in a future release.<br><a href="https://github.com/kubernetes/kubernetes/issues/38593" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/38593" target="_blank" rel="external">#38593</a></a></li>
<li>Federation control plane can be upgraded by updating the image<br>fields in the <code>Deployment</code> specs of the control plane components.<br>However, federation control plane upgrades were not tested in this<br>release <a href="https://github.com/kubernetes/kubernetes/issues/38537" target="_blank" rel="external">38537</a></li>
</ul>
<h2 id="Notable-Changes-to-Existing-Behavior"><a href="#Notable-Changes-to-Existing-Behavior" class="headerlink" title="Notable Changes to Existing Behavior"></a>Notable Changes to Existing Behavior</h2><ul>
<li>Node controller no longer force-deletes pods from the api-server. (<a href="https://github.com/kubernetes/kubernetes/pull/35235" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/35235" target="_blank" rel="external">#35235</a></a>, <a href="https://github.com/foxish" target="_blank" rel="external"><a href="https://github.com/foxish" target="_blank" rel="external">@foxish</a></a>)<ul>
<li>For StatefulSet (previously PetSet), this change means creation of<br>replacement pods is blocked until old pods are definitely not running<br>(indicated either by the kubelet returning from partitioned state,<br>deletion of the Node object, deletion of the instance in the cloud provider,<br>or force deletion of the pod from the api-server).<br>This helps prevent “split brain” scenarios in clustered applications by<br>ensuring that unreachable pods will not be presumed dead unless some<br>“fencing” operation has provided one of the above indications.</li>
<li>For all other existing controllers except StatefulSet, this has no effect on<br>the ability of the controller to replace pods because the controllers do not<br>reuse pod names (they use generate-name).</li>
<li>User-written controllers that reuse names of pod objects should evaluate this change.</li>
<li>When deleting an object with <code>kubectl delete ... --grace-period=0</code>, the client will<br>begin a graceful deletion and wait until the resource is fully deleted.  To force<br>deletion immediately, use the <code>--force</code> flag. This prevents users from accidentally<br>allowing two Stateful Set pods to share the same persistent volume which could lead to data<br>corruption <a href="https://github.com/kubernetes/kubernetes/pull/37263" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/37263" target="_blank" rel="external">#37263</a></a></li>
</ul>
</li>
</ul>
<ul>
<li><p>Allow anonymous API server access, decorate authenticated users with system:authenticated group (<a href="https://github.com/kubernetes/kubernetes/pull/32386" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/32386" target="_blank" rel="external">#32386</a></a>, <a href="https://github.com/liggitt" target="_blank" rel="external"><a href="https://github.com/liggitt" target="_blank" rel="external">@liggitt</a></a>)</p>
<ul>
<li>kube-apiserver learned the ‘—anonymous-auth’ flag, which defaults to true. When enabled, requests to the secure port that are not rejected by other configured authentication methods are treated as anonymous requests, and given a username of ‘system:anonymous’ and a group of ‘system:unauthenticated’.</li>
<li>Authenticated users are decorated with a ‘system:authenticated’ group.</li>
<li>NOTE: anonymous access is enabled by default. If you rely on authentication alone to authorize access, change to use an authorization mode other than AlwaysAllow, or or set ‘—anonymous-auth=false’.</li>
</ul>
</li>
<li><p>kubectl get -o jsonpath=… will now throw an error if the path is to a field not present in the json, even if the path is for a field valid for the type.  This is a change from the pre-1.5 behavior, which would return the default value for some fields even if they were not present in the json. (<a href="https://github.com/kubernetes/kubernetes/issues/37991" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/37991" target="_blank" rel="external">#37991</a></a>, <a href="http://github.com/pwittrock" target="_blank" rel="external"><a href="https://github.com/pwittrock" target="_blank" rel="external">@pwittrock</a></a>)</p>
</li>
<li><p>The strategicmerge patchMergeKey for VolumeMounts was changed from “name” to “mountPath”.  This was necessary because the name field refers to the name of the Volume, and is not a unique key for the VolumeMount.  Multiple VolumeMounts will have the same Volume name if mounting the same volume more than once.  The “mountPath” is verified to be unique and can act as the mergekey.  (<a href="https://github.coma/kubernetes/kubernetes/pull/35071" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/35071" target="_blank" rel="external">#35071</a></a>, <a href="http://github.com/pwittrock" target="_blank" rel="external"><a href="https://github.com/pwittrock" target="_blank" rel="external">@pwittrock</a></a>)</p>
</li>
</ul>
<h2 id="Deprecations"><a href="#Deprecations" class="headerlink" title="Deprecations"></a>Deprecations</h2><ul>
<li>extensions/v1beta1.Jobs is deprecated, use batch/v1.Job instead (<a href="https://github.com/kubernetes/kubernetes/pull/36355" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/36355" target="_blank" rel="external">#36355</a></a>, <a href="https://github.com/soltysh" target="_blank" rel="external"><a href="https://github.com/soltysh" target="_blank" rel="external">@soltysh</a></a>)</li>
<li>The kubelet —reconcile-cdir flag is deprecated because it has no function anymore. (<a href="https://github.com/kubernetes/kubernetes/pull/35523" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/35523" target="_blank" rel="external">#35523</a></a>, <a href="https://github.com/luxas" target="_blank" rel="external"><a href="https://github.com/luxas" target="_blank" rel="external">@luxas</a></a>)</li>
<li>Notice of deprecation for recycler <a href="https://github.com/kubernetes/kubernetes/pull/36760" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/36760" target="_blank" rel="external">#36760</a></a></li>
</ul>
<h2 id="Action-Required-Before-Upgrading"><a href="#Action-Required-Before-Upgrading" class="headerlink" title="Action Required Before Upgrading"></a>Action Required Before Upgrading</h2><ul>
<li>batch/v2alpha1.ScheduledJob has been renamed, use batch/v2alpha1.CronJob instead (<a href="https://github.com/kubernetes/kubernetes/pull/36021" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/36021" target="_blank" rel="external">#36021</a></a>, <a href="https://github.com/soltysh" target="_blank" rel="external"><a href="https://github.com/soltysh" target="_blank" rel="external">@soltysh</a></a>)</li>
<li>PetSet has been renamed to StatefulSet.<br>If you have existing PetSets, <strong>you must perform extra migration steps</strong> both<br>before and after upgrading to convert them to StatefulSets. (<a href="http://kubernetes.io/docs/tasks/manage-stateful-set/upgrade-pet-set-to-stateful-set/" target="_blank" rel="external">docs</a>) (<a href="https://github.com/kubernetes/kubernetes/pull/35663" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/35663" target="_blank" rel="external">#35663</a></a>, <a href="https://github.com/janetkuo" target="_blank" rel="external"><a href="https://github.com/janetkuo" target="_blank" rel="external">@janetkuo</a></a>)</li>
<li>If you are upgrading your Cluster Federation components from v1.4.x, please update your <code>federation-apiserver</code> and <code>federation-controller-manager</code> manifests to the new version (<a href="https://github.com/kubernetes/kubernetes/pull/30601" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/30601" target="_blank" rel="external">#30601</a></a>, <a href="https://github.com/madhusudancs" target="_blank" rel="external"><a href="https://github.com/madhusudancs" target="_blank" rel="external">@madhusudancs</a></a>)</li>
<li>The deprecated kubelet —configure-cbr0 flag has been removed, and with that the “classic” networking mode as well.  If you depend on this mode, please investigate whether the other network plugins <code>kubenet</code> or <code>cni</code> meet your needs. (<a href="https://github.com/kubernetes/kubernetes/pull/34906" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/34906" target="_blank" rel="external">#34906</a></a>, <a href="https://github.com/luxas" target="_blank" rel="external"><a href="https://github.com/luxas" target="_blank" rel="external">@luxas</a></a>)</li>
<li>New client-go structure, refer to kubernetes/client-go for versioning policy (<a href="https://github.com/kubernetes/kubernetes/pull/34989" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/34989" target="_blank" rel="external">#34989</a></a>, <a href="https://github.com/caesarxuchao" target="_blank" rel="external"><a href="https://github.com/caesarxuchao" target="_blank" rel="external">@caesarxuchao</a></a>)</li>
<li>The deprecated kube-scheduler —bind-pods-qps and —bind-pods burst flags have been removed, use —kube-api-qps and —kube-api-burst instead (<a href="https://github.com/kubernetes/kubernetes/pull/34471" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/34471" target="_blank" rel="external">#34471</a></a>, <a href="https://github.com/timothysc" target="_blank" rel="external"><a href="https://github.com/timothysc" target="_blank" rel="external">@timothysc</a></a>)</li>
<li>If you used the <a href="http://kubernetes.io/docs/admin/disruptions/" target="_blank" rel="external">PodDisruptionBudget</a> feature in 1.4 (i.e. created <code>PodDisruptionBudget</code> objects), then <strong>BEFORE</strong>  upgrading from 1.4 to 1.5, you must delete all <code>PodDisruptionBudget</code> objects (<code>policy/v1alpha1/PodDisruptionBudget</code>) that you have created. It is not possible to delete these objects after you upgrade, and their presence will prevent you from using the beta PodDisruptionBudget feature in 1.5 (which uses <code>policy/v1beta1/PodDisruptionBudget</code>). If you have already upgraded, you will need to downgrade the master to 1.4 to delete the <code>policy/v1alpha1/PodDisruptionBudget</code> objects.</li>
</ul>
<h2 id="External-Dependency-Version-Information"><a href="#External-Dependency-Version-Information" class="headerlink" title="External Dependency Version Information"></a>External Dependency Version Information</h2><p>Continuous integration builds have used the following versions of external dependencies, however, this is not a strong recommendation and users should consult an appropriate installation or upgrade guide before deciding what versions of etcd, docker or rkt to use.</p>
<ul>
<li>Docker versions 1.10.3 - 1.12.3<ul>
<li>Docker version 1.11.2 known issues<ul>
<li>Kernel crash with Aufs storage driver on Debian Jessie (<a href="https://github.com/kubernetes/kubernetes/issues/27885" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/27885" target="_blank" rel="external">#27885</a></a>)<br>which can be identified by the <a href="http://kubernetes.io/docs/admin/node-problem/" target="_blank" rel="external">node problem detector</a></li>
<li>Leaked File descriptors (<a href="https://github.com/docker/containerd/issues/275" target="_blank" rel="external">#275</a>)</li>
<li>Additional memory overhead per container (<a href="https://github.com/docker/docker/issues/21737" target="_blank" rel="external"><a href="https://github.com/kubernetes/kubernetes/pull/21737" target="_blank" rel="external">#21737</a></a>)</li>
</ul>
</li>
<li>Docker version 1.12.1 <a href="https://github.com/kubernetes/kubernetes/issues/28698" target="_blank" rel="external">has been validated</a> through the Kubernetes docker automated validation framework as has Docker version 1.12.3</li>
<li>Docker 1.10.3 contains <a href="https://github.com/docker/docker/compare/v1.10.3...runcom:docker-1.10.3-stable" target="_blank" rel="external">backports provided by RedHat</a> for known issues</li>
<li>Docker versions as old as may 1.9.1 work with <a href="CHANGELOG.md#191">known issues</a> but this is not guaranteed</li>
</ul>
</li>
<li>rkt version 1.21.0<ul>
<li>known issues with the rkt runtime are <a href="http://kubernetes.io/docs/getting-started-guides/rkt/notes/" target="_blank" rel="external">listed here</a></li>
</ul>
</li>
<li><p>etcd version 2.2.1</p>
<ul>
<li>etcd version 3.0.14 <a href="https://k8s-gubernator.appspot.com/builds/kubernetes-jenkins/logs/ci-kubernetes-e2e-gce-etcd3/" target="_blank" rel="external">has also been validated</a> but does require <a href="https://coreos.com/blog/migrating-applications-etcd-v3.html" target="_blank" rel="external">specific configuration steps</a></li>
</ul>
<p><a href="https://docs.k8s.io" target="_blank" rel="external">Documentation</a> &amp; <a href="https://releases.k8s.io/release-1.5/examples" target="_blank" rel="external">Examples</a></p>
<h2 id="Downloads-for-v1-5-0"><a href="#Downloads-for-v1-5-0" class="headerlink" title="Downloads for v1.5.0"></a>Downloads for v1.5.0</h2></li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>filename</th>
<th>sha256 hash</th>
</tr>
</thead>
<tbody>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes.tar.gz" target="_blank" rel="external">kubernetes.tar.gz</a></td>
<td><code>52b7df98ea05fb3ebbababf1ccb7f6d4e6f4cad00b8d09350f270aa7e3ad7e85</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-src.tar.gz" target="_blank" rel="external">kubernetes-src.tar.gz</a></td>
<td><code>fbefb2544667f96045c346cee595b0f315282dfdbd41a8f2d5ccc74054a4078e</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Client-Binaries"><a href="#Client-Binaries" class="headerlink" title="Client Binaries"></a>Client Binaries</h3><div class="table-container">
<table>
<thead>
<tr>
<th>filename</th>
<th>sha256 hash</th>
</tr>
</thead>
<tbody>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-darwin-386.tar.gz" target="_blank" rel="external">kubernetes-client-darwin-386.tar.gz</a></td>
<td><code>27d71bb6b16a26387ee30272bd4ee5758deccafafdc91b38f3d0dc19a34e129e</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-darwin-amd64.tar.gz" target="_blank" rel="external">kubernetes-client-darwin-amd64.tar.gz</a></td>
<td><code>5fa8550235919568d7d839b19de00e9bdd72a97cfde21dbdbe07fefd6d6290dc</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-linux-386.tar.gz" target="_blank" rel="external">kubernetes-client-linux-386.tar.gz</a></td>
<td><code>032a17701c014b8bbbb83c7da1046d8992a41031628cf7e1959a94378f5f195b</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-linux-amd64.tar.gz" target="_blank" rel="external">kubernetes-client-linux-amd64.tar.gz</a></td>
<td><code>afae4fadb7bbb1532967f88fef1de6458abda17219f634cc2c41608fd83ae7f6</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-linux-arm64.tar.gz" target="_blank" rel="external">kubernetes-client-linux-arm64.tar.gz</a></td>
<td><code>acca7607dae678a0165b7e10685e0eff0d418beebe7c25eaffe18c85717b5cc4</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-linux-arm.tar.gz" target="_blank" rel="external">kubernetes-client-linux-arm.tar.gz</a></td>
<td><code>fbc182b6d9ae476c7c509486d773074fd1007032886a8177735e08010c43f89d</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-windows-386.tar.gz" target="_blank" rel="external">kubernetes-client-windows-386.tar.gz</a></td>
<td><code>a8ddea329bc8d57267294464c163d8c2f7837f6353f8c685271864ed8b8bc54d</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-client-windows-amd64.tar.gz" target="_blank" rel="external">kubernetes-client-windows-amd64.tar.gz</a></td>
<td><code>bc3a76f1414fa1f4b2fb92732de2100d346edb7b870ed5414ea062bb401a8ebd</code></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Server-Binaries"><a href="#Server-Binaries" class="headerlink" title="Server Binaries"></a>Server Binaries</h3><div class="table-container">
<table>
<thead>
<tr>
<th>filename</th>
<th>sha256 hash</th>
</tr>
</thead>
<tbody>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-server-linux-amd64.tar.gz" target="_blank" rel="external">kubernetes-server-linux-amd64.tar.gz</a></td>
<td><code>b9c122d709c0556c1e19d31d98bf26ee530f91c0119f4454fb930cef5a0c1aa7</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-server-linux-arm64.tar.gz" target="_blank" rel="external">kubernetes-server-linux-arm64.tar.gz</a></td>
<td><code>3bbba5c8dedc47db8f9ebdfac5468398cce2470617de9d550affef9702b724c9</code></td>
</tr>
<tr>
<td>  <a href="https://dl.k8s.io/v1.5.0/kubernetes-server-linux-arm.tar.gz" target="_blank" rel="external">kubernetes-server-linux-arm.tar.gz</a></td>
<td><code>3ff9ccdd641690fd1c8878408cd369beca1f9f8b212198e251862d40cf2dadc0</code></td>
</tr>
</tbody>
</table>
</div>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Update on 2016.12.14:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Due to a serious security problem, kubernetes v1.5.0 is not recommanded. Kubernetes v1.5.1 
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://feisky.xyz/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Weekly reading list</title>
    <link href="http://feisky.xyz/2016/12/08/Weekly-reading-list/"/>
    <id>http://feisky.xyz/2016/12/08/Weekly-reading-list/</id>
    <published>2016-12-08T06:00:22.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Docker收购Infinit-PDF"><a href="#Docker收购Infinit-PDF" class="headerlink" title="Docker收购Infinit PDF"></a><a href="https://blog.docker.com/2016/12/docker-acquires-infinit/" target="_blank" rel="external">Docker收购Infinit</a> <a href="/assets/infinit.pdf">PDF</a></h1><p><a href="https://infinit.sh/" target="_blank" rel="external">Infinit</a>为容器提供了分布式存储，其特点包括</p>
<ul>
<li>基于软件：可以部署在任何硬件之上，从遗留设备到消费级实体机、虚拟机，甚至容器。</li>
<li>可编程：开发者可以轻松地完成多个存储基础设施的自动化创建和部署，并且每个都能借助基于策略的能力进行自定义，适配上层应用的需求。</li>
<li>可伸缩：通过依靠一个去中心化的架构（即点对点），Infinit没有使用leader/follower模型，因而不会有瓶颈和单点失效的问题。</li>
<li>自愈合：Infinit的再平衡策略能让系统适应各种故障，包括拜占庭将军问题。</li>
<li>多用途：Infinit平台提供了块、对象和文件存储的接口：NFS、SMB、AWS S3、OpenStack Swift、iSCSI和FUSE等等。</li>
</ul>
<p><img src="/images/14811775178610.png" alt=""></p>
<p>基本原理：</p>
<p>• Federate all nodes in an overlay network for lookup and routing.<br>• Store data as blocks in a distributed hashtable (key-value store) with a per-block consensus.<br>• Use cryptographic access control to dispense from any leader.<br>• Use symmetrical operations to ensure resilience and flexibility.</p>
<p><img src="/images/14811780770073.jpg" alt=""></p>
<p><img src="/images/14811782445452.jpg" alt=""></p>
<p>Infinit以volume的形式挂载到docker容器中：</p>
<p><img src="/images/14811779192673.jpg" alt=""></p>
<h2 id="Docker-Alibaba——超大规模Docker化的实战经验"><a href="#Docker-Alibaba——超大规模Docker化的实战经验" class="headerlink" title="Docker@Alibaba——超大规模Docker化的实战经验"></a><a href="https://yq.aliyun.com/articles/64256" target="_blank" rel="external">Docker@Alibaba——超大规模Docker化的实战经验</a></h2><ul>
<li>AliDocker，并非阿里云，主要是阿里内部业务在用</li>
<li>Swarm改造支持单swarm实例health nodes 2w+<ul>
<li>优化连接管理、最小化锁粒度、修改diff算法减少node刷新时的开销、减少连接线程</li>
</ul>
</li>
<li>Docker Engine增强<ul>
<li>磁盘配额、固定IP、Hooks、解决hyperd重启容器销毁问题等</li>
</ul>
</li>
<li>镜像分发：流式分发、镜像分批预热、P2P等</li>
<li>swarm-proxy HA</li>
</ul>
<p><img src="/images/14811788194621.jpg" alt="">7</p>
<h2 id="微服务在微信后台的架构实践"><a href="#微服务在微信后台的架构实践" class="headerlink" title="微服务在微信后台的架构实践"></a><a href="http://ppt.geekbang.org/slide/show/607" target="_blank" rel="external">微服务在微信后台的架构实践</a></h2><ul>
<li>多地自治，园区互备：城市间RTT 30ms-400ms，园区间小于2ms</li>
<li>RPC：protobuf/libco</li>
<li>调度：Yard，双层调度器（Mesos+Yard）</li>
<li>过载保护：轻重分离、队列式、组合命令式</li>
</ul>
<p><img src="/images/14811817178100.jpg" alt=""></p>
<ul>
<li>数据存储：PaxosStore，同步复制、多主多写</li>
</ul>
<p><img src="/images/14811818656014.jpg" alt=""></p>
<h2 id="Go-微服务架构的基石"><a href="#Go-微服务架构的基石" class="headerlink" title="Go:微服务架构的基石"></a><a href="http://ppt.geekbang.org/slide/show/615" target="_blank" rel="external">Go:微服务架构的基石</a></h2><ul>
<li>负载均衡：seesaw、caddy</li>
<li>服务网关：tyk、fabio、vulcand</li>
<li>进程间通信：RESTful、RPC、自定义<ul>
<li>REST框架：beego、gin、Iris、micro、go-kit、goa</li>
<li>RPC框架：grpc、thrift、hprose</li>
<li>自定义：协议，编解码</li>
</ul>
</li>
<li>服务发现：etcd、consul、serf</li>
<li>调度系统：kubernetes、swarm、mesos</li>
<li>消息队列：NSQ、Nats</li>
<li>APM（应用性能监控）：appdash、Cloudinsight、opentracing</li>
<li>配置管理：etcd、consul、mgmt</li>
<li>日志分析：Beats、Heka</li>
<li>服务监控：open-falcon、prometheus</li>
<li>CI/CD：Drone</li>
<li>熔断器：gateway、Hystrix-go</li>
</ul>
<h2 id="基于万节点Kubernetes支撑大规模云应用实践"><a href="#基于万节点Kubernetes支撑大规模云应用实践" class="headerlink" title="基于万节点Kubernetes支撑大规模云应用实践"></a><a href="http://ppt.geekbang.org/slide/show/586" target="_blank" rel="external">基于万节点Kubernetes支撑大规模云应用实践</a></h2><ul>
<li>基于OpenStack的IaaS：裁剪KVM镜像、优化启动流程，Openvswitch SDN、Ceph存储</li>
<li>容器与虚拟机共用一套虚拟化网络</li>
<li>Ceph存储直接挂载到容器</li>
<li>统一的日志收集、分析、搜索</li>
<li>Kubernetes调度器优化：将原来的串行队列改为多个优先级队列</li>
<li>etcd集群扩展：将Pod/Node/ReplicationController拆分到不同的etcd集群</li>
</ul>
<p><img src="/images/14811811876614.jpg" alt=""></p>
<p><img src="/images/14811813670269.jpg" alt=""></p>
<h1 id="20-天持续压测，告诉你云存储性能哪家强-📈"><a href="#20-天持续压测，告诉你云存储性能哪家强-📈" class="headerlink" title="20 天持续压测，告诉你云存储性能哪家强 📈"></a><a href="https://www.v2ex.com/t/326038?from=timeline&amp;isappinstalled=0#reply7" target="_blank" rel="external">20 天持续压测，告诉你云存储性能哪家强</a> <a href="http://www.codingpy.com/specials/cbs_test/" target="_blank" rel="external">📈</a></h1><p>对阿里云和腾讯云两种云存储产品（云盘）的性能和价格对比：</p>
<ul>
<li>测试方法：SNIA发布的<a href="http://snia.org/sites/default/files/SSS_PTS_Enterprise_v1.1.pdf" target="_blank" rel="external">企业级SSD评测规范</a>及<a href="https://github.com/cloudharmony/block-storage" target="_blank" rel="external">实现</a></li>
<li>阿里云 SSD 云盘必须搭配 I/O 优化实例才能给发挥最大性能</li>
<li>腾讯云高效云盘的读写操作可同时达到预期性能峰值（数据块 16KB 以下），而阿里云方面，读写无法同时达到预期性能峰值</li>
<li>腾讯云达到了预期的性能；阿里云部分没有达到， 400GB 容量的时延过高</li>
<li>腾讯云高效云盘的时延在 1ms 以下， IOPS 、吞吐量的优势更加突出</li>
<li>两家高效云盘的 IOPS 表现均比较稳定，几乎呈一条直线，只有阿里云的 400GB 云盘有些略微波动</li>
<li>容量越大，似乎闲置时间对性能恢复的影响越明显；阿里云 400GB 高效云盘的性能波动受闲置时间影响较明显</li>
</ul>
<p><img src="/images/14811840736214.jpg" alt=""></p>
<h2 id="外卖的背后-饿了么基础架构从0到1的演进"><a href="#外卖的背后-饿了么基础架构从0到1的演进" class="headerlink" title="外卖的背后-饿了么基础架构从0到1的演进"></a><a href="http://ppt.geekbang.org/slide/show/619" target="_blank" rel="external">外卖的背后-饿了么基础架构从0到1的演进</a></h2><ul>
<li>负载均衡<ul>
<li>最初：HAProxy部署在客户端本地，不需要考虑HAProxy的高可用；问题是部署规模大，维护客户列表复杂，并且配置不统一</li>
<li>解决：<ul>
<li>RPC+内置LB SDK，服务自注册/自发现，配置少，部署简单</li>
<li>Redis/DB解决方案GoProxy: DAL/Corvus作为服务自注册，GoProxy订阅注册事件并自带服务发现的Haproxy</li>
<li>健康检查：心跳检测，进程在、端口活不代表服务可用</li>
</ul>
</li>
</ul>
</li>
<li>无损升级<ul>
<li>最初：发布前通知客户端停止请求，服务端将正在处理的请求处理完毕才能升级</li>
<li>解决：<ul>
<li>RPC调用：服务发现机制会在注销时通知客户端，直连情况下客户端从可用列表中剔除准备下线的服务</li>
<li>数据库访问，客户端限制连接存活时间，DAL侧重连</li>
</ul>
</li>
</ul>
</li>
<li>基础架构：开放式架构<ul>
<li>基于组件，给业务开发团队最大的自由</li>
<li>基于运行时，给业务开发团队最大限度的自由</li>
<li>开放封闭原则：基础框架应该是可以扩展的，但是不可以“选择”的</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Docker收购Infinit-PDF&quot;&gt;&lt;a href=&quot;#Docker收购Infinit-PDF&quot; class=&quot;headerlink&quot; title=&quot;Docker收购Infinit PDF&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://blog.docker.
    
    </summary>
    
      <category term="Readings" scheme="http://feisky.xyz/categories/Readings/"/>
    
    
  </entry>
  
  <entry>
    <title>Weekly reading list</title>
    <link href="http://feisky.xyz/2016/12/04/Weekly-reading-list/"/>
    <id>http://feisky.xyz/2016/12/04/Weekly-reading-list/</id>
    <published>2016-12-04T23:59:01.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分布式后台毫秒服务引擎"><a href="#分布式后台毫秒服务引擎" class="headerlink" title="分布式后台毫秒服务引擎"></a><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2650994968&amp;idx=1&amp;sn=6713bb3b59e1fb38c70f7178de136cfc&amp;scene=0#wechat_redirect" target="_blank" rel="external">分布式后台毫秒服务引擎</a></h2><blockquote>
<p>腾讯QQ团队于12月4日开源了一个服务开发运营框架，叫做毫秒服务引擎（Mass Service Engine in Cluster，MSEC），它集RPC、名字发现服务、负载均衡、业务监控、灰度发布、容量管理、日志管理、Key-Value存储于一体，目的是提高开发与运营的效率和质量。</p>
</blockquote>
<p><img src="/images/14809236732969.jpg" alt=""></p>
<p><img src="/images/14809236897310.jpg" alt=""></p>
<ul>
<li>服务发现与负载均衡<ul>
<li>集中管理每个服务（包括异构服务）的IP地址</li>
<li>服务之间RPC调用：服务名+接口名</li>
<li>路由的同时统计过去一段时间的成功率和时延</li>
</ul>
</li>
<li>支持多种编程语言（通过Protocol buffer生成不同语言的接口），如C/C++、Java、PHP等</li>
<li>Web化的管理界面(Tomcat)</li>
<li>存储：Redis cluster</li>
<li>官方网站：<a href="http://haomiao.qq.com" target="_blank" rel="external">http://haomiao.qq.com</a></li>
<li>Github：<a href="https://github.com/Tencent/MSEC" target="_blank" rel="external">https://github.com/Tencent/MSEC</a></li>
</ul>
<h2 id="Understanding-SELinux-Roles"><a href="#Understanding-SELinux-Roles" class="headerlink" title="Understanding SELinux Roles"></a><a href="http://danwalsh.livejournal.com/75683.html" target="_blank" rel="external">Understanding SELinux Roles</a></h2><p>SELinux label包含4个部分<code>user_u:role_r:type_t:level</code>，每个用户可以访问的角色：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><div class="line"><span class="symbol">semanage</span> user -l</div><div class="line"></div><div class="line">         Labeling   <span class="keyword">MLS/ </span>      <span class="keyword">MLS/ </span>                       </div><div class="line"><span class="keyword">SELinux </span>User    Prefix     MCS Level  MCS Range       <span class="keyword">SELinux </span>Roles</div><div class="line"></div><div class="line"><span class="symbol">guest_u</span>             user       <span class="built_in">s0</span>         <span class="built_in">s0</span>                             guest_r</div><div class="line"><span class="symbol">root</span>                    user       <span class="built_in">s0</span>         <span class="built_in">s0</span>-<span class="built_in">s0</span>:<span class="built_in">c0</span>.c1023        staff_r sysadm_r system_r unconfined_r</div><div class="line"><span class="symbol">staff_u</span>               user       <span class="built_in">s0</span>         <span class="built_in">s0</span>-<span class="built_in">s0</span>:<span class="built_in">c0</span>.c1023        staff_r sysadm_r system_r unconfined_r</div><div class="line"><span class="symbol">sysadm_u</span>         user       <span class="built_in">s0</span>         <span class="built_in">s0</span>-<span class="built_in">s0</span>:<span class="built_in">c0</span>.c1023        sysadm_r</div><div class="line"><span class="symbol">system_u</span>          user       <span class="built_in">s0</span>         <span class="built_in">s0</span>-<span class="built_in">s0</span>:<span class="built_in">c0</span>.c1023        system_r unconfined_r</div><div class="line"><span class="symbol">unconfined_u</span>    user       <span class="built_in">s0</span>         <span class="built_in">s0</span>-<span class="built_in">s0</span>:<span class="built_in">c0</span>.c1023        system_r unconfined_r</div><div class="line"><span class="symbol">user_u</span>               user       <span class="built_in">s0</span>         <span class="built_in">s0</span>                             user_r</div><div class="line"><span class="symbol">xguest_u</span>           user       <span class="built_in">s0</span>         <span class="built_in">s0</span>                             xguest_r</div></pre></td></tr></table></figure>
<ul>
<li>system_r role is the default role for all processes started at boot</li>
<li>You can not assign an SELinux user a role that is not listed</li>
<li>object_r is not really a role, but more of a place holder.  Roles only make sense for processes, not for files</li>
<li>on the file system.  But the SELinux label requires a role for all labels.  object_r is the role that we use to fill the objects on disks role.  Changing a process to run as object_r or trying to assign a different role to a file will always be denied by the kernel.</li>
</ul>
<h2 id="Kompose-a-tool-to-go-from-Docker-compose-to-Kubernetes"><a href="#Kompose-a-tool-to-go-from-Docker-compose-to-Kubernetes" class="headerlink" title="Kompose: a tool to go from Docker-compose to Kubernetes"></a><a href="http://blog.kubernetes.io/2016/11/kompose-tool-go-from-docker-compose-to-kubernetes.html" target="_blank" rel="external">Kompose: a tool to go from Docker-compose to Kubernetes</a></h2><ul>
<li>把docker-compose.yml或dab转换为kubernetes service+deployment</li>
<li>Github: <a href="https://github.com/kubernetes-incubator/kompose" target="_blank" rel="external">https://github.com/kubernetes-incubator/kompose</a></li>
</ul>
<figure class="highlight applescript"><table><tr><td class="code"><pre><div class="line">$ kompose <span class="comment">--bundle docker-compose-bundle.dab convert</span></div><div class="line">WARN[<span class="number">0000</span>]: Unsupported key networks - <span class="keyword">ignoring</span></div><div class="line"><span class="built_in">file</span> <span class="string">"redis-svc.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"web-svc.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"web-deployment.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"redis-deployment.json"</span> created</div><div class="line"></div><div class="line">$ kompose -f docker-compose.yml convert</div><div class="line">WARN[<span class="number">0000</span>]: Unsupported key networks - <span class="keyword">ignoring</span></div><div class="line"><span class="built_in">file</span> <span class="string">"redis-svc.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"web-svc.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"web-deployment.json"</span> created</div><div class="line"><span class="built_in">file</span> <span class="string">"redis-deployment.json"</span> created</div></pre></td></tr></table></figure>
<h2 id="2016年网络虚拟化趋势"><a href="#2016年网络虚拟化趋势" class="headerlink" title="2016年网络虚拟化趋势"></a><a href="http://www.sdnlab.com/18153.html" target="_blank" rel="external">2016年网络虚拟化趋势</a></h2><ul>
<li>市场持续升温：NV的市场已经是一个数十亿美元的市场，Cisco、Juniper、Nuage、VMware是NV市场的四大巨头，他们占据了NV市场的绝大多数收入</li>
<li>思科和VMware公布的数据显示其与NV相关的投资组合在2016年将近30亿美元</li>
<li>容器化：思科收购ContainerX，VMWare推出vSphere集成容器（VIC）</li>
</ul>
<p><img src="/images/14809260496846.jpg" alt=""></p>
<h2 id="Amazon发布一大波新产品"><a href="#Amazon发布一大波新产品" class="headerlink" title="Amazon发布一大波新产品"></a>Amazon发布一大波新产品</h2><ul>
<li><a href="https://amazonlightsail.com/" target="_blank" rel="external">Amazon Lightsail</a>：廉价VPS，价格跟LightSale, DO, VULTR, Linode相同。</li>
<li><a href="https://aws.amazon.com/cn/blogs/aws/developer-preview-ec2-instances-f1-with-programmable-hardware/" target="_blank" rel="external">F1 instance with FPGA</a>：VHDL和Verilog终于有出路了</li>
<li>今年是机器学习大火的一年，Amazon也随大流（微软、Google）推出了AI服务：<ul>
<li>Amazon Rekognition图像处理和分析</li>
<li>Amazon Lex自然语言处理</li>
<li>Amazon Polly文本到语音的转换</li>
</ul>
</li>
<li><a href="https://aws.amazon.com/cn/snowmobile/" target="_blank" rel="external">AWS Snowmobile</a>：带宽从来都不是问题<br>  <img src="/images/14809265679834.jpg" alt=""></li>
</ul>
<h2 id="Linux-bcc-BPF-tcplife"><a href="#Linux-bcc-BPF-tcplife" class="headerlink" title="Linux bcc/BPF tcplife"></a><a href="http://www.brendangregg.com/blog/2016-11-30/linux-bcc-tcplife.html" target="_blank" rel="external">Linux bcc/BPF tcplife</a></h2><figure class="highlight tap"><table><tr><td class="code"><pre><div class="line"><span class="comment"># ./tcplife -D 80</span></div><div class="line">PID   COMM       LADDR           LPORT RADDR           RPORT TX_KB RX_KB MS</div><div class="line">27448 curl       100.66.11.247  <span class="number"> 54146 </span>54.154.224.174 <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>263.85</div><div class="line">27450 curl       100.66.11.247  <span class="number"> 20618 </span>54.154.164.22  <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>243.62</div><div class="line">27452 curl       100.66.11.247  <span class="number"> 11480 </span>54.154.43.103  <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>231.16</div><div class="line">27454 curl       100.66.11.247  <span class="number"> 31382 </span>54.154.15.7    <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>249.95</div><div class="line">27456 curl       100.66.11.247  <span class="number"> 33416 </span>52.210.59.223  <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>545.72</div><div class="line">27458 curl       100.66.11.247  <span class="number"> 16406 </span>52.30.140.35   <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>222.29</div><div class="line">27460 curl       100.66.11.247  <span class="number"> 11634 </span>52.30.133.135  <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>217.52</div><div class="line">27462 curl       100.66.11.247  <span class="number"> 25660 </span>52.30.126.182  <span class="number"> 80 </span>      <span class="number"> 0 </span>   <span class="number"> 1 </span>250.81</div><div class="line">[...]</div><div class="line"></div><div class="line"><span class="comment"># ./tcplife -h</span></div><div class="line">usage: tcplife [-h] [-T] [-t] [-w] [-s] [-p PID] [-L LOCALPORT]</div><div class="line">               [-D REMOTEPORT]</div><div class="line"></div><div class="line">Trace the lifespan of TCP sessions and summarize</div><div class="line"></div><div class="line">optional arguments:</div><div class="line">  -h, --help            show this help message and exit</div><div class="line">  -T, --time            include time column on output (HH:MM:SS)</div><div class="line">  -t, --timestamp       include timestamp on output (seconds)</div><div class="line">  -w, --wide            wide column output (fits IPv6 addresses)</div><div class="line">  -s, --csv             comma seperated values output</div><div class="line">  -p PID, --pid PID     trace this PID only</div><div class="line">  -L LOCALPORT, --localport LOCALPORT</div><div class="line">                        comma-separated list of local ports to trace.</div><div class="line">  -D REMOTEPORT, --remoteport REMOTEPORT</div><div class="line">                        comma-separated list of remote ports to trace.</div><div class="line"></div><div class="line">examples:</div><div class="line">    ./tcplife           <span class="comment"># trace all TCP connect()s</span></div><div class="line">    ./tcplife -t        <span class="comment"># include time column (HH:MM:SS)</span></div><div class="line">    ./tcplife -w        <span class="comment"># wider colums (fit IPv6)</span></div><div class="line">    ./tcplife -stT      <span class="comment"># csv output, with times &amp; timestamps</span></div><div class="line">    ./tcplife -p<span class="number"> 181 </span>   <span class="comment"># only trace PID 181</span></div><div class="line">    ./tcplife -L<span class="number"> 80 </span>    <span class="comment"># only trace local port 80</span></div><div class="line">    ./tcplife -L 80,81  <span class="comment"># only trace local ports 80 and 81</span></div><div class="line">    ./tcplife -D<span class="number"> 80 </span>    <span class="comment"># only trace remote port 80</span></div></pre></td></tr></table></figure>
<h2 id="cgroup-namespace"><a href="#cgroup-namespace" class="headerlink" title="cgroup namespace"></a><a href="http://hustcat.github.io/cgroup-namespace/" target="_blank" rel="external">cgroup namespace</a></h2><p>之前，在一个容器查看/proc/$PID/cgroup，或者在容器挂载cgroup时，会看到整个系统的cgroup信息；在内核从4.6开始，支持cgroup namespace （<a href="https://lwn.net/Articles/618873/" target="_blank" rel="external">https://lwn.net/Articles/618873/</a>）。</p>
<blockquote>
<p>(1)可以限制容器的cgroup filesytem视图，使得在容器中也可以安全的使用cgroup；<br>(2)此外，会使容器迁移更加容易；在迁移时，/proc/self/cgroup需要复制到目标机器，这要求容器的cgroup路径是唯一的，否则可能会与目标机器冲突。有了cgroupns，每个容器都有自己的cgroup filesystem视图，不用担心这种冲突。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;分布式后台毫秒服务引擎&quot;&gt;&lt;a href=&quot;#分布式后台毫秒服务引擎&quot; class=&quot;headerlink&quot; title=&quot;分布式后台毫秒服务引擎&quot;&gt;&lt;/a&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4
    
    </summary>
    
      <category term="Readings" scheme="http://feisky.xyz/categories/Readings/"/>
    
    
  </entry>
  
  <entry>
    <title>KubeCon/CloudNativeCon 2016见闻</title>
    <link href="http://feisky.xyz/2016/11/14/KubeCon-2016%E8%A7%81%E9%97%BB/"/>
    <id>http://feisky.xyz/2016/11/14/KubeCon-2016见闻/</id>
    <published>2016-11-14T01:49:52.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>题记：上周去西雅图参加了<a href="http://events.linuxfoundation.org/events/kubecon" target="_blank" rel="external">KubeCon&amp;CloudNativeCon 2016</a>，不仅见到Dawn、Brendan、Tim以及Sig Node的各路大神，还参加了不少有趣的session。</p>
<h2 id="Compiling-to-Containers-Brendan-Burns-Microsoft"><a href="#Compiling-to-Containers-Brendan-Burns-Microsoft" class="headerlink" title="Compiling to Containers - Brendan Burns, Microsoft"></a><a href="https://cnkc16.sched.org/event/8K8y/compiling-to-containers-brendan-burns-microsoft?iframe=no&amp;w=100%&amp;sidebar=yes&amp;bg=no" target="_blank" rel="external">Compiling to Containers</a> - Brendan Burns, Microsoft</h2><p>Containers可以看作是现代分布式系统的“汇编语言”，这样分布式系统的管理实际上就成了开发“Container汇编语言”。Brendan还以JavaScript为例，演示了如何基于<a href="https://github.com/brendandburns/metaparticle" target="_blank" rel="external">Metaparticle</a>来支持不同的service pattern:</p>
<ul>
<li>Simple Service: simply exposes a function as an HTTP service.</li>
<li>Scatter/Gather: fans all requests out to all leaf nodes (scatter phase), all responses are then aggregated in a root node (gather phase), this aggregate response is returned to the caller.</li>
<li>Shard: select a shard (replica) for a request.</li>
<li>Spread: similar to Shard, but uses a randomized shardingFunction.</li>
</ul>
<h2 id="Unik-Unikernel-Runtime-for-Kubernetes-Idit-Levine-EMC"><a href="#Unik-Unikernel-Runtime-for-Kubernetes-Idit-Levine-EMC" class="headerlink" title="Unik: Unikernel Runtime for Kubernetes - Idit Levine, EMC"></a><a href="https://cnkc16.sched.org/event/8K8v/unik-unikernel-runtime-for-kubernetes-idit-levine-emc?iframe=no&amp;w=100%&amp;sidebar=yes&amp;bg=no" target="_blank" rel="external">Unik: Unikernel Runtime for Kubernetes</a> - Idit Levine, EMC</h2><p><a href="https://github.com/emc-advanced-dev/unik" target="_blank" rel="external">Unik</a>是一个将应用编译成unikernel的工具，支持rump/OSv/IncludeOS/MirageOS等，编译的结果可以直接跑在公有云或者本地的虚拟机中。</p>
<p>Unik在Kubernetes中实现了一个特殊的<a href="https://github.com/emc-advanced-dev/kubernetes/tree/master/pkg/kubelet/unik" target="_blank" rel="external">runtime</a>，并可以通过kubernetes来管理unik：</p>
<ul>
<li>镜像管理：实际上通过rkt来操作镜像</li>
<li>Pod管理：one Pod == one VM == one Container，通过调用unik daemon来操作</li>
</ul>
<h2 id="Technical-View-Comparison-of-Container-Orchestration-and-Management-Systems-Lei-Zhang-HyperHQ"><a href="#Technical-View-Comparison-of-Container-Orchestration-and-Management-Systems-Lei-Zhang-HyperHQ" class="headerlink" title="Technical View: Comparison of Container Orchestration and Management Systems - Lei Zhang, HyperHQ"></a><a href="https://cnkc16.sched.org/event/8K3x/technical-view-comparison-of-container-orchestration-and-management-systems-lei-zhang-hyperhq?iframe=no&amp;w=100%&amp;sidebar=yes&amp;bg=no" target="_blank" rel="external">Technical View: Comparison of Container Orchestration and Management Systems</a> - Lei Zhang, HyperHQ</h2><p>我司张磊同学的大作，从架构、控制平面、服务发现与负载均衡、调度等各个角度对比Kubernetes/Swarmkit/Mesos等常见容器编排系统，并以<a href="https://github.com/hyperhq/hypernetes" target="_blank" rel="external">hypernetes</a>和<a href="http://hyper.sh/" target="_blank" rel="external">Hyper Container Service</a>为例说明为什么kubernetes是一个更好的选择。</p>
<p><img src="/images/1-4.png" alt="1"><br><img src="/images/2-3.png" alt="2"></p>
<h2 id="Everything-You-Ever-Wanted-to-Know-About-Resource-Scheduling-But-Were-Afraid-to-Ask-Tim-Hockin-Google"><a href="#Everything-You-Ever-Wanted-to-Know-About-Resource-Scheduling-But-Were-Afraid-to-Ask-Tim-Hockin-Google" class="headerlink" title="Everything You Ever Wanted to Know About Resource Scheduling, But Were Afraid to Ask - Tim Hockin, Google"></a><a href="https://cnkc16.sched.org/event/8K8l/everything-you-ever-wanted-to-know-about-resource-scheduling-but-were-afraid-to-ask-tim-hockin-google?iframe=no&amp;w=100%&amp;sidebar=yes&amp;bg=no" target="_blank" rel="external">Everything You Ever Wanted to Know About Resource Scheduling, But Were Afraid to Ask</a> - Tim Hockin, Google</h2><p>Kubernetes is fundamentally about resource management:</p>
<ul>
<li>CPU/Memory/Disk</li>
<li>Network/Ports/IP addresses</li>
<li>PIDs</li>
<li>GPUs</li>
<li>Storage</li>
<li>Power</li>
</ul>
<p>关于资源管理的三方面:</p>
<ul>
<li>Isolation：保证应用可以获取想要的资源并且不影响其他应用，目前基于Requests/Limits只支持cpu和内存</li>
<li>Sizing：应该给用户分配多少资源呢，没有统一的方法，只能靠benchmark，但精确的benchmark很难，所以Kubernetes提供了Horizontal Pod Autoscaler，未来可能还会有VerticalPodAutoscaler</li>
<li>Utilization：资源的实际使用情况是啥样的，涉及Priority调度、Quota管理、Overcommit等等。</li>
</ul>
<p><img src="/images/3-4.png" alt="3"></p>
<p>Slide见<a href="https://speakerdeck.com/thockin/everything-you-ever-wanted-to-know-about-resource-scheduling-dot-dot-dot-almost" target="_blank" rel="external">这里</a>.</p>
<h2 id="Self-hosted-Scale-and-Federation-with-Kubernetes-v1-4-and-Beyond-Brandon-Philips-CoreOS"><a href="#Self-hosted-Scale-and-Federation-with-Kubernetes-v1-4-and-Beyond-Brandon-Philips-CoreOS" class="headerlink" title="Self-hosted, Scale, and Federation with Kubernetes v1.4 and Beyond - Brandon Philips, CoreOS"></a><a href="https://cnkc16.sched.org/event/8K3v/self-hosted-scale-and-federation-with-kubernetes-v14-and-beyond-brandon-philips-coreos-inc?iframe=yes&amp;w=100%&amp;sidebar=yes&amp;bg=no#" target="_blank" rel="external">Self-hosted, Scale, and Federation with Kubernetes v1.4 and Beyond</a> - Brandon Philips, CoreOS</h2><p>基本的idea是用Kubernetes来管理Kubernetes的部署和升级，这也是一个孵化状态的项目<a href="https://github.com/kubernetes-incubator/bootkube" target="_blank" rel="external">bootkube</a>。由于kubelet初始化需要控制平面的配合，bootkube会在一开始的时候会启动一个暂时的控制平面（api-server, scheduler, controller manager），部署完成后再替换回来。</p>
<p>部署前将bootkube作为控制平面：</p>
<p><img src="/images/bootkube-1.png" alt="bootkube-1"></p>
<p>部署后替换成真正的控制平面：</p>
<p><img src="/images/bootkube-2.png" alt="bootkube-2"></p>
<p>相关文档</p>
<ul>
<li><a href="https://github.com/kubernetes-incubator/bootkube" target="_blank" rel="external">Incubator BootKube</a></li>
<li><a href="https://speakerdeck.com/philips/kubecon-2016-self-hosted-scale-and-federation-with-kubernetes-v1-dot-4-and-beyond" target="_blank" rel="external">Slide</a></li>
<li><a href="https://docs.google.com/document/d/1VNp4CMjPPHevh2_JQGMl-hpz9JSLq3s7HlI87CTjl-8/edit" target="_blank" rel="external">Design of bootkube</a></li>
<li><a href="https://coreos.com/blog/self-hosted-kubernetes.html" target="_blank" rel="external">Blog of self-booted kubernetes</a></li>
<li><a href="https://docs.google.com/document/d/1_I6xT0XHCoOqZUT-dtpxzwvYpTR5JmFQY0S4gL2PPkU/edit#heading=h.yeahbhtih70g" target="_blank" rel="external">Kubelet as a Container and Self-Hosted Kubernetes</a></li>
</ul>
<h2 id="F2F"><a href="#F2F" class="headerlink" title="F2F"></a>F2F</h2><p><strong><a href="https://docs.google.com/document/d/1ZVQIzLuHsBFDCw-QLO30rqRlSNSc1xynfs9GAFrjeVc/edit" target="_blank" rel="external">Sig-node F2F</a></strong></p>
<ul>
<li>Performance-Sensitive Application Platform<ul>
<li>高性能应用的场景，比如telecom, HFT等，需要NUMA、GPU、sysctls、hugepage、cpuset等等的支持。</li>
<li>一个idea是通过daemonset并配合NodeAllocatable</li>
</ul>
</li>
<li>CRI blockers and progress<ul>
<li>1.5的feature基本完成，只剩下一些bug fixes</li>
<li>per-pod cgroups</li>
<li>monitoring</li>
<li>api versioning</li>
<li>hostport network</li>
<li>metrics</li>
<li>CRI validation tests</li>
<li>auth</li>
</ul>
</li>
<li>Runtime agnostic debugging tools<ul>
<li>CLI for CRI?</li>
</ul>
</li>
<li>NodeSpec standardization</li>
<li>Packaging</li>
</ul>
<p><strong><a href="https://docs.google.com/document/d/1wtJeXhiVOL7qdDK_zouZPjskTIrsOLmD-9Ij478y7_Y/edit" target="_blank" rel="external">OCI F2F</a></strong></p>
<p>最主要的是<code>Runtime CLI Spec</code>和<code>Image Spec rc3</code>。比较有趣的是<a href="https://github.com/vbatts/nspawn-oci" target="_blank" rel="external">systemd wrapper / rkt wrapper for OCI runtime-spec CLI</a>，rkt也要加入OCI的大营。</p>
<h2 id="Developer-Summit"><a href="#Developer-Summit" class="headerlink" title="Developer Summit"></a>Developer Summit</h2><p><strong><a href="https://docs.google.com/presentation/d/1SD6a6eJl47t0qyTFE8GzaiytW4T_crdWgYAMCaLy1W8" target="_blank" rel="external">Scaling the Kubernetes CodeBase</a></strong></p>
<p>Kubernetes使用github来管理代码库，但现在碰到了明显的瓶颈：从2015年下半年开始<a href="http://velodrome.k8s.io/dashboard/db/kubernetes-developer-velocity" target="_blank" rel="external">merge时间明显加长</a>，open issues和PRs一直再增长，大量无关紧要的github通知等等。未来计划将Kubernetes的代码拆分到多个repo中，kuberentes代码库只保留核心代码，并通过Extension mechanism来支持各种功能：</p>
<ul>
<li>Apiserver federation</li>
<li>Authorization hooks</li>
<li>Admission-control hooks</li>
<li>Initializers and finalizers</li>
<li>ThirdPartyResource</li>
<li>Kubectl extensions</li>
<li>Service Broker, Operators</li>
<li>Controller pattern</li>
<li>External cloudproviders</li>
<li>CRI, network, and storage plugins</li>
<li>Cluster addons: UI, monitoring, logging</li>
<li>Feature gates, feature discovery, dependency management</li>
</ul>
<p>更多记录见<a href="https://docs.google.com/document/d/1zN2DWKerXwbzxZTO52wBRqp_uHMdLp8P52xYOmp5WZ4/edit" target="_blank" rel="external">这里</a>.</p>
<p><strong>其他的Summit简介</strong></p>
<ul>
<li><a href="https://docs.google.com/presentation/d/1dFfN3_9VM4cRKknZB9_0wsM_1YLJToRTEx7dX6BoEhI" target="_blank" rel="external">Kubernetes 2017 Features &amp; Roadmaps</a> <a href="https://docs.google.com/spreadsheets/d/154cAee2mOn3LoQDgpgG2ZzAIdIlQ_KnMlghGjnGwQ1w" target="_blank" rel="external">Roadmap</a><ul>
<li>Scale the project (tablestakes)</li>
<li>Reference architectures for application workflows</li>
<li>Secure multi-tenancy with service catalog</li>
<li>Production ready cluster lifecycle</li>
<li>Multi-cloud support for AWS / Azure / on premises</li>
</ul>
</li>
<li><a href="https://docs.google.com/document/d/11kK39Zz3zxIY9-GFa8buqqWYOrctFQ7hvOw5NBFwJL0/edit#heading=h.n0vlwrfu65r1" target="_blank" rel="external">Cluster Lifecycle Deployment &amp; Upgrade Roadmap</a><ul>
<li>HA</li>
<li>Upgrades</li>
<li>Config Management</li>
<li>Toolbox vs. guided flow</li>
<li>Documentation</li>
<li>Conformance Testing</li>
<li>PKI</li>
</ul>
</li>
<li><a href="https://docs.google.com/presentation/d/1GFuKgN-1kMmcg41T9HsasP8YEWtMAipEibYnwGkQuHo" target="_blank" rel="external">Documentation</a> and <a href="https://docs.google.com/document/d/1VYoVl63Iq2QSKxpoV7HGXmWasxU5EQCAuoIItj-ODvM/edit" target="_blank" rel="external">here</a></li>
<li><a href="https://docs.google.com/document/d/1cJhpjRcXpTmTWQswEfBqSbrfqrawtD9ZlWW30Q3BWv4/edit" target="_blank" rel="external">K8s Dev Summit: Outstanding Issues and PRs</a><ul>
<li>Issues 4600+, PRs 600+，还在不断增长中</li>
<li><a href="https://github.com/kubernetes/community/tree/master/sig-contribx" target="_blank" rel="external">Sig Contribx</a>会跟进处理这个问题</li>
</ul>
</li>
<li><a href="https://docs.google.com/document/d/1WmRwT3nhLXTYRLKlj9rjZmEXv3BEu7TFX29nuaO3enA/edit#heading=h.w90umf5dyer3" target="_blank" rel="external">Multi-tenancy</a></li>
<li><a href="https://docs.google.com/document/d/1X5i-Z3GsFyknxq4LyB3cObXEm5ds7DTUYOKwHAMHK5A/edit" target="_blank" rel="external">Azure &amp; AWS Kubernetes Discussion</a></li>
<li><a href="https://docs.google.com/document/d/1klHgGFKtSPHGNlG24LDb5-ornBUtZLcUnEjF8XKXDes/edit" target="_blank" rel="external">Contrib notes</a> and <a href="https://docs.google.com/document/d/19B2vcK6Y3xE3JO7sd4n6lPF0m9bBVZpNucvcR3MwEXA/edit" target="_blank" rel="external">On developer onboarding</a></li>
<li><a href="https://docs.google.com/document/d/1p7scsTPzPyouktBFTxu4RhRwW8yUn5Lj7VGY9SaOo-8/edit" target="_blank" rel="external">Compute resource management</a></li>
<li><a href="https://docs.google.com/document/d/1K2hh7nQ9glYzGE-5J7oKBB7oK3S_MKqwCISXZK-sB2Q/edit" target="_blank" rel="external">Logging volumes</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;题记：上周去西雅图参加了&lt;a href=&quot;http://events.linuxfoundation.org/events/kubecon&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;KubeCon&amp;amp;CloudNativeCon 2016&lt;/a&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://feisky.xyz/tags/kubernetes/"/>
    
      <category term="kubecon" scheme="http://feisky.xyz/tags/kubecon/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes container runtime interface</title>
    <link href="http://feisky.xyz/2016/09/24/Kubernetes-container-runtime-interface/"/>
    <id>http://feisky.xyz/2016/09/24/Kubernetes-container-runtime-interface/</id>
    <published>2016-09-24T22:59:31.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>题记：最近一段时间在做Kubernetes容器引擎接口（Container Runtime Interface， CRI）的重构，并支持以插件的方式引入外部容器引擎。CRI还在紧张有序的开发中，预计在v1.5发布第一个alpha版。</p>
<h2 id="什么是CRI"><a href="#什么是CRI" class="headerlink" title="什么是CRI"></a>什么是CRI</h2><p>CRI是Kubelet（负责管理容器生命周期的服务）与容器引擎之间的接口。为了适应多种不同的容器引擎，Kubelet在加入rkt的时候就已经在docker API的基础上抽象了一个Runtime接口，只是由于一些特定的缺陷，在这个接口上不太容易引入其他新的容器引擎：</p>
<ul>
<li>Runtime接口的抽象度太高，导致一些原本该在Kubelet控制的逻辑被放到了Runtime实现里面。比如在当前的实现中，rkt和docker的<code>SyncPod</code>（负责Pod创建的接口）存在大量重复的逻辑，每次修改docker部分的时，都有可能需要同时修改rkt部分。这样，如果再加入新的容器引擎的话，同时修改多个Runtime部分的代码是没法维护的。</li>
<li>Runtime接口是集成在Kubelet内部的，集成容器引擎相关的代码需要放到Kubernetes代码库里面，这同样带来了维护的问题：代码维护麻烦，任何一个容器引擎修改了代码都需要发布新的kubelet；集成测试麻烦，要为每个不同的容器引擎部署不同的集成测试环境。</li>
<li>没有提供容器创建的接口，无法直接在Kubelet里面做到对容器的精细控制。</li>
<li>耦合了镜像和容器管理，而它们的生命周期本来就是独立的。</li>
</ul>
<p>既然Runtime接口有很多问题，并且有很多容器引擎想要集成到Kubernetes中，所以有必要重新定义CRI，并且提供一种插件机制，允许容器引擎以外部独立进程的方式接入。所以，Brendan Burns在<a href="http://hypercontainer.io" target="_blank" rel="external">Hyper</a>集成的时候就提供了一种以客户端/服务器方式接入外部容器引擎的思路。在大量的社区讨论后，Node team重新抽象了容器引擎接口（也就是CRI），并决定以gRPC的方式接入外部容器引擎。</p>
<h2 id="CRI是如何工作的"><a href="#CRI是如何工作的" class="headerlink" title="CRI是如何工作的"></a>CRI是如何工作的</h2><p>CRI比Runtime接口提供了更细粒度的抽象，解耦了镜像管理和容器管理，并为Pod和Container提供了独立的操作接口。CRI以gRPC的方式接入，Kubelet是gPRC API的客户端，而容器引擎则是gRPC API的服务端。gRPC已经自动实现了它们之间交互的细节，容器引擎只需要实现每个具体的API。</p>
<p>一个典型的启动Pod的流程为</p>
<p><img src="/images/createpod.png" alt="createpod"></p>
<p>而停止Pod的流程为</p>
<p><img src="/images/killpod.png" alt="killpod"></p>
<h2 id="CRI带了什么"><a href="#CRI带了什么" class="headerlink" title="CRI带了什么"></a>CRI带了什么</h2><p>CRI解决了上述提到的Runtime接口的问题，使得新的容器引擎可以更方便的集成到Kubernetes中来，这必将给Kubernetes社区带来新一轮的变革，并促进Kubernetes走入更多的应用场景中。比如，Redhat借助OCI容器引擎runc摆脱对docker依赖，Hyper以虚拟化的方式解决多租户场景下的容器隔离问题，甚至Mirantis直接用Kubernetes来管理原生的虚拟机。</p>
<p>CRI也解耦了容器和镜像的管理，可以方便的扩展其他镜像格式，比如ACI等。</p>
<p>CRI还在着力解决一些很有挑战的问题，比如</p>
<ul>
<li>容器日志的管理，包括日志格式化规范、日志文件rotate、日志文件磁盘IO控制以及日志的统一收集处理等。</li>
<li>解除streaming API（exec、attach、logs等）对kubelet的网络压力。当前所有的streaming API都是从<code>apiserver-&gt;kubelet-&gt;runtime</code>，apiserver是无状态的，可以水平扩展，但kubelet和runtime则是每台机器只能有一个，streaming API有可能会给他们带来处理的瓶颈。所以在CRI中，将会考虑使用一个独立进程（需要对apiserver开放端口）来单独处理这些请求<code>apiserver-&gt;newStreamProcess</code>，释放kubelet来做更核心的事情。</li>
<li>更灵活的网络配置，将Pod网络的配置完全交给容器引擎，而Kubernetes只需要最终的网络状态。</li>
</ul>
<h2 id="CRI的未来"><a href="#CRI的未来" class="headerlink" title="CRI的未来"></a>CRI的未来</h2><p>虽然CRI还在持续开发中（目前还没有任何release），但已经有很多厂商已经开始了引入新容器引擎的进程：</p>
<ul>
<li>Frakti：为解决多租户场景下的容器隔离问题，Hyper以虚拟化的方式运行容器。关于frakti的更多细节见<a href="https://github.com/kubernetes/frakti。" target="_blank" rel="external">https://github.com/kubernetes/frakti。</a></li>
<li>OCI-O：为解耦对docker的依赖，Redhat提供对OCI容器引擎的支持（目前主要是runc）。关于oci-o的更多细节见<a href="https://github.com/kubernetes-incubator/oci-o。" target="_blank" rel="external">https://github.com/kubernetes-incubator/oci-o。</a></li>
<li>Rktlet：为了加速rkt容器引擎的开发维护，CoreOS提议将rkt集成的代码独立出Kubelet（vendor到kubelet，同集成到kubelet内部便于发布），并重构rkt以适应CRI的变化。关于rktlet的更多细节见<a href="https://github.com/kubernetes-incubator/rktlet。" target="_blank" rel="external">https://github.com/kubernetes-incubator/rktlet。</a></li>
<li>Virtlet：为了支持原生的虚拟机管理，Mirantis提议直接用Kubernetes来管理原生的虚拟机（需要将docker镜像替换成qcow2镜像）。关于virtlet的更多细节见<a href="https://github.com/Mirantis/virtlet。" target="_blank" rel="external">https://github.com/Mirantis/virtlet。</a></li>
<li>当然，docker相关的代码还会继续保留在kubelet内部，只不过要重构到CRI上面来。</li>
</ul>
<p>CRI预计在Kubernetes v1.5发布第一个alpha版。届时，上面各个容器引擎的实现也将会发布第一个release。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;题记：最近一段时间在做Kubernetes容器引擎接口（Container Runtime Interface， CRI）的重构，并支持以插件的方式引入外部容器引擎。CRI还在紧张有序的开发中，预计在v1.5发布第一个alpha版。&lt;/p&gt;
&lt;h2 id=&quot;什么是CRI&quot;&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://feisky.xyz/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes中的服务发现与负载均衡</title>
    <link href="http://feisky.xyz/2016/09/11/Kubernetes%E4%B8%AD%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    <id>http://feisky.xyz/2016/09/11/Kubernetes中的服务发现与负载均衡/</id>
    <published>2016-09-11T01:48:09.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes在设计之初就充分考虑了针对容器的服务发现与负载均衡机制，提供了Service资源，并通过kube-proxy配合cloud provider来适应不同的应用场景。随着kubernetes用户的激增，用户场景的不断丰富，又产生了一些新的负载均衡机制。目前，kubernetes中的负载均衡大致可以分为以下几种机制，每种机制都有其特定的应用场景：</p>
<ul>
<li>Service：直接用Service提供cluster内部的负载均衡，并借助cloud provider提供的LB提供外部访问</li>
<li>Ingress Controller：还是用Service提供cluster内部的负载均衡，但是通过自定义LB提供外部访问</li>
<li>Service Load Balancer：把load balancer直接跑在容器中，实现Bare Metal的Service Load Balancer</li>
<li>Custom Load Balancer：自定义负载均衡，并替代kube-proxy，一般在物理部署Kubernetes时使用，方便接入公司已有的外部服务</li>
</ul>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p><img src="/images/k8s-service.png" alt=""></p>
<p>Service是对一组提供相同功能的Pods的抽象，并为它们提供一个统一的入口。借助Service，应用可以方便的实现服务发现与负载均衡，并实现应用的零宕机升级。Service通过标签来选取服务后端，一般配合Replication Controller或者Deployment来保证后端容器的正常运行。</p>
<p>Service有三种类型：</p>
<ul>
<li>ClusterIP：默认类型，自动分配一个仅cluster内部可以访问的虚拟IP</li>
<li>NodePort：在ClusterIP基础上为Service在每台机器上绑定一个端口，这样就可以通过<code>&lt;NodeIP&gt;:NodePort</code>来访问改服务</li>
<li>LoadBalancer：在NodePort的基础上，借助cloud provider创建一个外部的负载均衡器，并将请求转发到<code>&lt;NodeIP&gt;:NodePort</code></li>
</ul>
<p>另外，也可以讲已有的服务以Service的形式加入到Kubernetes集群中来，只需要在创建Service的时候不指定Label selector，而是在Service创建好后手动为其添加endpoint。</p>
<h2 id="Ingress-Controller"><a href="#Ingress-Controller" class="headerlink" title="Ingress Controller"></a>Ingress Controller</h2><p>Service虽然解决了服务发现和负载均衡的问题，但它在使用上还是有一些限制，比如</p>
<p>－ 只支持4层负载均衡，没有7层功能<br>－ 对外访问的时候，NodePort类型需要在外部搭建额外的负载均衡，而LoadBalancer要求kubernetes必须跑在支持的cloud provider上面</p>
<p>Ingress就是为了解决这些限制而引入的新资源，主要用来将服务暴露到cluster外面，并且可以自定义服务的访问策略。比如想要通过负载均衡器实现不同子域名到不同服务的访问：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><div class="line">foo.bar.com --|<span class="string">                 </span>|<span class="string">-&gt; foo.bar.com s1:80</span></div><div class="line">              |<span class="string"> 178.91.123.132  </span>|</div><div class="line">bar.foo.com --|<span class="string">                 </span>|<span class="string">-&gt; bar.foo.com s2:80</span></div></pre></td></tr></table></figure>
<p>可以这样来定义Ingress：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><div class="line"><span class="attr">apiVersion:</span> extensions/v1beta1</div><div class="line"><span class="attr">kind:</span> Ingress</div><div class="line"><span class="attr">metadata:</span></div><div class="line"><span class="attr">  name:</span> test</div><div class="line"><span class="attr">spec:</span></div><div class="line"><span class="attr">  rules:</span></div><div class="line"><span class="attr">  - host:</span> foo.bar.com</div><div class="line"><span class="attr">    http:</span></div><div class="line"><span class="attr">      paths:</span></div><div class="line"><span class="attr">      - backend:</span></div><div class="line"><span class="attr">          serviceName:</span> s1</div><div class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></div><div class="line"><span class="attr">  - host:</span> bar.foo.com</div><div class="line"><span class="attr">    http:</span></div><div class="line"><span class="attr">      paths:</span></div><div class="line"><span class="attr">      - backend:</span></div><div class="line"><span class="attr">          serviceName:</span> s2</div><div class="line"><span class="attr">          servicePort:</span> <span class="number">80</span></div></pre></td></tr></table></figure>
<p>注意Ingress本身并不会自动创建负载均衡器，cluster中需要运行一个ingress controller来根据Ingress的定义来管理负载均衡器。目前社区提供了nginx和gce的参考实现。</p>
<h2 id="Service-Load-Balancer"><a href="#Service-Load-Balancer" class="headerlink" title="Service Load Balancer"></a>Service Load Balancer</h2><p>在Ingress出现以前，Service Load Balancer是推荐的解决Service局限性的方式。Service Load Balancer将haproxy跑在容器中，并监控service和endpoint的变化，通过容器IP对外提供4层和7层负载均衡服务。</p>
<p>社区提供的Service Load Balancer支持四种负载均衡协议：TCP、HTTP、HTTPS和SSL TERMINATION，并支持ACL访问控制。</p>
<h2 id="Custom-Load-Balancer"><a href="#Custom-Load-Balancer" class="headerlink" title="Custom Load Balancer"></a>Custom Load Balancer</h2><p>虽然Kubernetes提供了丰富的负载均衡机制，但在实际使用的时候，还是会碰到一些复杂的场景是它不能支持的，比如</p>
<ul>
<li>接入已有的负载均衡设备</li>
<li>多租户网络情况下，容器网络和主机网络是隔离的，这样<code>kube-proxy</code>就不能正常工作</li>
</ul>
<p>这个时候就可以自定义组件，并代替kube-proxy来做负载均衡。基本的思路是监控kubernetes中service和endpoints的变化，并根据这些变化来配置负载均衡器。比如weave flux、nginx plus、kube2haproxy等</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://kubernetes.io/docs/user-guide/services/" target="_blank" rel="external">http://kubernetes.io/docs/user-guide/services/</a></li>
<li><a href="http://kubernetes.io/docs/user-guide/ingress/" target="_blank" rel="external">http://kubernetes.io/docs/user-guide/ingress/</a></li>
<li><a href="https://github.com/kubernetes/contrib/tree/master/service-loadbalancer" target="_blank" rel="external">https://github.com/kubernetes/contrib/tree/master/service-loadbalancer</a></li>
<li><a href="https://www.nginx.com/blog/load-balancing-kubernetes-services-nginx-plus/" target="_blank" rel="external">https://www.nginx.com/blog/load-balancing-kubernetes-services-nginx-plus/</a></li>
<li><a href="https://github.com/weaveworks/flux" target="_blank" rel="external">https://github.com/weaveworks/flux</a></li>
<li><a href="https://github.com/AdoHe/kube2haproxy" target="_blank" rel="external">https://github.com/AdoHe/kube2haproxy</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes在设计之初就充分考虑了针对容器的服务发现与负载均衡机制，提供了Service资源，并通过kube-proxy配合cloud provider来适应不同的应用场景。随着kubernetes用户的激增，用户场景的不断丰富，又产生了一些新的负载均衡机制。目前，
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://feisky.xyz/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>如何快速启动一个Kubernetes集群</title>
    <link href="http://feisky.xyz/2016/08/24/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AAKubernetes%E9%9B%86%E7%BE%A4/"/>
    <id>http://feisky.xyz/2016/08/24/如何快速启动一个Kubernetes集群/</id>
    <published>2016-08-24T06:48:44.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>相比Docker一个二进制文件解决所有问题，Kubernetes则为不同的服务提供了不同的二进制文件，并将一些服务放到了addons中。故而，Kubernetes的部署相对要麻烦的多。借助<a href="https://github.com/kubernetes/minikube" target="_blank" rel="external">minikube</a>项目，现在可以很方便的在本机快速启动一个单节点的Kubernetes集群。</p>
<h2 id="安装minikube"><a href="#安装minikube" class="headerlink" title="安装minikube"></a>安装minikube</h2><p>minikube最新release版本为v0.8.0，支持Kubernetes v1.3.0到v1.3.5的各个版本，默认启动Kubernetes v1.3.5。</p>
<p>OSX</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><div class="line">curl -Lo minikube https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/minikube/</span>releases<span class="regexp">/v0.8.0/mi</span>nikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span></div></pre></td></tr></table></figure>
<p>Linux</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><div class="line">curl -Lo minikube https:<span class="regexp">//</span>storage.googleapis.com<span class="regexp">/minikube/</span>releases<span class="regexp">/v0.8.0/mi</span>nikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span></div></pre></td></tr></table></figure>
<p>Windows</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><div class="line">下载http<span class="variable">s:</span>//storage.googleapis.<span class="keyword">com</span>/minikube/releases/v0.<span class="number">8.0</span>/minikube-windows-amd64.<span class="keyword">exe</span>，并重命名为minikube.<span class="keyword">exe</span></div></pre></td></tr></table></figure>
<p>minikube支持xhyve(on OSX)、VirtualBox、VMWare Fusion等多种不同的driver，这些driver也需要单独安装，比如在OSX上安装xhyve driver:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">brew install docker-machine-driver-xhyve</div><div class="line"><span class="comment"># docker-machine-driver-xhyve need root owner and uid</span></div><div class="line">sudo chown root:wheel $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve</div><div class="line">sudo chmod u+s $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve</div></pre></td></tr></table></figure>
<p>另外，还需要安装一个<code>kubectl</code>客户端，用来跟kubernetes交互：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><div class="line">gcloud components <span class="keyword">install</span> kubectl</div></pre></td></tr></table></figure>
<h2 id="启动Kubernetes-Cluster"><a href="#启动Kubernetes-Cluster" class="headerlink" title="启动Kubernetes Cluster"></a>启动Kubernetes Cluster</h2><p>启动Kubernetes Cluster就非常简单了，一个命令即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line">$ minikube <span class="keyword">start</span></div><div class="line"><span class="keyword">Starting</span> <span class="keyword">local</span> Kubernetes cluster...</div><div class="line">Kubectl <span class="keyword">is</span> <span class="keyword">now</span> configured <span class="keyword">to</span> <span class="keyword">use</span> the cluster.</div></pre></td></tr></table></figure>
<p>当然了，国内环境下，最好加上代理：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><div class="line"><span class="symbol">minikube</span> start --docker-env HTTP_PROXY<span class="symbol">=http</span>://proxy-<span class="built_in">ip</span>:port --docker-env HTTPS_PROXY<span class="symbol">=http</span>://proxy-<span class="built_in">ip</span>:port</div></pre></td></tr></table></figure>
<p>然后就可以通过kubectl来玩Kubernetes了，比如启动一个简单的nginx服务：</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><div class="line">$ kubectl run nginx <span class="comment">--image=nginx --port=80</span></div><div class="line">deployment <span class="string">"nginx"</span> created</div><div class="line">$ kubectl expose deployment nginx <span class="comment">--port=80 --type=NodePort --name=nginx-http</span></div><div class="line">service <span class="string">"nginx-http"</span> exposed</div><div class="line">$ kubectl <span class="built_in">get</span> pods</div><div class="line">NAME                     READY     STATUS    RESTARTS   AGE</div><div class="line">nginx<span class="number">-2032906785</span><span class="number">-81</span>t56   <span class="number">1</span>/<span class="number">1</span>       Running   <span class="number">0</span>          <span class="number">2</span>m</div><div class="line">$ kubectl <span class="built_in">get</span> services</div><div class="line">NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</div><div class="line">kubernetes   <span class="number">10.0</span><span class="number">.0</span><span class="number">.1</span>     &lt;<span class="literal">none</span>&gt;        <span class="number">443</span>/TCP   <span class="number">20</span>m</div><div class="line">nginx-<span class="keyword">http</span>   <span class="number">10.0</span><span class="number">.0</span><span class="number">.146</span>   &lt;<span class="literal">none</span>&gt;        <span class="number">80</span>/TCP    <span class="number">2</span>m</div><div class="line">$ minikube service nginx-<span class="keyword">http</span> <span class="comment">--url</span></div><div class="line"><span class="keyword">http</span>://<span class="number">192.168</span><span class="number">.64</span><span class="number">.10</span>:<span class="number">30569</span></div></pre></td></tr></table></figure>
<p>这样就可以通过<code>http://192.168.64.10:30569</code>来直接访问nginx服务。</p>
<p>minikube默认还部署了最新的dashboard，可以通过<code>minikube dashboard</code>命令在默认浏览器中打开：</p>
<p><img src="/images/k8s-dashboard.png" alt="k8s-dashboard"></p>
<p>更多的玩法可以参考minikube的帮助文档：</p>
<pre><code>Usage:
  minikube [command]

Available Commands:
  dashboard        Opens/displays the kubernetes dashboard URL for your local cluster
  delete           Deletes a local kubernetes cluster.
  docker-env       sets up docker env variables; similar to &#39;$(docker-machine env)&#39;
  get-k8s-versions Gets the list of available kubernetes versions available for minikube.
  ip               Retrieve the IP address of the running cluster.
  logs             Gets the logs of the running localkube instance, used for debugging minikube, not user code.
  service          Gets the kubernetes URL for the specified service in your local cluster
  ssh              Log into or run a command on a machine with SSH; similar to &#39;docker-machine ssh&#39;
  start            Starts a local kubernetes cluster.
  status           Gets the status of a local kubernetes cluster.
  stop             Stops a running local kubernetes cluster.
  version          Print the version of minikube.
</code></pre><p>更多请参考<a href="https://github.com/kubernetes/minikube。" target="_blank" rel="external">https://github.com/kubernetes/minikube。</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;相比Docker一个二进制文件解决所有问题，Kubernetes则为不同的服务提供了不同的二进制文件，并将一些服务放到了addons中。故而，Kubernetes的部署相对要麻烦的多。借助&lt;a href=&quot;https://github.com/kubernetes/mini
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
      <category term="Kubernetes" scheme="http://feisky.xyz/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Setup hyperd with flannel network</title>
    <link href="http://feisky.xyz/2016/07/19/Setup-hyperd-with-flannel-network/"/>
    <id>http://feisky.xyz/2016/07/19/Setup-hyperd-with-flannel-network/</id>
    <published>2016-07-19T07:58:26.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h1><p>Flannel is a virtual network that gives a subnet to each host for use with container runtimes.</p>
<p>Platforms like Google’s Kubernetes assume that each container (pod) has a unique, routable IP inside the cluster. The advantage of this model is that it reduces the complexity of doing port mapping.</p>
<p>flannel runs an agent, flanneld, on each host and is responsible for allocating a subnet lease out of a preconfigured address space. flannel uses etcd to store the network configuration, allocated subnets, and auxiliary data (such as host’s IP). The forwarding of packets is achieved using one of several strategies that are known as backends. The simplest backend is udp and uses a TUN device to encapsulate every IP fragment in a UDP packet, forming an overlay network. The following diagram demonstrates the path a packet takes as it traverses the overlay network:</p>
<p><img src="/images/14689151388980.jpg" alt=""></p>
<h1 id="Flannel-install"><a href="#Flannel-install" class="headerlink" title="Flannel install"></a>Flannel install</h1><p>First install etcd:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">curl -L https://github.com/coreos/etcd/releases/download/v3.0.3/etcd-v3.0.3-linux-amd64.tar.gz -o etcd-v3.0.3-linux-amd64.tar.gz</div><div class="line">tar xzvf etcd-v3.0.3-linux-amd64.tar.gz</div><div class="line">cp etcd-v3.0.3-linux-amd64/&#123;etcd,etcdctl&#125; /usr/bin</div><div class="line">rm -rf etcd-v3.0.3-linux-amd64 etcd-v3.0.3-linux-amd64.tar.gz</div></pre></td></tr></table></figure>
<p>Then, install flannel:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">curl -L https://github.com/coreos/flannel/releases/download/v0.5.5/flannel-0.5.5-linux-amd64.tar.gz -o flannel-0.5.5-linux-amd64.tar.gz</div><div class="line">tar zxvf flannel-0.5.5-linux-amd64.tar.gz</div><div class="line">cp flannel-0.5.5/flanneld /usr/bin</div><div class="line">rm -rf flannel-0.5.5*</div></pre></td></tr></table></figure>
<p>Start etcd and setup default network:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">nohup etcd --advertise-client-urls <span class="string">'http://192.168.33.10:2379'</span> --listen-client-urls <span class="string">'http://192.168.33.10:2379'</span> &amp;</div><div class="line">etcdctl --endpoints=192.168.33.10:2379 <span class="built_in">set</span> /coreos.com/network/config  <span class="string">'&#123; "Network": "172.168.0.0/16", "Backend": &#123; "Type": "vxlan", "VNI": 2000 &#125; &#125;'</span></div></pre></td></tr></table></figure>
<p>Start flanneld on all nodes:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">nohup flanneld -etcd-endpoints=http://192.168.33.10:2379 -iface=eth1 &amp;</div></pre></td></tr></table></figure>
<h1 id="Hyperd-install"><a href="#Hyperd-install" class="headerlink" title="Hyperd install"></a>Hyperd install</h1><figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">apt-get install qemu-system-x86 -y</div><div class="line">curl <span class="_">-s</span>SL http://hypercontainer.io/install | bash</div></pre></td></tr></table></figure>
<p>Configure hyperd to use subnet provided by flannel：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="built_in">source</span> /run/flannel/subnet.env</div><div class="line">brctl addbr docker0</div><div class="line">ip addr add dev docker0 <span class="variable">$&#123;FLANNEL_SUBNET&#125;</span></div><div class="line">ip link <span class="built_in">set</span> docker0 up</div><div class="line"></div><div class="line">cat &gt;/etc/hyper/config &lt;&lt;EOF</div><div class="line">Kernel=/var/lib/hyper/kernel</div><div class="line">Initrd=/var/lib/hyper/hyper-initrd.img</div><div class="line">Hypervisor=qemu</div><div class="line">StorageDriver=devicemapper</div><div class="line">Bridge=docker0</div><div class="line">BridgeIP=<span class="variable">$&#123;FLANNEL_SUBNET&#125;</span></div><div class="line">EOF</div><div class="line"></div><div class="line">nohup hyperd --nondaemon --v=3 &amp;</div></pre></td></tr></table></figure>
<h1 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h1><figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">root@s2:~<span class="comment"># hyper run -d busybox</span></div><div class="line">POD id is pod-hZviZLulsb</div><div class="line">Time to run a POD is 3648 ms</div><div class="line">root@s2:~<span class="comment"># hyper exec pod-hZviZLulsb ip addr</span></div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet6 ::1/128 scope host</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000</div><div class="line">    link/ether 52:54:51:e5:db:2f brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 172.168.12.3/24 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet6 fe80::5054:51ff:fee5:db2f/64 scope link</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line"></div><div class="line">root@s1:~<span class="comment"># hyper run -d busybox</span></div><div class="line">POD id is pod-GbccOdYKjK</div><div class="line">Time to run a POD is 3631 ms</div><div class="line">root@s1:~<span class="comment"># hyper exec pod-GbccOdYKjK ip addr</span></div><div class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div><div class="line">    inet 127.0.0.1/8 scope host lo</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet6 ::1/128 scope host</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000</div><div class="line">    link/ether 52:54:da:0c:b6:<span class="built_in">cd</span> brd ff:ff:ff:ff:ff:ff</div><div class="line">    inet 172.168.95.3/24 scope global eth0</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">    inet6 fe80::5054:daff:fe0c:b6<span class="built_in">cd</span>/64 scope link</div><div class="line">       valid_lft forever preferred_lft forever</div><div class="line">root@s1:~<span class="comment"># hyper exec pod-GbccOdYKjK ping -c3 172.168.12.3</span></div><div class="line">PING 172.168.12.3 (172.168.12.3): 56 data bytes</div><div class="line">64 bytes from 172.168.12.3: seq=0 ttl=62 time=57.400 ms</div><div class="line">64 bytes from 172.168.12.3: seq=1 ttl=62 time=6.563 ms</div><div class="line">64 bytes from 172.168.12.3: seq=2 ttl=62 time=1.580 ms</div><div class="line"></div><div class="line">--- 172.168.12.3 ping statistics ---</div><div class="line">3 packets transmitted, 3 packets received, 0% packet loss</div><div class="line">round-trip min/avg/max = 1.580/21.847/57.400 ms</div></pre></td></tr></table></figure>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a href="https://github.com/coreos/flannel" target="_blank" rel="external">https://github.com/coreos/flannel</a></li>
<li><a href="http://docs.hypercontainer.io/get_started/install/linux.html" target="_blank" rel="external">http://docs.hypercontainer.io/get_started/install/linux.html</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Flannel&quot;&gt;&lt;a href=&quot;#Flannel&quot; class=&quot;headerlink&quot; title=&quot;Flannel&quot;&gt;&lt;/a&gt;Flannel&lt;/h1&gt;&lt;p&gt;Flannel is a virtual network that gives a subnet t
    
    </summary>
    
    
      <category term="hyper" scheme="http://feisky.xyz/tags/hyper/"/>
    
      <category term="container" scheme="http://feisky.xyz/tags/container/"/>
    
      <category term="flannel" scheme="http://feisky.xyz/tags/flannel/"/>
    
  </entry>
  
  <entry>
    <title>Play with docker v1.12</title>
    <link href="http://feisky.xyz/2016/06/24/Play-with-docker-v1-12/"/>
    <id>http://feisky.xyz/2016/06/24/Play-with-docker-v1-12/</id>
    <published>2016-06-24T04:39:49.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p>
<p>Docker v1.12 brings in its integrated orchestration into docker engine.</p>
<blockquote>
<p>Starting with Docker 1.12, we have added features to the core Docker Engine to make multi-host and multi-container orchestration easy.  We’ve added new API objects, like Service and Node, that will let you use the Docker API to deploy and manage apps on a group of Docker Engines called a swarm. With Docker 1.12, the best way to orchestrate Docker is Docker!</p>
</blockquote>
<p><img src="https://cloud.githubusercontent.com/assets/676637/16327966/a4f34346-3a07-11e6-8d21-153509596cec.png" alt="docker-v1 12"></p>
<h2 id="Playing-on-GCE"><a href="#Playing-on-GCE" class="headerlink" title="Playing on GCE"></a>Playing on GCE</h2><p>Create swarm-manager:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">gcloud init</div><div class="line">docker-machine create swarm-manager --engine-install-url experimental.docker.com <span class="_">-d</span> google --google-machine-type n1-standard-1 --google-zone us-central1<span class="_">-f</span> --google-disk-size <span class="string">"500"</span> --google-tags swarm-cluster --google-project k8s-dev-prj</div></pre></td></tr></table></figure>
<p>Check what version has been installed:</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><div class="line">$ <span class="built_in">eval</span> $(docker-machine env swarm-manager)</div><div class="line">$ docker <span class="keyword">version</span></div><div class="line">Clien<span class="variable">t:</span></div><div class="line"> Version:      <span class="number">1.12</span>.<span class="number">0</span>-rc2</div><div class="line"> API <span class="keyword">version</span>:  <span class="number">1.24</span></div><div class="line"> Go <span class="keyword">version</span>:   go1.<span class="number">6.2</span></div><div class="line"> Git commi<span class="variable">t:</span>   <span class="number">906</span>eacd</div><div class="line"> Buil<span class="variable">t:</span>        Fri Jun <span class="number">17</span> <span class="number">20</span>:<span class="number">35</span>:<span class="number">33</span> <span class="number">2016</span></div><div class="line"> OS/Arch:      darwin/amd64</div><div class="line"> Experimenta<span class="variable">l:</span> true</div><div class="line"></div><div class="line">Server:</div><div class="line"> Version:      <span class="number">1.12</span>.<span class="number">0</span>-rc2</div><div class="line"> API <span class="keyword">version</span>:  <span class="number">1.24</span></div><div class="line"> Go <span class="keyword">version</span>:   go1.<span class="number">6.2</span></div><div class="line"> Git commi<span class="variable">t:</span>   <span class="number">906</span>eacd</div><div class="line"> Buil<span class="variable">t:</span>        Fri Jun <span class="number">17</span> <span class="number">21</span>:<span class="number">07</span>:<span class="number">35</span> <span class="number">2016</span></div><div class="line"> OS/Arch:      linux/amd64</div><div class="line"> Experimenta<span class="variable">l:</span> true</div></pre></td></tr></table></figure>
<p>Create worker node:</p>
<figure class="highlight haml"><table><tr><td class="code"><pre><div class="line">docker-machine create swarm-worker-1 \</div><div class="line">    -<span class="ruby">-engine-install-url experimental.docker.com \</span></div><div class="line">    -<span class="ruby">d google \</span></div><div class="line">    -<span class="ruby">-google-machine-type n1-standard-<span class="number">1</span> \</span></div><div class="line">    -<span class="ruby">-google-zone us-central1-f \</span></div><div class="line">    -<span class="ruby">-google-disk-size <span class="string">"500"</span> \</span></div><div class="line">    -<span class="ruby">-google-tags swarm-cluster \</span></div><div class="line">    -<span class="ruby">-google-project k8s-dev-prj</span></div></pre></td></tr></table></figure>
<p>Initialize swarm</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="comment"># init manager</span></div><div class="line"><span class="built_in">eval</span> $(docker-machine env swarm-manager)</div><div class="line">docker swarm init</div></pre></td></tr></table></figure>
<blockquote>
<p>Under the hood this creates a Raft consensus group of one node.  This first node has the role of manager, meaning it accepts commands and schedule tasks.  As you join more nodes to the swarm, they will by default be workers, which simply execute containers dispatched by the manager.  You can optionally add additional manager nodes.  The manager nodes will be part of the Raft consensus group. We use an optimized Raft store in which reads are serviced directly from memory which makes scheduling performance fast.</p>
</blockquote>
<figure class="highlight mel"><table><tr><td class="code"><pre><div class="line"># join worker</div><div class="line"><span class="keyword">eval</span> $(docker-machine <span class="keyword">env</span> swarm-worker<span class="number">-1</span>)</div><div class="line">manager_ip=$(gcloud compute instances list | awk <span class="string">'/swarm-manager/&#123;print $4&#125;'</span>)</div><div class="line">docker swarm join $&#123;manager_ip&#125;:<span class="number">2377</span></div></pre></td></tr></table></figure>
<p>List all nodes:</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><div class="line">$ eval $(docker-machine env swarm-manager)</div><div class="line">$ docker <span class="keyword">node</span> <span class="title">ls</span></div><div class="line">ID                           NAME            MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS</div><div class="line"><span class="number">0m</span>2qy40ch1nqfpmhnsvj8jzch *  swarm-manager   Accepted    Ready   Active        Leader</div><div class="line"><span class="number">4</span>v1oo055unqiz9fy14u8wg3fn    swarm-worker-<span class="number">1</span>  Accepted    Ready   Active</div></pre></td></tr></table></figure>
<h2 id="Playing-with-service"><a href="#Playing-with-service" class="headerlink" title="Playing with service"></a>Playing with service</h2><figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="built_in">eval</span> $(docker-machine env swarm-manager)</div><div class="line">docker service create --replicas 2 -p 80:80/tcp --name nginx nginx</div></pre></td></tr></table></figure>
<blockquote>
<p>This command declares a desired state on your swarm of 2 nginx containers, reachable as a single, internally load balanced service on port 80 of any node in your swarm.  Internally, we make this work using Linux IPVS, an in-kernel Layer 4 multi-protocol load balancer that’s been in the Linux kernel for more than 15 years.  With IPVS routing packets inside the kernel, swarm’s routing mesh delivers high performance container-aware load-balancing.</p>
<p>When you create services, can optionally create replicated or global services.  Replicated services mean any number of containers that you define will be spread across the available hosts.  Global services, by contrast, schedule one instance the same container on every host in the swarm.</p>
<p>Let’s turn to how Docker provides resiliency.  Swarm mode enabled engines are self-healing, meaning that they are aware of the application you defined and will continuously check and reconcile the environment when things go awry.  For example, if you unplug one of the machines running an nginx instance, a new container will come up on another node.  Unplug the network switch for half the machines in your swarm, and the other half will take over, redistributing the containers amongst themselves.  For updates, you now have flexibility in how you re-deploy services once you make a change. You can set a rolling or parallel update of the containers on your swarm.</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">docker service scale nginx=3</div><div class="line"></div><div class="line">$ docker ps</div><div class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</div><div class="line">b51a902db8bc        nginx:latest        <span class="string">"nginx -g 'daemon off"</span>   2 minutes ago       Up 2 minutes        80/tcp, 443/tcp     nginx.1.8yvwxbquvz1ptuqsc8hewwbau</div></pre></td></tr></table></figure>
<figure class="highlight vbscript"><table><tr><td class="code"><pre><div class="line"># switch <span class="keyword">to</span> worker</div><div class="line">$ <span class="built_in">eval</span> $(docker-machine env swarm-worker<span class="number">-1</span>)</div><div class="line">$ docker ps</div><div class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES</div><div class="line">da6a8250bef4        nginx:latest        <span class="string">"nginx -g 'daemon off"</span>   About a <span class="built_in">minute</span> ago   Up About a <span class="built_in">minute</span>   <span class="number">80</span>/tcp, <span class="number">443</span>/tcp     nginx<span class="number">.2</span>.bqko7fyj1nowwj1flxva3ur0g</div><div class="line"><span class="number">54</span>d9ffd07894        nginx:latest        <span class="string">"nginx -g 'daemon off"</span>   About a <span class="built_in">minute</span> ago   Up About a <span class="built_in">minute</span>   <span class="number">80</span>/tcp, <span class="number">443</span>/tcp     nginx<span class="number">.3</span><span class="number">.02</span>k4d34gjooa9f8m6yhfi5hyu</div></pre></td></tr></table></figure>
<p>As seen above, one container runs on swarm-manager, and the others run on swarm-worker-1.</p>
<h2 id="Expose-services"><a href="#Expose-services" class="headerlink" title="Expose services"></a>Expose services</h2><h3 id="Visit-by-node-node-ip"><a href="#Visit-by-node-node-ip" class="headerlink" title="Visit by node node ip"></a>Visit by node node ip</h3><figure class="highlight haml"><table><tr><td class="code"><pre><div class="line">gcloud compute firewall-rules create nginx-swarm \</div><div class="line">  -<span class="ruby">-allow <span class="symbol">tcp:</span><span class="number">80</span> \</span></div><div class="line">  -<span class="ruby">-description <span class="string">"nginx swarm service"</span> \</span></div><div class="line">  -<span class="ruby">-target-tags swarm-cluster</span></div></pre></td></tr></table></figure>
<p>Then use external IP (get by exec <code>gcloud compute instances list</code>) to visit nginx service.</p>
<h3 id="GCP-Load-Balancer-tcp"><a href="#GCP-Load-Balancer-tcp" class="headerlink" title="GCP Load Balancer (tcp)"></a>GCP Load Balancer (tcp)</h3><figure class="highlight sql"><table><tr><td class="code"><pre><div class="line">gcloud compute addresses <span class="keyword">create</span> network-lb-ip<span class="number">-1</span> <span class="comment">--region us-central1</span></div><div class="line">gcloud <span class="keyword">compute</span> <span class="keyword">http</span>-health-checks <span class="keyword">create</span> basic-<span class="keyword">check</span></div><div class="line">gcloud <span class="keyword">compute</span> target-pools <span class="keyword">create</span> www-pool <span class="comment">--region us-central1 --health-check basic-check</span></div><div class="line">gcloud <span class="keyword">compute</span> target-pools <span class="keyword">add</span>-instances www-pool <span class="comment">--instances swarm-manager,swarm-worker-1 --zone us-central1-f</span></div><div class="line"></div><div class="line"># <span class="keyword">Get</span> lb addresses</div><div class="line">STATIC_EXTERNAL_IP=$(gcloud <span class="keyword">compute</span> addresses <span class="keyword">list</span> | awk <span class="string">'/network-lb-ip-1/&#123;print $3&#125;'</span>)</div><div class="line"># <span class="keyword">create</span> forwarding <span class="keyword">rules</span></div><div class="line">gcloud <span class="keyword">compute</span> forwarding-<span class="keyword">rules</span> <span class="keyword">create</span> www-rule <span class="comment">--region us-central1 --port-range 80 --address $&#123;STATIC_EXTERNAL_IP&#125; --target-pool www-pool</span></div></pre></td></tr></table></figure>
<p>Now you could visit <a href="http://${STATIC_EXTERNAL_IP}" target="_blank" rel="external">http://${STATIC_EXTERNAL_IP}</a> for nginx service.</p>
<p>BTW, <a href="https://blog.docker.com/2016/06/azure-aws-beta/" target="_blank" rel="external">Docker for aws and azure</a> will do this more easily as integrated:</p>
<ul>
<li>Use an SSH key already associated with your IaaS account for access control</li>
<li>Provision infrastructure load balancers and update them dynamically as apps are created and updated</li>
<li>Configure security groups and virtual networks to create secure Docker setups that are easy for operations to understand and manage</li>
</ul>
<blockquote>
<p>By default, apps deployed with bundles do not have ports publicly exposed. Update port mappings for services, and Docker will automatically wire up the underlying platform loadbalancers:<code>docker service update -p 80:80 &lt;example-service&gt;</code></p>
</blockquote>
<h3 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h3><h4 id="Local-networking"><a href="#Local-networking" class="headerlink" title="Local networking"></a>Local networking</h4><p><img width="1239" alt="2016-06-24 12 05 13" src="https://cloud.githubusercontent.com/assets/676637/16327964/9dfd842a-3a07-11e6-9031-c79c9c43ec83.png"></p>
<p>Create local scope network and place containers in existing vlans:</p>
<figure class="highlight lsl"><table><tr><td class="code"><pre><div class="line">docker network create -d macvlan --subnet=<span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">16</span> --ip-range=<span class="number">192.168</span><span class="number">.41</span><span class="number">.0</span>/<span class="number">24</span> --aux-address=<span class="string">"favoriate_ip_ever=192.168.41.2"</span> --gateway=<span class="number">192.168</span><span class="number">.41</span><span class="number">.1</span> -o parent=eth0<span class="number">.41</span> macnet41</div><div class="line">docker run --net=macnet41 -it --rm alpine /bin/sh</div></pre></td></tr></table></figure>
<h4 id="Multi-host-networking"><a href="#Multi-host-networking" class="headerlink" title="Multi-host networking"></a>Multi-host networking</h4><p>A typical two-tier (web+db) application runs on swarm scope network would be created like this:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line">docker network <span class="keyword">create</span> -d overlay mynet</div><div class="line">docker service <span class="keyword">create</span> –<span class="keyword">name</span> frontend –replicas <span class="number">5</span> -p <span class="number">80</span>:<span class="number">80</span>/tcp –network mynet mywebapp</div><div class="line">docker service <span class="keyword">create</span> –<span class="keyword">name</span> redis –network mynet redis:latest</div></pre></td></tr></table></figure>
<p><img width="1133" alt="2016-06-26 10 27 20" src="https://cloud.githubusercontent.com/assets/676637/16362920/7dbd339e-3bed-11e6-9987-8d425480ba59.png"></p>
<p><img width="1169" alt="2016-06-24 12 05 30" src="https://cloud.githubusercontent.com/assets/676637/16327980/c4af9432-3a07-11e6-93ed-9e94d12f0c9b.png"><br><img width="1228" alt="2016-06-24 12 05 58" src="https://cloud.githubusercontent.com/assets/676637/16327982/c4b2a906-3a07-11e6-8e97-70a26c5fc701.png"><br><img width="1235" alt="2016-06-24 12 06 11" src="https://cloud.githubusercontent.com/assets/676637/16327981/c4b14fc0-3a07-11e6-84f0-260a716044cb.png"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Docker v1.12 indeeds introduced easy-of-use interface for orchestrating containers, but I’m concerned whether this way could scale for large clusters. Maybe we could see it on Docker’s further iterations.</p>
<h3 id="Further-more"><a href="#Further-more" class="headerlink" title="Further more"></a>Further more</h3><ul>
<li><a href="https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/" target="_blank" rel="external">https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/</a></li>
<li><a href="http://www.slideshare.net/MadhuVenugopal2/dockercon-us-2016-docker-networking-deep-dive" target="_blank" rel="external">http://www.slideshare.net/MadhuVenugopal2/dockercon-us-2016-docker-networking-deep-dive</a></li>
<li><a href="https://medium.com/google-cloud/docker-swarm-on-google-cloud-platform-c9925bd7863c#.3plkwmxss" target="_blank" rel="external">https://medium.com/google-cloud/docker-swarm-on-google-cloud-platform-c9925bd7863c#.3plkwmxss</a></li>
<li><a href="https://beta.docker.com/docs/" target="_blank" rel="external">https://beta.docker.com/docs/</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;Docker v1.12 brings in its integrated orchestration into docker engine.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Starting with Docker 1.12, we ha
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Playing docker with hypervisor container runtime runV</title>
    <link href="http://feisky.xyz/2016/06/17/Playing-docker-with-hypervisor-container-runtime-runV/"/>
    <id>http://feisky.xyz/2016/06/17/Playing-docker-with-hypervisor-container-runtime-runV/</id>
    <published>2016-06-17T09:12:38.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>Table of contents:</p>
<p>[TOC]</p>
<hr>
<p>The latest master branch of <a href="https://github.com/hyperhq/runv" target="_blank" rel="external">runV</a> has already supported running as an runtime in docker. Since v1.11, docker introduced OCI contain runtime (runc) integration via containerd. Since runc and runV are both <a href="https://github.com/opencontainers/runtime-spec/blob/master/implementations.md" target="_blank" rel="external">recommended implementation of OCI</a>, it is natural to make runV working with containerd. </p>
<p>Now let’s have a try.</p>
<h3 id="Install-runv-and-docker"><a href="#Install-runv-and-docker" class="headerlink" title="Install runv and docker"></a>Install runv and docker</h3><p>Docker could be installed via <a href="https://docs.docker.com/engine/installation/" target="_blank" rel="external">https://docs.docker.com/engine/installation/</a>.</p>
<p>Since only master branch of runV supports running integrated with docker, we should compile runV by source.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">sudo apt-get install -y autoconf automake pkg-config libdevmapper-dev libsqlite3-dev libvirt-dev qemu libvirt-bin</div><div class="line">mkdir -p <span class="variable">$GOPATH</span>/src/github.com/hyperhq</div><div class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/hyperhq</div><div class="line">git <span class="built_in">clone</span> https://github.com/hyperhq/runv</div><div class="line"><span class="built_in">cd</span> runv</div><div class="line">./autogen.sh</div><div class="line">./configure</div><div class="line">make</div><div class="line">make install</div></pre></td></tr></table></figure>
<h3 id="Start-docker-with-runV-runtime"><a href="#Start-docker-with-runV-runtime" class="headerlink" title="Start docker with runV runtime"></a>Start docker with runV runtime</h3><p>Stop docker first since it is running with runc by default.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">systemctl stop docker</div></pre></td></tr></table></figure>
<p>Now start docker with runV:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="comment"># start containerd</span></div><div class="line">systemd-run --unit=containerd-runv docker-containerd --debug <span class="_">-l</span> /var/run/docker/libcontainerd/docker-containerd.sock --runtime /usr/<span class="built_in">local</span>/bin/runv --runtime-args --debug --runtime-args --driver=libvirt --runtime-args --kernel=/var/lib/hyper/kernel --runtime-args --initrd=/var/lib/hyper/hyper-initrd.img --start-timeout 2m</div><div class="line"></div><div class="line"><span class="comment"># start docker</span></div><div class="line">systemd-run --unit=docker-runv docker daemon -D <span class="_">-l</span> debug --containerd=/var/run/docker/libcontainerd/docker-containerd.sock</div><div class="line"></div><div class="line"><span class="comment"># check status</span></div><div class="line">[root@linux ~]<span class="comment"># systemctl status containerd-runv</span></div><div class="line">● containerd-runv.service - /usr/bin/docker-containerd --debug <span class="_">-l</span> /var/run/docker/libcontainerd/docker-containerd.sock --runtime /usr/<span class="built_in">local</span>/bin/runv --runtime-args --debug --runtime-args --driver=libvirt --runtime-args --kernel=/var/lib/hyper/kernel --runtime-args --initrd=/var/lib/hyper/hyper-initrd.img --start-timeout 2m</div><div class="line">   Loaded: loaded (/run/systemd/system/containerd-runv.service; static; vendor preset: disabled)</div><div class="line">  Drop-In: /run/systemd/system/containerd-runv.service.d</div><div class="line">           └─50-Description.conf, 50-ExecStart.conf</div><div class="line">   Active: active (running) since 五 2016-06-17 09:47:57 UTC; 10s ago</div><div class="line"> Main PID: 12650 (docker-containe)</div><div class="line">   Memory: 1.8M</div><div class="line">   CGroup: /system.slice/containerd-runv.service</div><div class="line">           └─12650 /usr/bin/docker-containerd --debug <span class="_">-l</span> /var/run/docker/libcontainerd/docker-containerd.sock --run...</div><div class="line"></div><div class="line">6月 17 09:47:57 linux systemd[1]: Started /usr/bin/docker-containerd --debug <span class="_">-l</span> /var/run/docker/libcontainerd/docker...</div><div class="line">6月 17 09:47:57 linux systemd[1]: Starting /usr/bin/docker-containerd --debug <span class="_">-l</span> /var/run/docker/libcontainerd/docke...</div><div class="line">6月 17 09:47:57 linux docker-containerd[12650]: time=<span class="string">"2016-06-17T09:47:57Z"</span> level=warning msg=<span class="string">"containerd: low ...=4096</span></div><div class="line">6月 17 09:47:57 linux docker-containerd[12650]: time="2016-06-17T09:47:57Z<span class="string">" level=debug msg="</span>containerd: <span class="built_in">read</span> p...unt=0</div><div class="line">6月 17 09:47:57 linux docker-containerd[12650]: time=<span class="string">"2016-06-17T09:47:57Z"</span> level=debug msg=<span class="string">"containerd: superv...nerd"</span></div><div class="line">6月 17 09:47:57 linux docker-containerd[12650]: time=<span class="string">"2016-06-17T09:47:57Z"</span> level=debug msg=<span class="string">"containerd: grpc a...sock"</span></div><div class="line">Hint: Some lines were ellipsized, use <span class="_">-l</span> to show <span class="keyword">in</span> full.</div><div class="line"></div><div class="line">[root@linux ~]<span class="comment"># systemctl status docker-runv</span></div><div class="line">● docker-runv.service - /usr/bin/docker daemon -D <span class="_">-l</span> debug --containerd=/var/run/docker/libcontainerd/docker-containerd.sock</div><div class="line">   Loaded: loaded (/run/systemd/system/docker-runv.service; static; vendor preset: disabled)</div><div class="line">  Drop-In: /run/systemd/system/docker-runv.service.d</div><div class="line">           └─50-Description.conf, 50-ExecStart.conf</div><div class="line">   Active: active (running) since 五 2016-06-17 09:34:11 UTC; 25s ago</div><div class="line"> Main PID: 11120 (docker)</div><div class="line">   Memory: 20.8M</div><div class="line">   CGroup: /system.slice/docker-runv.service</div><div class="line">           └─11120 /usr/bin/docker daemon -D <span class="_">-l</span> debug --containerd=/var/run/docker/libcontainerd/docker-containerd.sock</div><div class="line"></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019309548Z"</span> level=debug msg=<span class="string">"Registering POST, /volumes/create"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019448115Z"</span> level=debug msg=<span class="string">"Registering DELETE, /volumes/&#123;name:.*&#125;"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019551244Z"</span> level=debug msg=<span class="string">"Registering POST, /build"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019607895Z"</span> level=debug msg=<span class="string">"Registering GET, /networks"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019675700Z"</span> level=debug msg=<span class="string">"Registering GET, /networks/&#123;id:.*&#125;"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.019771551Z"</span> level=debug msg=<span class="string">"Registering POST, /networks/create"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.020256142Z"</span> level=debug msg=<span class="string">"Registering POST, /networks/&#123;id:.*&#125;/connect"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.020369131Z"</span> level=debug msg=<span class="string">"Registering POST, /networks/&#123;id:.*&#125;/disconnect"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.020463042Z"</span> level=debug msg=<span class="string">"Registering DELETE, /networks/&#123;id:.*&#125;"</span></div><div class="line">6月 17 09:34:13 linux docker[11120]: time=<span class="string">"2016-06-17T09:34:13.021491071Z"</span> level=info msg=<span class="string">"API listen on /var/run/docker.sock"</span></div></pre></td></tr></table></figure>
<h3 id="Create-container"><a href="#Create-container" class="headerlink" title="Create container"></a>Create container</h3><p>Let’s create a nginx container.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">[root@linux ~]<span class="comment"># docker run -i -d  nginx</span></div><div class="line">6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c</div><div class="line">[root@linux ~]<span class="comment"># docker ps</span></div><div class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</div><div class="line">6a34a0513ebb        nginx               <span class="string">"nginx -g 'daemon off"</span>   9 seconds ago       Up 3 seconds        80/tcp, 443/tcp     berserk_mcnulty</div><div class="line"></div><div class="line"><span class="comment"># Is it working</span></div><div class="line">[root@linux ~]<span class="comment"># docker inspect --format '&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;' 6a34a0513ebb</span></div><div class="line">172.17.0.2</div><div class="line">[root@linux ~]<span class="comment"># curl -I 172.17.0.2</span></div><div class="line">HTTP/1.1 200 OK</div><div class="line">Server: nginx/1.11.1</div><div class="line">Date: Fri, 17 Jun 2016 09:52:37 GMT</div><div class="line">Content-Type: text/html</div><div class="line">Content-Length: 612</div><div class="line">Last-Modified: Tue, 31 May 2016 14:40:22 GMT</div><div class="line">Connection: keep-alive</div><div class="line">ETag: <span class="string">"574da256-264"</span></div><div class="line">Accept-Ranges: bytes</div></pre></td></tr></table></figure>
<p>Is the container really running in runV with hypervisor?</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">root@linux ~]<span class="comment"># runv list</span></div><div class="line">ID                                                                 PID         STATUS      BUNDLE                                                                                           CREATED</div><div class="line">6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c   12756       running     /var/run/docker/libcontainerd/6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c   2016-06-17T09:48:38.324839156Z</div><div class="line"></div><div class="line">[root@linux ~]<span class="comment"># runv state 6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c</span></div><div class="line">&#123;</div><div class="line">  <span class="string">"ociVersion"</span>: <span class="string">"0.6.0-dev"</span>,</div><div class="line">  <span class="string">"id"</span>: <span class="string">"6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c"</span>,</div><div class="line">  <span class="string">"pid"</span>: 12756,</div><div class="line">  <span class="string">"bundlePath"</span>: <span class="string">"/var/run/docker/libcontainerd/6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c"</span>,</div><div class="line">  <span class="string">"rootfsPath"</span>: <span class="string">"/var/run/docker/libcontainerd/6a34a0513ebbdb2c57d828bf4e814773c8a5cf6af8c35e4376f2028769a7c35c/rootfs"</span>,</div><div class="line">  <span class="string">"status"</span>: <span class="string">"running"</span>,</div><div class="line">  <span class="string">"created"</span>: <span class="string">"2016-06-17T09:48:38.324839156Z"</span></div><div class="line">&#125;</div><div class="line"></div><div class="line">[root@linux ~]<span class="comment"># virsh list</span></div><div class="line"> Id    名称                         状态</div><div class="line">----------------------------------------------------</div><div class="line"> 919   vm-CeaKLvbPEg                  running</div><div class="line"></div><div class="line">[root@linux ~]<span class="comment"># ps -ef | grep vm-CeaKLvbPEg | grep -v grep</span></div><div class="line">root     12743     1  1 09:48 ?        00:00:06 /usr/bin/qemu-system-x86_64 -name vm-CeaKLvbPEg -S -machine pc-i440fx-2.0,accel=tcg,usb=off -cpu Haswell-noTSX,+abm,+hypervisor,+rdrand,+f16c,+osxsave,+ht,+vme -m 128 -realtime mlock=off -smp 1,sockets=1,cores=1,threads=1 -uuid 4f158103-bd5e-4fd1<span class="_">-a</span>62f-9e18093ceaf4 -nographic -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/domain-vm-CeaKLvbPEg/monitor.sock,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-reboot -boot strict=on -kernel /var/lib/hyper/kernel -initrd /var/lib/hyper/hyper-initrd.img -append console=ttyS0 panic=1 no_timer_check -device virtio-scsi-pci,id=scsi0,bus=pci.0,addr=0x3 -device virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x2 -fsdev <span class="built_in">local</span>,security_model=none,id=fsdev-fs0,path=/var/run/hyper/vm-CeaKLvbPEg/share_dir -device virtio-9p-pci,id=fs0,fsdev=fsdev-fs0,mount_tag=share_dir,bus=pci.0,addr=0x4 -chardev socket,id=charserial0,path=/var/run/hyper/vm-CeaKLvbPEg/console.sock,server,nowait -device isa-serial,chardev=charserial0,id=serial0 -chardev socket,id=charchannel0,path=/var/run/hyper/vm-CeaKLvbPEg/hyper.sock,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=sh.hyper.channel.0 -chardev socket,id=charchannel1,path=/var/run/hyper/vm-CeaKLvbPEg/tty.sock,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=2,chardev=charchannel1,id=channel1,name=sh.hyper.channel.1 -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5 -msg timestamp=on</div></pre></td></tr></table></figure>
<h3 id="Is-it-stable"><a href="#Is-it-stable" class="headerlink" title="Is it stable?"></a>Is it stable?</h3><p>Of course not, runV is still under quick development and features are not complete now. For example, there are a lot of commands not supported now:</p>
<ul>
<li><code>docker stop</code></li>
<li><code>docker stats</code></li>
<li><code>docker exec</code></li>
</ul>
<p>Although there are still problems, I’m exited by what runV has done. Looking forward to its release.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Table of contents:&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;The latest master branch of &lt;a href=&quot;https://github.com/hyperhq/runv&quot; target=&quot;_blank&quot; rel=&quot;ex
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
      <category term="runV" scheme="http://feisky.xyz/tags/runV/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes-mesos architecture</title>
    <link href="http://feisky.xyz/2016/06/07/Kubernetes-mesos-architecture/"/>
    <id>http://feisky.xyz/2016/06/07/Kubernetes-mesos-architecture/</id>
    <published>2016-06-07T05:21:07.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/kubernetes_mesos_architecture.png" alt=""></p>
<p>From <a href="http://cdn.yongbok.net/ruo91/architecture/k8s/kubernetes_mesos_architecture_v1.x.png" target="_blank" rel="external">http://cdn.yongbok.net/ruo91/architecture/k8s/kubernetes_mesos_architecture_v1.x.png</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;/images/kubernetes_mesos_architecture.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;From &lt;a href=&quot;http://cdn.yongbok.net/ruo91/architecture/k8s/kubernete
    
    </summary>
    
    
      <category term="mesos" scheme="http://feisky.xyz/tags/mesos/"/>
    
      <category term="kubernetes" scheme="http://feisky.xyz/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Hypernetes: Bringing Security and Multi-tenancy to Kubernetes</title>
    <link href="http://feisky.xyz/2016/06/06/Hypernetes-Bringing-Security-and-Multi-tenancy-to-Kubernetes/"/>
    <id>http://feisky.xyz/2016/06/06/Hypernetes-Bringing-Security-and-Multi-tenancy-to-Kubernetes/</id>
    <published>2016-06-06T08:10:25.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>Notes: this post is copied from <a href="http://blog.kubernetes.io/2016/05/hypernetes-security-and-multi-tenancy-in-kubernetes.html" target="_blank" rel="external">http://blog.kubernetes.io/2016/05/hypernetes-security-and-multi-tenancy-in-kubernetes.html</a>.</p>
</blockquote>
<p><em>Today’s guest post is written by Harry Zhang and Pengfei Ni, engineers at HyperHQ, describing a new hypervisor based container called HyperContainer</em>  </p>
<p>While many developers and security professionals are comfortable with Linux containers as an effective boundary, many users need a stronger degree of isolation, particularly for those running in a multi-tenant environment. Sadly, today, those users are forced to run their containers inside virtual machines, even one VM per container.  </p>
<p>Unfortunately, this results in the loss of many of the benefits of a cloud-native deployment: slow startup time of VMs; a memory tax for every container; low utilization resulting in wasting resources.  </p>
<p>In this post, we will introduce HyperContainer, a hypervisor based container and see how it naturally fits into the Kubernetes design, and enables users to serve their customers directly with virtualized containers, instead of wrapping them inside of full blown VMs.  </p>
<p><strong>HyperContainer</strong>  </p>
<p><a href="http://hypercontainer.io/" target="_blank" rel="external">HyperContainer</a> is a hypervisor-based container, which allows you to launch Docker images with standard hypervisors (KVM, Xen, etc.). As an open-source project, HyperContainer consists of an <a href="https://github.com/opencontainers/runtime-spec" target="_blank" rel="external">OCI</a> compatible runtime implementation, named <a href="https://github.com/hyperhq/runv/" target="_blank" rel="external">runV</a>, and a management daemon named <a href="https://github.com/hyperhq/hyperd" target="_blank" rel="external">hyperd</a>. The idea behind HyperContainer is quite straightforward: to combine the best of both virtualization and container.  </p>
<p>We can consider containers as two parts (as Kubernetes does). The first part is the container runtime, where HyperContainer uses virtualization to achieve execution isolation and resource limitation instead of namespaces and cgroups. The second part is the application data, where HyperContainer leverages Docker images. So in HyperContainer, virtualization technology makes it possible to build a fully isolated sandbox with an independent guest kernel (so things like <code>top</code> and /proc all work), but from developer’s view, it’s portable and behaves like a standard container.  </p>
<p><strong>HyperContainer as Pod</strong>  </p>
<p>The interesting part of HyperContainer is not only that it is secure enough for multi-tenant environments (such as a public cloud), but also how well it fits into the Kubernetes philosophy.  </p>
<p>One of the most important concepts in Kubernetes is Pods. The design of Pods is a lesson learned (<a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/43438.pdf" target="_blank" rel="external">Borg paper section 8.1</a>) from real world workloads, where in many cases people want an atomic scheduling unit composed of multiple containers (please check this <a href="https://github.com/kubernetes/kubernetes/tree/master/examples/javaweb-tomcat-sidecar" target="_blank" rel="external">example</a> for further information). In the context of Linux containers, a Pod wraps and encapsulates several containers into a logical group. But in HyperContainer, the hypervisor serves as a natural boundary, and Pods are introduced as first-class objects:  </p>
<p><img src="https://lh6.googleusercontent.com/8DjNb9IE0HjinFxkaoGbPaaKbts5_Osbj-8NVWQMgY_8D32643Aum0SaMc2OedV2gECG3EXov8qj_f8XDe0IfpptZt61HxfJEonLo3RA5xkr5zSmd2nxqVc8yESc423nPEZTj1H3" alt=""></p>
<p>HyperContainer wraps a Pod of light-weight application containers and exposes the container interface at Pod level. Inside the Pod, a minimalist Linux kernel called HyperKernel is booted. This HyperKernel is built with a tiny Init service called HyperStart. It will act as the PID 1 process and creates the Pod, setup Mount namespace, and launch apps from the loaded images. </p>
<p>This model works nicely with Kubernetes. The integration of HyperContainer with Kubernetes, as we indicated in the title, is what makes up the <a href="https://github.com/hyperhq/hypernetes" target="_blank" rel="external">Hypernetes</a> project. </p>
<p><strong>Hypernetes</strong></p>
<p>One of the best parts of Kubernetes is that it is designed to support multiple container runtimes, meaning users are not locked-in to a single vendor. We are very pleased to announce that we have already begun working with the Kubernetes team to integrate HyperContainer into Kubernetes upstream. This integration involves:</p>
<ol>
<li>container runtime optimizing and refactoring</li>
<li>new client-server mode runtime interface</li>
<li>containerd integration to support runV</li>
</ol>
<p>The OCI standard and kubelet’s multiple runtime architecture make this integration much easier even though HyperContainer is not based on Linux container technology stack.</p>
<p>On the other hand, in order to run HyperContainers in multi-tenant environment, we also created a new network plugin and modified an existing volume plugin. Since Hypernetes runs Pod as their own VMs, it can make use of your existing IaaS layer technologies for multi-tenant network and persistent volumes. The current Hypernetes implementation uses standard Openstack components.</p>
<p>Below we go into further details about how all those above are implemented.</p>
<p><strong>Identity and Authentication</strong></p>
<hr>
<p>In Hypernetes we chose <a href="http://docs.openstack.org/developer/keystone/" target="_blank" rel="external">Keystone</a> to manage different tenants and perform identification and authentication for tenants during any administrative operation. Since Keystone comes from the OpenStack ecosystem, it works seamlessly with the network and storage plugins we used in Hypernetes.</p>
<p><strong>Multi-tenant Network Model</strong></p>
<p>For a multi-tenant container cluster, each tenant needs to have strong network isolation from each other tenant. In Hypernetes, each tenant has its own Network. Instead of configuring a new network using OpenStack, which is complex, with Hypernetes, you just create a Network object like below.  </p>
<p>apiVersion: v1  kind: Network  metadata:    name: net1  spec:    tenantID: 065f210a2ca9442aad898ab129426350    subnets:      subnet1:        cidr: 192.168.0.0/24        gateway: 192.168.0.1</p>
<p>Note that the tenantID is supplied by Keystone. This yaml will automatically create a new Neutron network with a default router and a subnet 192.168.0.0/24. </p>
<p>A Network controller will be responsible for the life-cycle management of any Network instance created by the user. This Network can be assigned to one or more Namespaces, and any Pods belonging to the same Network can reach each other directly through IP address.  </p>
<p>apiVersion: v1  kind: Namespace  metadata:    name: ns1  spec:    network: net1  </p>
<p>If a Namespace does not have a Network spec, it will use the default Kubernetes network model instead, including the default kube-proxy. So if a user creates a Pod in a Namespace with an associated Network, Hypernetes will follow the <a href="http://kubernetes.io/docs/admin/network-plugins/" target="_blank" rel="external">Kubernetes Network Plugin Model</a> to set up a Neutron network for this Pod. Here is a high level example:</p>
<p><img src="https://lh4.googleusercontent.com/ij88fHWT3wDSxDh4W7S0sARfjdRd5oTJTZGT_r8oQoqoGGjZWmHLJtPG8TT3U_tZ2rFqK7lwK56l3UIq3csSUxSdgGvfzORaAEAkl9fChxiLzVgz-mExTMi8sxUlfsesS59G0Fsa" alt="A Hypernetes Network Workflow.png"></p>
<p>Hypernetes uses a standalone gRPC handler named kubestack to translate the Kubernetes Pod request into the Neutron network API. Moreover, kubestack is also responsible for handling another important networking feature: a multi-tenant Service proxy.</p>
<p>In a multi-tenant environment, the default iptables-based kube-proxy can not reach the individual Pods, because they are isolated into different networks. Instead, Hypernetes uses a <a href="https://github.com/hyperhq/hyperd/blob/2072dd8e28a02a25ae6a819f81029b47a579e683/servicediscovery/servicediscovery.go" target="_blank" rel="external">built-in HAproxy in every HyperContainer</a> as the portal. This HAproxy will proxy all the Service instances in the namespace of that Pod. Kube-proxy will be responsible for updating these backend servers by following the standard OnServiceUpdate and OnEndpointsUpdate processes, so that users will not notice any difference. A downside of this method is that HAproxy has to listen to some specific ports which may conflicts with user’s containers.That’s why we are planning to use LVS to replace this proxy in the next release.</p>
<p>With the help of the Neutron based network plugin, the Hypernetes Service is able to provide an OpenStack load balancer, just like how the “external” load balancer does on GCE. When user creates a Service with external IPs, an OpenStack load balancer will be created and endpoints will be automatically updated through the kubestack workflow above.</p>
<p><strong>Persistent Storage</strong></p>
<p>When considering storage, we are actually building a tenant-aware persistent volume in Kubernetes. The reason we decided not to use existing Cinder volume plugin of Kubernetes is that its model does not work in the virtualization case. Specifically:</p>
<p>The Cinder volume plugin requires OpenStack as the Kubernetes provider.</p>
<p>The OpenStack provider will find on which VM the target Pod is running on</p>
<p>Cinder volume plugin will mount a Cinder volume to a path inside the host VM of Kubernetes.</p>
<p>The kubelet will bind mount this path as a volume into containers of target Pod.</p>
<p>But in Hypernetes, things become much simpler. Thanks to the physical boundary of Pods, HyperContainer can mount Cinder volumes directly as block devices into Pods, just like a normal VM. This mechanism eliminates extra time to query Nova to find out the VM of target Pod in the existing Cinder volume workflow listed above.</p>
<p>The current implementation of the Cinder plugin in Hypernetes is based on Ceph RBD backend, and it works the same as all other Kubernetes volume plugins, one just needs to remember to create the Cinder volume (referenced by volumeID below) beforehand.  </p>
<p>apiVersion: v1  kind: Pod  metadata:    name: nginx    labels:      app: nginx  spec:    containers:    - name: nginx      image: nginx      ports:      - containerPort: 80      volumeMounts:      - name: nginx-persistent-storage        mountPath: /var/lib/nginx    volumes:    - name: nginx-persistent-storage      cinder:        volumeID: 651b2a7b-683e-47e1-bdd6-e3c62e8f91c0        fsType: ext4  </p>
<p>So when the user provides a Pod yaml with a Cinder volume, Hypernetes will check if kubelet is using the Hyper container runtime. If so, the Cinder volume can be mounted directly to the Pod without any extra path mapping. Then the volume metadata will be passed to the Kubelet RunPod process as part of HyperContainer spec. Done!</p>
<p>Thanks to the plugin model of Kubernetes network and volume, we can easily build our own solutions above for HyperContainer though it is essentially different from the traditional Linux container. We also plan to propose these solutions to Kubernetes upstream by following the CNI model and volume plugin standard after the runtime integration is completed.</p>
<p>We believe all of these <a href="https://github.com/hyperhq/" target="_blank" rel="external">open source projects</a> are important components of the container ecosystem, and their growth depends greatly on the open source spirit and technical vision of the Kubernetes team. </p>
<p><strong>Conclusion</strong></p>
<p>This post introduces some of the technical details about HyperContainer and the Hypernetes project. We hope that people will be interested in this new category of secure container and its integration with Kubernetes. If you are looking to try out Hypernetes and HyperContainer, we have just announced the public beta of our new secure container cloud service (<a href="https://hyper.sh/" target="_blank" rel="external">Hyper_</a>), which is built on these technologies. But even if you are running on-premise, we believe that Hypernetes and HyperContainer will let you run Kubernetes in a more secure way.</p>
<p><em>~Harry Zhang and Pengfei Ni, engineers at HyperHQ</em></p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Notes: this post is copied from &lt;a href=&quot;http://blog.kubernetes.io/2016/05/hypernetes-security-and-multi-tenancy-in-kubernet
    
    </summary>
    
    
      <category term="Kubernetes" scheme="http://feisky.xyz/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>How docker 1.11 share network accross containers</title>
    <link href="http://feisky.xyz/2016/05/11/How-docker-1-11-share-network-accross-containers/"/>
    <id>http://feisky.xyz/2016/05/11/How-docker-1-11-share-network-accross-containers/</id>
    <published>2016-05-11T02:25:06.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>Docker 1.11 has moved to runc with containerd, I am interested in how it processing shared netns accross containers.</p>
<p>For example, I have already running a container 75599a6f387b7842c6da57efd38f9742b2ca621782f891402f83852c66dbd706. A new container within same netns can be created with cmd:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">docker run -itd --net=container:75599a6f387b alpine sh</div></pre></td></tr></table></figure>
<p>This will generate a runc <code>config.json</code> as follows:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"ociVersion"</span>: <span class="string">"0.6.0-dev"</span>,</div><div class="line">    <span class="attr">"platform"</span>: &#123;</div><div class="line">        <span class="attr">"os"</span>: <span class="string">"linux"</span>,</div><div class="line">        <span class="attr">"arch"</span>: <span class="string">"amd64"</span></div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"process"</span>: &#123;</div><div class="line">        <span class="attr">"terminal"</span>: <span class="literal">true</span>,</div><div class="line">        <span class="attr">"user"</span>: &#123;</div><div class="line">            <span class="attr">"additionalGids"</span>: [</div><div class="line">                <span class="number">0</span>,</div><div class="line">                <span class="number">1</span>,</div><div class="line">                <span class="number">2</span>,</div><div class="line">                <span class="number">3</span>,</div><div class="line">                <span class="number">4</span>,</div><div class="line">                <span class="number">6</span>,</div><div class="line">                <span class="number">10</span>,</div><div class="line">                <span class="number">11</span>,</div><div class="line">                <span class="number">20</span>,</div><div class="line">                <span class="number">26</span>,</div><div class="line">                <span class="number">27</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"args"</span>: [</div><div class="line">            <span class="string">"sh"</span></div><div class="line">        ],</div><div class="line">        <span class="attr">"env"</span>: [</div><div class="line">            <span class="string">"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span>,</div><div class="line">            <span class="string">"HOSTNAME=75599a6f387b"</span>,</div><div class="line">            <span class="string">"TERM=xterm"</span></div><div class="line">        ],</div><div class="line">        <span class="attr">"cwd"</span>: <span class="string">"/"</span>,</div><div class="line">        <span class="attr">"capabilities"</span>: [</div><div class="line">            <span class="string">"CAP_CHOWN"</span>,</div><div class="line">            <span class="string">"CAP_DAC_OVERRIDE"</span>,</div><div class="line">            <span class="string">"CAP_FSETID"</span>,</div><div class="line">            <span class="string">"CAP_FOWNER"</span>,</div><div class="line">            <span class="string">"CAP_MKNOD"</span>,</div><div class="line">            <span class="string">"CAP_NET_RAW"</span>,</div><div class="line">            <span class="string">"CAP_SETGID"</span>,</div><div class="line">            <span class="string">"CAP_SETUID"</span>,</div><div class="line">            <span class="string">"CAP_SETFCAP"</span>,</div><div class="line">            <span class="string">"CAP_SETPCAP"</span>,</div><div class="line">            <span class="string">"CAP_NET_BIND_SERVICE"</span>,</div><div class="line">            <span class="string">"CAP_SYS_CHROOT"</span>,</div><div class="line">            <span class="string">"CAP_KILL"</span>,</div><div class="line">            <span class="string">"CAP_AUDIT_WRITE"</span></div><div class="line">        ]</div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"root"</span>: &#123;</div><div class="line">        <span class="attr">"path"</span>: <span class="string">"/var/lib/docker/devicemapper/mnt/d33c7932917e64bde482b437fc3ccaad9a00a04e0cf49e39f9d3be5d71991db6/rootfs"</span>,</div><div class="line">        <span class="attr">"readonly"</span>: <span class="literal">false</span></div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"hostname"</span>: <span class="string">"75599a6f387b"</span>,</div><div class="line">    <span class="attr">"mounts"</span>: [</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/proc"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"proc"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"proc"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"noexec"</span>,</div><div class="line">                <span class="string">"nodev"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/dev"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"tmpfs"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"tmpfs"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"strictatime"</span>,</div><div class="line">                <span class="string">"mode=755"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/dev/pts"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"devpts"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"devpts"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"noexec"</span>,</div><div class="line">                <span class="string">"newinstance"</span>,</div><div class="line">                <span class="string">"ptmxmode=0666"</span>,</div><div class="line">                <span class="string">"mode=0620"</span>,</div><div class="line">                <span class="string">"gid=5"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/sys"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"sysfs"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"sysfs"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"noexec"</span>,</div><div class="line">                <span class="string">"nodev"</span>,</div><div class="line">                <span class="string">"ro"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/sys/fs/cgroup"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"cgroup"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"cgroup"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"ro"</span>,</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"noexec"</span>,</div><div class="line">                <span class="string">"nodev"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/dev/mqueue"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"mqueue"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"mqueue"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"nosuid"</span>,</div><div class="line">                <span class="string">"noexec"</span>,</div><div class="line">                <span class="string">"nodev"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/etc/resolv.conf"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"bind"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"/var/lib/docker/containers/75599a6f387b7842c6da57efd38f9742b2ca621782f891402f83852c66dbd706/resolv.conf"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"rbind"</span>,</div><div class="line">                <span class="string">"rprivate"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/etc/hostname"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"bind"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"/var/lib/docker/containers/75599a6f387b7842c6da57efd38f9742b2ca621782f891402f83852c66dbd706/hostname"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"rbind"</span>,</div><div class="line">                <span class="string">"rprivate"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/etc/hosts"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"bind"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"/var/lib/docker/containers/75599a6f387b7842c6da57efd38f9742b2ca621782f891402f83852c66dbd706/hosts"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"rbind"</span>,</div><div class="line">                <span class="string">"rprivate"</span></div><div class="line">            ]</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">            <span class="attr">"destination"</span>: <span class="string">"/dev/shm"</span>,</div><div class="line">            <span class="attr">"type"</span>: <span class="string">"bind"</span>,</div><div class="line">            <span class="attr">"source"</span>: <span class="string">"/var/lib/docker/containers/d8230e57e88d15515a94138ef512a4271e31d03bb6fb257b3d57a847e70b5c68/shm"</span>,</div><div class="line">            <span class="attr">"options"</span>: [</div><div class="line">                <span class="string">"rbind"</span>,</div><div class="line">                <span class="string">"rprivate"</span></div><div class="line">            ]</div><div class="line">        &#125;</div><div class="line">    ],</div><div class="line">    <span class="attr">"hooks"</span>: &#123;&#125;,</div><div class="line">    <span class="attr">"linux"</span>: &#123;</div><div class="line">        <span class="attr">"resources"</span>: &#123;</div><div class="line">            <span class="attr">"devices"</span>: [</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">false</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">5</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">3</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">9</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">8</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">5</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">0</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">true</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">5</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">1</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;,</div><div class="line">                &#123;</div><div class="line">                    <span class="attr">"allow"</span>: <span class="literal">false</span>,</div><div class="line">                    <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                    <span class="attr">"major"</span>: <span class="number">10</span>,</div><div class="line">                    <span class="attr">"minor"</span>: <span class="number">229</span>,</div><div class="line">                    <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">                &#125;</div><div class="line">            ],</div><div class="line">            <span class="attr">"disableOOMKiller"</span>: <span class="literal">false</span>,</div><div class="line">            <span class="attr">"oomScoreAdj"</span>: <span class="number">0</span>,</div><div class="line">            <span class="attr">"memory"</span>: &#123;</div><div class="line">                <span class="attr">"kernelTCP"</span>: <span class="literal">null</span>,</div><div class="line">                <span class="attr">"swappiness"</span>: <span class="number">18446744073709551615</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"cpu"</span>: &#123;&#125;,</div><div class="line">            <span class="attr">"pids"</span>: &#123;</div><div class="line">                <span class="attr">"limit"</span>: <span class="number">0</span></div><div class="line">            &#125;,</div><div class="line">            <span class="attr">"blockIO"</span>: &#123;</div><div class="line">                <span class="attr">"blkioWeight"</span>: <span class="number">0</span></div><div class="line">            &#125;</div><div class="line">        &#125;,</div><div class="line">        <span class="attr">"cgroupsPath"</span>: <span class="string">"/docker/d8230e57e88d15515a94138ef512a4271e31d03bb6fb257b3d57a847e70b5c68"</span>,</div><div class="line">        <span class="attr">"namespaces"</span>: [</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"mount"</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"network"</span>,</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/proc/14702/ns/net"</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"uts"</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"pid"</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"ipc"</span></div><div class="line">            &#125;</div><div class="line">        ],</div><div class="line">        <span class="attr">"devices"</span>: [</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/dev/zero"</span>,</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                <span class="attr">"minor"</span>: <span class="number">5</span>,</div><div class="line">                <span class="attr">"fileMode"</span>: <span class="number">438</span>,</div><div class="line">                <span class="attr">"uid"</span>: <span class="number">0</span>,</div><div class="line">                <span class="attr">"gid"</span>: <span class="number">0</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/dev/null"</span>,</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                <span class="attr">"minor"</span>: <span class="number">3</span>,</div><div class="line">                <span class="attr">"fileMode"</span>: <span class="number">438</span>,</div><div class="line">                <span class="attr">"uid"</span>: <span class="number">0</span>,</div><div class="line">                <span class="attr">"gid"</span>: <span class="number">0</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/dev/urandom"</span>,</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                <span class="attr">"minor"</span>: <span class="number">9</span>,</div><div class="line">                <span class="attr">"fileMode"</span>: <span class="number">438</span>,</div><div class="line">                <span class="attr">"uid"</span>: <span class="number">0</span>,</div><div class="line">                <span class="attr">"gid"</span>: <span class="number">0</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/dev/random"</span>,</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                <span class="attr">"major"</span>: <span class="number">1</span>,</div><div class="line">                <span class="attr">"minor"</span>: <span class="number">8</span>,</div><div class="line">                <span class="attr">"fileMode"</span>: <span class="number">438</span>,</div><div class="line">                <span class="attr">"uid"</span>: <span class="number">0</span>,</div><div class="line">                <span class="attr">"gid"</span>: <span class="number">0</span></div><div class="line">            &#125;,</div><div class="line">            &#123;</div><div class="line">                <span class="attr">"path"</span>: <span class="string">"/dev/fuse"</span>,</div><div class="line">                <span class="attr">"type"</span>: <span class="string">"c"</span>,</div><div class="line">                <span class="attr">"major"</span>: <span class="number">10</span>,</div><div class="line">                <span class="attr">"minor"</span>: <span class="number">229</span>,</div><div class="line">                <span class="attr">"fileMode"</span>: <span class="number">438</span>,</div><div class="line">                <span class="attr">"uid"</span>: <span class="number">0</span>,</div><div class="line">                <span class="attr">"gid"</span>: <span class="number">0</span></div><div class="line">            &#125;</div><div class="line">        ],</div><div class="line">        <span class="attr">"maskedPaths"</span>: [</div><div class="line">            <span class="string">"/proc/kcore"</span>,</div><div class="line">            <span class="string">"/proc/latency_stats"</span>,</div><div class="line">            <span class="string">"/proc/timer_stats"</span>,</div><div class="line">            <span class="string">"/proc/sched_debug"</span></div><div class="line">        ],</div><div class="line">        <span class="attr">"readonlyPaths"</span>: [</div><div class="line">            <span class="string">"/proc/asound"</span>,</div><div class="line">            <span class="string">"/proc/bus"</span>,</div><div class="line">            <span class="string">"/proc/fs"</span>,</div><div class="line">            <span class="string">"/proc/irq"</span>,</div><div class="line">            <span class="string">"/proc/sys"</span>,</div><div class="line">            <span class="string">"/proc/sysrq-trigger"</span></div><div class="line">        ]</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>So, it is very clear how it works:</p>
<ul>
<li>New container mounts same network namespace <code>/proc/14702/ns/net</code></li>
<li>New container mounts same network related configs, such as <code>/etc/resolv.conf</code>, <code>/etc/hosts</code> and <code>/etc/hostname</code></li>
</ul>
<p>There is still a little problem when first container is deleted: it could be deleted without any warning, but after delete operation, the second container will become not functional:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">[~]<span class="comment"># docker ps</span></div><div class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</div><div class="line">d8230e57e88d        alpine              <span class="string">"sh"</span>                14 minutes ago      Up 14 minutes                           focused_spence</div><div class="line">[~]<span class="comment"># docker exec d8230e57e88d echo aaa</span></div><div class="line">rpc error: code = 2 desc = <span class="string">"oci runtime error: exec failed: lstat /proc/14702/ns/net: no such file or directory"</span></div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker 1.11 has moved to runc with containerd, I am interested in how it processing shared netns accross containers.&lt;/p&gt;
&lt;p&gt;For example, 
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Go performance optimize</title>
    <link href="http://feisky.xyz/2016/05/06/Go-performance-optimize/"/>
    <id>http://feisky.xyz/2016/05/06/Go-performance-optimize/</id>
    <published>2016-05-06T12:40:06.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p><em>*[Go性能优化技巧(By 雨痕)](<a href="http://mp.weixin.qq.com/s?src=3&amp;timestamp=1461920086&amp;ver=1&amp;signature=dvsw--b6KnMYdRt43I2g4kMRIN37-tbcl2AnwpG58mxVaoZpqG24Aou2amIcFH1aIgXelirKZ0iSYJnPud" target="_blank" rel="external">http://mp.weixin.qq.com/s?src=3&amp;timestamp=1461920086&amp;ver=1&amp;signature=dvsw--b6KnMYdRt43I2g4kMRIN37-tbcl2AnwpG58mxVaoZpqG24Aou2amIcFH1aIgXelirKZ0iSYJnPud</a></em>qh3uzFrbmeM<em>bcDNCVC0t</em>m4oEblW1GOp0FHTsG-lSzRzE67RaskRf7u4<em>B5NZlkmYhTbWJNF44Bvwz9D58</em>D-54=)</p>
<ol>
<li>字符串（string）作为一种不可变类型，在与字节数组（slice, [ ]byte）转换时需付出 “沉重” 代价，根本原因是对底层字节数组的复制。</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="keyword">package</span> main</div><div class="line"></div><div class="line"><span class="keyword">import</span> (</div><div class="line">    <span class="string">"fmt"</span></div><div class="line">    <span class="string">"unsafe"</span></div><div class="line">)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">str2bytes</span><span class="params">(s <span class="keyword">string</span>)</span> []<span class="title">byte</span></span> &#123;</div><div class="line">    ptr := (*[<span class="number">2</span>]<span class="keyword">uintptr</span>)(unsafe.Pointer(&amp;s))</div><div class="line">    btr := [<span class="number">3</span>]<span class="keyword">uintptr</span>&#123;ptr[<span class="number">0</span>], ptr[<span class="number">1</span>], ptr[<span class="number">1</span>]&#125;</div><div class="line">    <span class="keyword">return</span> *(*[]<span class="keyword">byte</span>)(unsafe.Pointer(&amp;btr))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">bytes2str</span><span class="params">(b []<span class="keyword">byte</span>)</span> <span class="title">string</span></span> &#123;</div><div class="line">    <span class="keyword">return</span> *(*<span class="keyword">string</span>)(unsafe.Pointer(&amp;b))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">    s := <span class="string">"abcdefghi"</span></div><div class="line">    b := str2bytes(s)</div><div class="line">    s2 := bytes2str(b)</div><div class="line"></div><div class="line">    fmt.Println(s, b, s2)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ol>
<li><p>Go Proverbs: A little copying is better than a little dependency. 对于一些短小的对象，复制成本远小于在堆上分配和回收操作。</p>
</li>
<li><p>map预设容量：map 会按需扩张，但须付出数据拷贝和重新哈希成本。如有可能，应尽可能预设足够容量空间，避免此类行为发生。</p>
</li>
<li><p>map直接存储，对于小对象，直接将数据交由 map 保存，远比用指针高效。这不但减少了堆内存分配，关键还在于垃圾回收器不会扫描非指针类型 key/value 对象。</p>
</li>
<li><p>defer的代价:编译器通过 runtime.deferproc “注册” 延迟调用，除目标函数地址外，还会复制相关参数（包括 receiver）。在函数返回前，执行 runtime.deferreturn 提取相关信息执行延迟调用。这其中的代价自然不是普通函数调用一条 CALL 指令所能比拟的。可以考虑将内层处理逻辑转换为匿名函数.</p>
</li>
<li><p>不合理的闭包会造成性能问题，比如闭包引用原环境变量会导致Data Race并变量逃逸到堆上，增加GC扫描和回收的负担.</p>
</li>
<li><p>Channel： Don’t communicate by sharing memory, share memory by communicating.</p>
</li>
</ol>
<blockquote>
<p>如果说 channel 适用于结构层面解耦，那么 mutex 则适合保护语句级别的数据安全。至于 atomic，虽然也可实现 lock-free 结构，但处理起来要复杂得多（比如 ABA 等问题），也未必就比 mutex 快很多。还有，sync.Mutex 本就没有使用内核实现，而是像 Futex 那样，直接在用户空间以 atomic 操作完成，因为 runtime 没有任何理由将剩余 CPU 时间片还给内核。</p>
</blockquote>
<ol>
<li>关于interface:</li>
</ol>
<blockquote>
<p>接口的用途无需多言。但这并不意味着可在任何场合使用接口，要知道通过接口调用和普通调用存在很大差别。首先，相比静态绑定，动态绑定性能要差很多；其次，运行期需额外开销，比如接口会复制对象，哪怕仅是个指针，也会在堆上增加一个需 GC 处理的目标。</p>
</blockquote>
<ol>
<li><p>尽管反射（reflect）存在性能问题，但依然被频繁使用，以弥补静态语言在动态行为上的不足。只是某些时候，我们须对此做些变通，以提升性能。利用指针类型转换实现性能优化，本就是 “非常手段”，是一种为了性能而放弃 “其他” 的做法。与其担心代码是否适应未来的变化，不如写个单元测试，确保在升级时做出必要的安全检查。 <a href="http://mp.weixin.qq.com/s?timestamp=1462538257&amp;src=3&amp;ver=1&amp;signature=dth4TWXJxgxWRCAQDVFbKniJE-JCeVdqp0eMklk4f0kgrbb7QuS7xs5KDDFwmZg0ba6tMcn41JsyNZceCzyp5nErTGnWK-K9wlgOp9wAw5S3bbeBa3-BkGp3r*kN-ORevh9Iuo1UnjtFWtOoEoSX0vTH6uxMcP7*Ts0r0f4yhzE=" target="_blank" rel="external">Link</a></p>
</li>
<li><p>作为内置类型，通道（channel）从运行时得到很多支持，其自身设计也算得上精巧。但不管怎么说，它本质上依旧是一种队列，当多个 goroutine 并发操作时，免不了要使用锁。某些时候，这种竞争机制，会导致性能问题。[在研究 go runtime 源码实现过程中，会看到大量利用 “批操作” 来提升性能的样例)(<a href="http://mp.weixin.qq.com/s?timestamp=1462538257&amp;src=3&amp;ver=1&amp;signature=dth4TWXJxgxWRCAQDVFbKniJE-JCeVdqp0eMklk4f0kgrbb7QuS7xs5KDDFwmZg0ba6tMcn41JsyNZceCzyp5pZfVq*Q5bYXUHM1nH0kMNsPL3e92xy5a0zTraWNTSnQ9u8Ie3b9rjnbg0blEE3NEoenRnmCV3MpZdqseFiuy*A=" target="_blank" rel="external">http://mp.weixin.qq.com/s?timestamp=1462538257&amp;src=3&amp;ver=1&amp;signature=dth4TWXJxgxWRCAQDVFbKniJE-JCeVdqp0eMklk4f0kgrbb7QuS7xs5KDDFwmZg0ba6tMcn41JsyNZceCzyp5pZfVq*Q5bYXUHM1nH0kMNsPL3e92xy5a0zTraWNTSnQ9u8Ie3b9rjnbg0blEE3NEoenRnmCV3MpZdqseFiuy*A=</a>)</p>
</li>
<li><p>Goroutine Leak: 极简单的演示，我们注释掉数据读取方，让发送方全部进入休眠等待状态。按理说，当 test 执行结束后，通道 c 已超出作用域，理应被释放回收，但实际情况是：这些处于 “chan send” 状态的 G 对象（goroutine）会一直存在，直到唤醒或进程结束，这就是所谓的 “Goroutine Leak”。解决方法很简单，可设置 timeout。或定期用 runtime.Stack 扫描所有 goroutine 调用栈，如果发现某个 goroutine 长时间（阈值）处于 “chan send” 状态，可用一个类似 “/dev/null hole” 的接收器负责唤醒并 “处理” 掉相关数据。 <a href="http://mp.weixin.qq.com/s?timestamp=1462538257&amp;src=3&amp;ver=1&amp;signature=dth4TWXJxgxWRCAQDVFbKniJE-JCeVdqp0eMklk4f0kgrbb7QuS7xs5KDDFwmZg0ba6tMcn41JsyNZceCzyp5o9mcQPs7Eqi*KhEEPKyOoiDvyJHFBWSxCetuDBLPPTsdi-SZQypc24ZMdm5qRs13Je5vyZgLwIlLqhUsErg9oI=" target="_blank" rel="external">Link</a></p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;*[Go性能优化技巧(By 雨痕)](&lt;a href=&quot;http://mp.weixin.qq.com/s?src=3&amp;amp;timestamp=1461920086&amp;amp;ver=1&amp;amp;signature=dvsw--b6KnMYdRt43I2g4kMR
    
    </summary>
    
    
      <category term="go" scheme="http://feisky.xyz/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>The Rise of Cloud Computing Systems - Jeff Dean</title>
    <link href="http://feisky.xyz/2016/05/05/The-Rise-of-Cloud-Computing-Systems-Jeff-Dean/"/>
    <id>http://feisky.xyz/2016/05/05/The-Rise-of-Cloud-Computing-Systems-Jeff-Dean/</id>
    <published>2016-05-05T09:16:46.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[

	<div class="row">
	  <iframe src="http://nagland.github.io/viewer/web/viewer.html?val=http://feiskyer.github.io/assets/ccs.pdf" style="width:100%; height:550px"></iframe>
	</div>



]]></content>
    
    <summary type="html">
    
      

	&lt;div class=&quot;row&quot;&gt;
	  &lt;iframe src=&quot;http://nagland.github.io/viewer/web/viewer.html?val=http://feiskyer.github.io/assets/ccs.pdf&quot; style=&quot;wi
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Reading notes of week 17</title>
    <link href="http://feisky.xyz/2016/04/29/Reading-notes-of-week-17/"/>
    <id>http://feisky.xyz/2016/04/29/Reading-notes-of-week-17/</id>
    <published>2016-04-29T08:50:14.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p><strong><a href="http://blog.kubernetes.io/2016/04/Kubernetes-Network-Policy-APIs.html" target="_blank" rel="external">SIG-Networking: Kubernetes Network Policy APIs Coming in 1.3</a></strong></p>
<blockquote>
<p>One problem many users have is that the open access network policy of Kubernetes is not suitable for applications that need more precise control over the traffic that accesses a pod or service. Today, this could be a multi-tier application where traffic is only allowed from a tier’s neighbor. But as new Cloud Native applications are built by composing microservices, the ability to control traffic as it flows among these services becomes even more critical.</p>
<p>From these scenarios several possible approaches were considered and a minimal policy specification was defined. The basic idea is that if isolation were enabled on a per namespace basis, then specific pods would be selected where specific traffic types would be allowed.</p>
</blockquote>
<p>Network isolation is enabled by defining the network-isolation annotation on namespaces as shown below:</p>
<pre><code>    net.alpha.kubernetes.io/network-isolation: [ on | off ]
</code></pre><p>Once network isolation is enabled, explicit network policies must be applied to enable pod communication.</p>
<p>A policy specification can be applied to a namespace to define the details of the policy as shown below:</p>
<figure class="highlight xquery"><table><tr><td class="code"><pre><div class="line">POST /apis/net.alpha.kubernetes.io/v1alpha1/namespaces/tenant-a/networkpolicys/</div><div class="line"></div><div class="line">&#123;</div><div class="line"><span class="string">"kind"</span>: <span class="string">"NetworkPolicy"</span>,</div><div class="line"><span class="string">"metadata"</span>: &#123;</div><div class="line"><span class="string">"name"</span>: <span class="string">"pol1"</span></div><div class="line">&#125;,</div><div class="line"><span class="string">"spec"</span>: &#123;</div><div class="line"><span class="string">"allowIncoming"</span>: &#123;</div><div class="line"><span class="string">"from"</span>: [</div><div class="line">&#123; <span class="string">"pods"</span>: &#123; <span class="string">"segment"</span>: <span class="string">"frontend"</span> &#125; &#125;</div><div class="line">],</div><div class="line"><span class="string">"toPorts"</span>: [</div><div class="line">&#123; <span class="string">"port"</span>: <span class="number">80</span>, <span class="string">"protocol"</span>: <span class="string">"TCP"</span> &#125;</div><div class="line">]</div><div class="line">&#125;,</div><div class="line"><span class="string">"podSelector"</span>: &#123; <span class="string">"segment"</span>: <span class="string">"backend"</span> &#125;</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><img src="https://lh5.googleusercontent.com/zMEpLMYmask-B-rYWnbMyGb0M7YusPQFPS6EfpNOSLbkf-cM49V7rTDBpA6k9-Zdh2soMul39rz9rHFJfL-jnEn_mHbpg0E1WlM-wjU-qvQu9KDTQqQ9uBmdaeWynDDNhcT3UjX5" alt=""></p>
<p><a href="https://docs.google.com/document/d/1qAm-_oSap-f1d6a-xRTj6xaH1sYQBfK36VyjB5XOZug/edit" target="_blank" rel="external">https://docs.google.com/document/d/1qAm-_oSap-f1d6a-xRTj6xaH1sYQBfK36VyjB5XOZug/edit</a></p>
<p>**<a href="http://www.infoq.com/articles/build-a-container-golang?utm_source=golangweekly&amp;utm_medium=email" target="_blank" rel="external">Build Your Own Container Using Less than 100 Lines of Go</a></p>
<blockquote>
<p>a super super simple container, in (way) less than 100 lines of go</p>
</blockquote>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="keyword">package</span> main</div><div class="line"></div><div class="line"><span class="keyword">import</span> (</div><div class="line">    <span class="string">"fmt"</span></div><div class="line">    <span class="string">"os"</span></div><div class="line">    <span class="string">"os/exec"</span></div><div class="line">    <span class="string">"syscall"</span></div><div class="line">)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">    <span class="keyword">switch</span> os.Args[<span class="number">1</span>] &#123;</div><div class="line">    <span class="keyword">case</span> <span class="string">"run"</span>:</div><div class="line">        parent()</div><div class="line">    <span class="keyword">case</span> <span class="string">"child"</span>:</div><div class="line">        child()</div><div class="line">    <span class="keyword">default</span>:</div><div class="line">        <span class="built_in">panic</span>(<span class="string">"wat should I do"</span>)</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">parent</span><span class="params">()</span></span> &#123;</div><div class="line">    cmd := exec.Command(<span class="string">"/proc/self/exe"</span>, <span class="built_in">append</span>([]<span class="keyword">string</span>&#123;<span class="string">"child"</span>&#125;, os.Args[<span class="number">2</span>:]...)...)</div><div class="line">    cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;</div><div class="line">        Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS,</div><div class="line">    &#125;</div><div class="line">    cmd.Stdin = os.Stdin</div><div class="line">    cmd.Stdout = os.Stdout</div><div class="line">    cmd.Stderr = os.Stderr</div><div class="line"></div><div class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</div><div class="line">        fmt.Println(<span class="string">"ERROR"</span>, err)</div><div class="line">        os.Exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">child</span><span class="params">()</span></span> &#123;</div><div class="line">    must(syscall.Mount(<span class="string">"rootfs"</span>, <span class="string">"rootfs"</span>, <span class="string">""</span>, syscall.MS_BIND, <span class="string">""</span>))</div><div class="line">    must(os.MkdirAll(<span class="string">"rootfs/oldrootfs"</span>, <span class="number">0700</span>))</div><div class="line">    must(syscall.PivotRoot(<span class="string">"rootfs"</span>, <span class="string">"rootfs/oldrootfs"</span>))</div><div class="line">    must(os.Chdir(<span class="string">"/"</span>))</div><div class="line"></div><div class="line">    cmd := exec.Command(os.Args[<span class="number">2</span>], os.Args[<span class="number">3</span>:]...)</div><div class="line">    cmd.Stdin = os.Stdin</div><div class="line">    cmd.Stdout = os.Stdout</div><div class="line">    cmd.Stderr = os.Stderr</div><div class="line"></div><div class="line">    <span class="keyword">if</span> err := cmd.Run(); err != <span class="literal">nil</span> &#123;</div><div class="line">        fmt.Println(<span class="string">"ERROR"</span>, err)</div><div class="line">        os.Exit(<span class="number">1</span>)</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">must</span><span class="params">(err error)</span></span> &#123;</div><div class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</div><div class="line">        <span class="built_in">panic</span>(err)</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><em>*[Go性能优化技巧(By 雨痕)](<a href="http://mp.weixin.qq.com/s?src=3&amp;timestamp=1461920086&amp;ver=1&amp;signature=dvsw--b6KnMYdRt43I2g4kMRIN37-tbcl2AnwpG58mxVaoZpqG24Aou2amIcFH1aIgXelirKZ0iSYJnPud" target="_blank" rel="external">http://mp.weixin.qq.com/s?src=3&amp;timestamp=1461920086&amp;ver=1&amp;signature=dvsw--b6KnMYdRt43I2g4kMRIN37-tbcl2AnwpG58mxVaoZpqG24Aou2amIcFH1aIgXelirKZ0iSYJnPud</a></em>qh3uzFrbmeM<em>bcDNCVC0t</em>m4oEblW1GOp0FHTsG-lSzRzE67RaskRf7u4<em>B5NZlkmYhTbWJNF44Bvwz9D58</em>D-54=)</p>
<ol>
<li>字符串（string）作为一种不可变类型，在与字节数组（slice, [ ]byte）转换时需付出 “沉重” 代价，根本原因是对底层字节数组的复制。</li>
</ol>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="keyword">package</span> main</div><div class="line"></div><div class="line"><span class="keyword">import</span> (</div><div class="line">    <span class="string">"fmt"</span></div><div class="line">    <span class="string">"unsafe"</span></div><div class="line">)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">str2bytes</span><span class="params">(s <span class="keyword">string</span>)</span> []<span class="title">byte</span></span> &#123;</div><div class="line">    ptr := (*[<span class="number">2</span>]<span class="keyword">uintptr</span>)(unsafe.Pointer(&amp;s))</div><div class="line">    btr := [<span class="number">3</span>]<span class="keyword">uintptr</span>&#123;ptr[<span class="number">0</span>], ptr[<span class="number">1</span>], ptr[<span class="number">1</span>]&#125;</div><div class="line">    <span class="keyword">return</span> *(*[]<span class="keyword">byte</span>)(unsafe.Pointer(&amp;btr))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">bytes2str</span><span class="params">(b []<span class="keyword">byte</span>)</span> <span class="title">string</span></span> &#123;</div><div class="line">    <span class="keyword">return</span> *(*<span class="keyword">string</span>)(unsafe.Pointer(&amp;b))</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">    s := <span class="string">"abcdefghi"</span></div><div class="line">    b := str2bytes(s)</div><div class="line">    s2 := bytes2str(b)</div><div class="line"></div><div class="line">    fmt.Println(s, b, s2)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ol>
<li><p>Go Proverbs: A little copying is better than a little dependency. 对于一些短小的对象，复制成本远小于在堆上分配和回收操作。</p>
</li>
<li><p>map预设容量：map 会按需扩张，但须付出数据拷贝和重新哈希成本。如有可能，应尽可能预设足够容量空间，避免此类行为发生。</p>
</li>
<li><p>map直接存储，对于小对象，直接将数据交由 map 保存，远比用指针高效。这不但减少了堆内存分配，关键还在于垃圾回收器不会扫描非指针类型 key/value 对象。</p>
</li>
<li><p>defer的代价:编译器通过 runtime.deferproc “注册” 延迟调用，除目标函数地址外，还会复制相关参数（包括 receiver）。在函数返回前，执行 runtime.deferreturn 提取相关信息执行延迟调用。这其中的代价自然不是普通函数调用一条 CALL 指令所能比拟的。可以考虑将内层处理逻辑转换为匿名函数.</p>
</li>
<li><p>不合理的闭包会造成性能问题，比如闭包引用原环境变量会导致Data Race并变量逃逸到堆上，增加GC扫描和回收的负担.</p>
</li>
</ol>
<p><strong><a href="http://www.sdnlab.com/16646.html" target="_blank" rel="external">基于组的策略（GBP）开启新型网络设计时代</a></strong></p>
<p>很早就玩过GBP，当时还是基于思科ACI的。GBP这个东西从概念上完全照搬了ACI的那套理论，将原有网络的概念转换成了面向应用的网络策策略。对大部分做网络的人来说，有一定的接受难度；但对应用开发人员挺友好的。不过ACI需要增加路由器的控制，才能算是一个完整的方案。</p>
<p>现在GBP也集成了ODL，终于有更多的玩家进来。</p>
<p>顺便说下，Kubernetes Network Policy跟GBP的概念很像，都是面向应用的接口.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://blog.kubernetes.io/2016/04/Kubernetes-Network-Policy-APIs.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;SIG-Networking: Ku
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
      <category term="container" scheme="http://feisky.xyz/tags/container/"/>
    
      <category term="blockchain" scheme="http://feisky.xyz/tags/blockchain/"/>
    
  </entry>
  
  <entry>
    <title>runc and runV</title>
    <link href="http://feisky.xyz/2016/04/28/runc/"/>
    <id>http://feisky.xyz/2016/04/28/runc/</id>
    <published>2016-04-28T03:15:03.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>runc is a CLI tool for spawning and running containers according to the OCI specification, while runV is a hypervisor-based runtime for OCI. Both of them are recommanded (implementations](<a href="https://github.com/opencontainers/runtime-spec/blob/master/implementations.md" target="_blank" rel="external">https://github.com/opencontainers/runtime-spec/blob/master/implementations.md</a>) of OCI.</p>
<h2 id="Playing-with-runc"><a href="#Playing-with-runc" class="headerlink" title="Playing with runc"></a>Playing with runc</h2><p>Install runc:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">yum install -y libseccomp-devel</div><div class="line">mkdir -p <span class="variable">$GOPATH</span>/src/github.com/opencontainers</div><div class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/opencontainers</div><div class="line">git <span class="built_in">clone</span> https://github.com/opencontainers/runc</div><div class="line"><span class="built_in">cd</span> runc</div><div class="line">make</div><div class="line">sudo make install</div></pre></td></tr></table></figure>
<p>Run busybox:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">$ docker pull busybox</div><div class="line">$ mkdir rootfs</div><div class="line">$ docker <span class="built_in">export</span> $(docker create busybox) | tar -C rootfs -xvf -</div><div class="line">$ runc spec .</div><div class="line">$ runc start <span class="built_in">test</span></div><div class="line">/ <span class="comment"># ps</span></div><div class="line">PID   USER     COMMAND</div><div class="line">1 root     sh</div><div class="line">9 root     ps</div></pre></td></tr></table></figure>
<h2 id="Playing-with-docker-containerd"><a href="#Playing-with-docker-containerd" class="headerlink" title="Playing with docker-containerd"></a>Playing with docker-containerd</h2><p>docker-containerd is installed togather with docker 1.11.</p>
<figure class="highlight llvm"><table><tr><td class="code"><pre><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> containers</div><div class="line">ID                                                                 PATH                                                                                             STATUS              PROCESSES</div><div class="line"><span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span>   /var/run/docker/libcontainerd/<span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span>   running             init</div><div class="line">bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span>   /var/run/docker/libcontainerd/bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span>   running             init</div><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> containers exec --id=<span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span> --pid=<span class="number">20</span> --cwd=/ -a /bin/ps aux</div><div class="line">PID   USER     TIME   COMMAND</div><div class="line">    <span class="number">1</span> root       <span class="number">0</span>:<span class="number">00</span> sh</div><div class="line">   <span class="number">51</span> root       <span class="number">0</span>:<span class="number">00</span> /bin/ps aux</div><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> state <span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span></div><div class="line">&#123;<span class="string">"containers"</span>:[&#123;<span class="string">"id"</span>:<span class="string">"346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c"</span>,<span class="string">"bundlePath"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c"</span>,<span class="string">"processes"</span>:[&#123;<span class="string">"pid"</span>:<span class="string">"init"</span>,<span class="string">"terminal"</span>:<span class="keyword">true</span>,<span class="string">"user"</span>:&#123;<span class="string">"additionalGids"</span>:[<span class="number">10</span>]&#125;,<span class="string">"args"</span>:[<span class="string">"sh"</span>],<span class="string">"env"</span>:[<span class="string">"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span>,<span class="string">"HOSTNAME=346c1b7bbb04"</span>,<span class="string">"TERM=xterm"</span>],<span class="string">"cwd"</span>:<span class="string">"/"</span>,<span class="string">"systemPid"</span>:<span class="number">3716</span>,<span class="string">"stdin"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stdin"</span>,<span class="string">"stdout"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stdout"</span>,<span class="string">"stderr"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stderr"</span>,<span class="string">"capabilities"</span>:[<span class="string">"CAP_CHOWN"</span>,<span class="string">"CAP_DAC_OVERRIDE"</span>,<span class="string">"CAP_FSETID"</span>,<span class="string">"CAP_FOWNER"</span>,<span class="string">"CAP_MKNOD"</span>,<span class="string">"CAP_NET_RAW"</span>,<span class="string">"CAP_SETGID"</span>,<span class="string">"CAP_SETUID"</span>,<span class="string">"CAP_SETFCAP"</span>,<span class="string">"CAP_SETPCAP"</span>,<span class="string">"CAP_NET_BIND_SERVICE"</span>,<span class="string">"CAP_SYS_CHROOT"</span>,<span class="string">"CAP_KILL"</span>,<span class="string">"CAP_AUDIT_WRITE"</span>]&#125;],<span class="string">"status"</span>:<span class="string">"running"</span>,<span class="string">"pids"</span>:[<span class="number">3716</span>],<span class="string">"runtime"</span>:<span class="string">"docker-runc"</span>&#125;],<span class="string">"machine"</span>:&#123;<span class="string">"cpus"</span>:<span class="number">2</span>,<span class="string">"memory"</span>:<span class="number">7982</span>&#125;&#125;</div></pre></td></tr></table></figure>
<h2 id="Playing-with-runV"><a href="#Playing-with-runV" class="headerlink" title="Playing with runV"></a>Playing with runV</h2><p>Install runV:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">mkdir -p <span class="variable">$GOPATH</span>/src/github.com/hyperhq</div><div class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/hyperhq</div><div class="line">git <span class="built_in">clone</span> https://github.com/hyperhq/runv/</div><div class="line"><span class="built_in">cd</span> runv</div><div class="line">./autogen.sh</div><div class="line">./configure</div><div class="line">make</div><div class="line">sudo make install</div></pre></td></tr></table></figure>
<p>To run container in runV, kernel and initrd are needed since runV is based on hypervisor. They could be compiled from <a href="https://github.com/hyperhq/hyperstart" target="_blank" rel="external">hyperstart</a>.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">$ docker pull busybox</div><div class="line">$ mkdir rootfs</div><div class="line">$ docker <span class="built_in">export</span> $(docker create busybox) | tar -C rootfs -xvf -</div><div class="line">$ runv spec .</div><div class="line">$ runv --kernel=/var/lib/hyper/kernel --initrd=/var/lib/hyper/hyper-initrd.img start <span class="built_in">test</span></div></pre></td></tr></table></figure>
<h2 id="Playing-with-runv-containerd"><a href="#Playing-with-runv-containerd" class="headerlink" title="Playing with runv-containerd"></a>Playing with runv-containerd</h2><p>Install ctr CLI from containerd</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/src/github.com/docker</div><div class="line">git <span class="built_in">clone</span> https://github.com/docker/containerd.git</div><div class="line"><span class="built_in">cd</span> containerd</div><div class="line">make</div><div class="line">make install</div></pre></td></tr></table></figure>
<p>Start runv containerd</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">runv-containerd --kernel=/var/lib/hyper/kernel --initrd=/var/lib/hyper/hyper-initrd.img</div></pre></td></tr></table></figure>
<p>Run ctr command now:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">ctr --address=unix:///run/runv-containerd/containerd.sock containers</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="comment"># Creating OCI bundles</span></div><div class="line">mkdir -p busybox/rootfs</div><div class="line">docker <span class="built_in">export</span> $(docker create busybox) | tar -C busybox/rootfs -xvf -</div><div class="line"><span class="built_in">cd</span> busybox</div><div class="line">runv spec .</div></pre></td></tr></table></figure>
<p>Change the contents of config.json to </p>
<figure class="highlight json"><table><tr><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="attr">"ociVersion"</span>: <span class="string">"0.5.0-dev"</span>,</div><div class="line">  <span class="attr">"platform"</span>: &#123;</div><div class="line">    <span class="attr">"os"</span>: <span class="string">"linux"</span>,</div><div class="line">    <span class="attr">"arch"</span>: <span class="string">"amd64"</span></div><div class="line">  &#125;,</div><div class="line">  <span class="attr">"process"</span>: &#123;</div><div class="line">    <span class="attr">"terminal"</span>: <span class="literal">true</span>,</div><div class="line">    <span class="attr">"user"</span>: &#123;&#125;,</div><div class="line">    <span class="attr">"args"</span>: [</div><div class="line">      <span class="string">"sh"</span></div><div class="line">    ],</div><div class="line">    <span class="attr">"env"</span>: [</div><div class="line">      <span class="string">"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span>,</div><div class="line">      <span class="string">"TERM=xterm"</span></div><div class="line">    ],</div><div class="line">    <span class="attr">"cwd"</span>: <span class="string">"/"</span></div><div class="line">  &#125;,</div><div class="line">  <span class="attr">"root"</span>: &#123;</div><div class="line">    <span class="attr">"path"</span>: <span class="string">"rootfs"</span>,</div><div class="line">    <span class="attr">"readonly"</span>: <span class="literal">false</span></div><div class="line">  &#125;,</div><div class="line">  <span class="attr">"hostname"</span>: <span class="string">"shell"</span>,</div><div class="line">  <span class="attr">"mounts"</span>: [</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/proc"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"proc"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"proc"</span></div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/dev"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"tmpfs"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"tmpfs"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"strictatime"</span>,</div><div class="line">        <span class="string">"mode=755"</span>,</div><div class="line">        <span class="string">"size=65536k"</span></div><div class="line">      ]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/dev/pts"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"devpts"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"devpts"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"noexec"</span>,</div><div class="line">        <span class="string">"newinstance"</span>,</div><div class="line">        <span class="string">"ptmxmode=0666"</span>,</div><div class="line">        <span class="string">"mode=0620"</span>,</div><div class="line">        <span class="string">"gid=5"</span></div><div class="line">      ]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/dev/shm"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"tmpfs"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"shm"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"noexec"</span>,</div><div class="line">        <span class="string">"nodev"</span>,</div><div class="line">        <span class="string">"mode=1777"</span>,</div><div class="line">        <span class="string">"size=65536k"</span></div><div class="line">      ]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/dev/mqueue"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"mqueue"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"mqueue"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"noexec"</span>,</div><div class="line">        <span class="string">"nodev"</span></div><div class="line">      ]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/sys"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"sysfs"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"sysfs"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"noexec"</span>,</div><div class="line">        <span class="string">"nodev"</span>,</div><div class="line">        <span class="string">"ro"</span></div><div class="line">      ]</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      <span class="attr">"destination"</span>: <span class="string">"/sys/fs/cgroup"</span>,</div><div class="line">      <span class="attr">"type"</span>: <span class="string">"cgroup"</span>,</div><div class="line">      <span class="attr">"source"</span>: <span class="string">"cgroup"</span>,</div><div class="line">      <span class="attr">"options"</span>: [</div><div class="line">        <span class="string">"nosuid"</span>,</div><div class="line">        <span class="string">"noexec"</span>,</div><div class="line">        <span class="string">"nodev"</span>,</div><div class="line">        <span class="string">"relatime"</span>,</div><div class="line">        <span class="string">"ro"</span></div><div class="line">      ]</div><div class="line">    &#125;</div><div class="line">  ],</div><div class="line">  <span class="attr">"hooks"</span>: &#123;&#125;,</div><div class="line">  <span class="attr">"linux"</span>: &#123;</div><div class="line">    <span class="attr">"resources"</span>: &#123;</div><div class="line">      <span class="attr">"devices"</span>: [</div><div class="line">				&#123;</div><div class="line">          <span class="attr">"allow"</span>: <span class="literal">false</span>,</div><div class="line">          <span class="attr">"access"</span>: <span class="string">"rwm"</span></div><div class="line">        &#125;</div><div class="line">			]</div><div class="line">    &#125;,</div><div class="line">    <span class="attr">"namespaces"</span>: [</div><div class="line">      &#123;</div><div class="line">        <span class="attr">"type"</span>: <span class="string">"pid"</span></div><div class="line">      &#125;,</div><div class="line">      &#123;</div><div class="line">        <span class="attr">"type"</span>: <span class="string">"ipc"</span></div><div class="line">      &#125;,</div><div class="line">      &#123;</div><div class="line">        <span class="attr">"type"</span>: <span class="string">"uts"</span></div><div class="line">      &#125;,</div><div class="line">      &#123;</div><div class="line">        <span class="attr">"type"</span>: <span class="string">"mount"</span></div><div class="line">      &#125;</div><div class="line">    ],</div><div class="line">		<span class="attr">"devices"</span>: <span class="literal">null</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Start container:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">ctr --address=unix:///run/runv-containerd/containerd.sock containers start <span class="built_in">test</span> /root/busybox</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line">$ ctr --address=unix:///run/runv-containerd/containerd.sock containers</div><div class="line">ID                  PATH                STATUS              PROCESSES</div><div class="line"><span class="built_in">test</span>                /root/busybox       running             init</div><div class="line"></div><div class="line">$ ctr --address=unix:///run/runv-containerd/containerd.sock containers <span class="built_in">exec</span> --id=<span class="built_in">test</span> --pid=20 --cwd=/ <span class="_">-a</span>  ps aux</div><div class="line">PID   USER     TIME   COMMAND</div><div class="line">    1 root       0:00 /init</div><div class="line">    2 root       0:00 sh</div><div class="line">    4 root       0:00 ps aux</div><div class="line"></div><div class="line">ps -ef | grep qemu</div><div class="line">qemu-system-x86_64 -machine pc-i440fx-2.0,usb=off -cpu core2duo -kernel /var/lib/hyper/kernel -initrd /var/lib/hyper/hyper-initrd.img -append <span class="string">"console=ttyS0 panic=1 no_timer_check"</span> -realtime mlock=off -no-user-config -nodefaults -no-hpet -rtc base=utc,driftfix=slew -no-reboot -display none -boot strict=on -m 128 -smp 1 -qmp unix:/var/run/hyper/vm-JRPdDUOkqA/qmp.sock,server,nowait -serial unix:/var/run/hyper/vm-JRPdDUOkqA/console.sock,server,nowait -device virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x2 -device virtio-scsi-pci,id=scsi0,bus=pci.0,addr=0x3 -chardev socket,id=charch0,path=/var/run/hyper/vm-JRPdDUOkqA/hyper.sock,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=1,chardev=charch0,id=channel0,name=sh.hyper.channel.0 -chardev socket,id=charch1,path=/var/run/hyper/vm-JRPdDUOkqA/tty.sock,server,nowait -device virtserialport,bus=virtio-serial0.0,nr=2,chardev=charch1,id=channel1,name=sh.hyper.channel.1 -fsdev <span class="built_in">local</span>,id=virtio9p,path=/var/run/hyper/vm-JRPdDUOkqA/share_dir,security_model=none -device virtio-9p-pci,fsdev=virtio9p,mount_tag=share_dir</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;runc is a CLI tool for spawning and running containers according to the OCI specification, while runV is a hypervisor-based runtime for O
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
      <category term="container" scheme="http://feisky.xyz/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>Container runtime in Docker v1.11</title>
    <link href="http://feisky.xyz/2016/04/28/Docker-1-11-Runtime/"/>
    <id>http://feisky.xyz/2016/04/28/Docker-1-11-Runtime/</id>
    <published>2016-04-28T02:07:23.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>Docker v1.11正式集成了runc（终于支持OCI了），并将原来的一个二进制文件拆分为多个，同时还保持docker CLI和API不变：</p>
<ul>
<li>docker</li>
<li>docker-containerd</li>
<li>docker-containerd-shim</li>
<li>docker-runc</li>
<li>docker-containerd-ctr</li>
</ul>
<p><img src="/images/docker-v11.png" alt=""></p>
<p>这么做的好处很明显：</p>
<ul>
<li>最重要的可以在docker或者containerd重启的时候container还保持running</li>
<li>container runtime pluggable，比如以后可以选择用runV（当然默认肯定是runc）</li>
<li>性能，新的containerd没有历史包袱，一开始就针对性能做了优化（100 containers in 1.64 seconds）</li>
<li>docker daemon的角色变化，docker只需要做少量的准备工作，把真正运行容器的工作交给containerd：<ul>
<li>Image management</li>
<li>Generate OCI bundle for containers</li>
<li>Mount the container’s root filesystem inside the bundle</li>
<li>Call containerd to start container</li>
</ul>
</li>
</ul>
<p><strong><a href="https://github.com/docker/containerd" target="_blank" rel="external">Containerd</a></strong></p>
<p>containerd is a daemon to control runC, built for performance and density. containerd leverages runC’s advanced features such as seccomp and user namespace support as well as checkpoint and restore for cloning and live migration of containers:</p>
<p><img src="/images/containerd.png" alt=""></p>
<p><strong>docker-containerd-ctr</strong></p>
<p>docker-containerd-ctr is the CLI for docker-containerd, which is based on gPRC APIs.</p>
<figure class="highlight llvm"><table><tr><td class="code"><pre><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> containers</div><div class="line">ID                                                                 PATH                                                                                             STATUS              PROCESSES</div><div class="line"><span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span>   /var/run/docker/libcontainerd/<span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span>   running             init</div><div class="line">bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span>   /var/run/docker/libcontainerd/bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span>   running             init</div><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> containers exec --id=<span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span> --pid=<span class="number">20</span> --cwd=/ -a /bin/ps aux</div><div class="line">PID   USER     TIME   COMMAND</div><div class="line">    <span class="number">1</span> root       <span class="number">0</span>:<span class="number">00</span> sh</div><div class="line">   <span class="number">51</span> root       <span class="number">0</span>:<span class="number">00</span> /bin/ps aux</div><div class="line">$ docker-containerd-ctr --address <span class="string">"/var/run/docker/libcontainerd/docker-containerd.sock"</span> state <span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span></div><div class="line">&#123;<span class="string">"containers"</span>:[&#123;<span class="string">"id"</span>:<span class="string">"346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c"</span>,<span class="string">"bundlePath"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c"</span>,<span class="string">"processes"</span>:[&#123;<span class="string">"pid"</span>:<span class="string">"init"</span>,<span class="string">"terminal"</span>:<span class="keyword">true</span>,<span class="string">"user"</span>:&#123;<span class="string">"additionalGids"</span>:[<span class="number">10</span>]&#125;,<span class="string">"args"</span>:[<span class="string">"sh"</span>],<span class="string">"env"</span>:[<span class="string">"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span>,<span class="string">"HOSTNAME=346c1b7bbb04"</span>,<span class="string">"TERM=xterm"</span>],<span class="string">"cwd"</span>:<span class="string">"/"</span>,<span class="string">"systemPid"</span>:<span class="number">3716</span>,<span class="string">"stdin"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stdin"</span>,<span class="string">"stdout"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stdout"</span>,<span class="string">"stderr"</span>:<span class="string">"/var/run/docker/libcontainerd/346c1b7bbb04b760032557e1324a4027ec0055ea84dca109134c02e03dc1242c/init-stderr"</span>,<span class="string">"capabilities"</span>:[<span class="string">"CAP_CHOWN"</span>,<span class="string">"CAP_DAC_OVERRIDE"</span>,<span class="string">"CAP_FSETID"</span>,<span class="string">"CAP_FOWNER"</span>,<span class="string">"CAP_MKNOD"</span>,<span class="string">"CAP_NET_RAW"</span>,<span class="string">"CAP_SETGID"</span>,<span class="string">"CAP_SETUID"</span>,<span class="string">"CAP_SETFCAP"</span>,<span class="string">"CAP_SETPCAP"</span>,<span class="string">"CAP_NET_BIND_SERVICE"</span>,<span class="string">"CAP_SYS_CHROOT"</span>,<span class="string">"CAP_KILL"</span>,<span class="string">"CAP_AUDIT_WRITE"</span>]&#125;],<span class="string">"status"</span>:<span class="string">"running"</span>,<span class="string">"pids"</span>:[<span class="number">3716</span>],<span class="string">"runtime"</span>:<span class="string">"docker-runc"</span>&#125;],<span class="string">"machine"</span>:&#123;<span class="string">"cpus"</span>:<span class="number">2</span>,<span class="string">"memory"</span>:<span class="number">7982</span>&#125;&#125;</div></pre></td></tr></table></figure>
<p><strong>containerd-shim</strong></p>
<p>containerd-shim is a small shim that sits in front of a runtime implementation that allows it to be repartented to init and handle reattach from the caller.</p>
<p>The cwd of the shim should be the bundle for the container.  Arg1 should be the path to the state directory where the shim can locate fifos and other information.</p>
<p><strong><a href="https://github.com/opencontainers/runc.git" target="_blank" rel="external">runc</a></strong></p>
<p>runc is a CLI tool for spawning and running containers according to the OCI specification.</p>
<p><strong>cgroups结构</strong></p>
<p>从cgroups里面可以直接看到这几个进程之间的管理关系，比如启动两个container之后：</p>
<figure class="highlight llvm"><table><tr><td class="code"><pre><div class="line">│ ├─docker.service</div><div class="line">│ │ ├─ <span class="number">961</span> /usr/bin/docker daemon -H fd://</div><div class="line">│ │ ├─ <span class="number">967</span> docker-containerd -l /var/run/docker/libcontainerd/docker-containerd.sock --runtime docker-runc</div><div class="line">│ │ ├─<span class="number">1063</span> docker-proxy -proto tcp -host-ip <span class="number">0.0</span>.<span class="number">0.0</span> -host-port <span class="number">27017</span> -container-ip <span class="number">172.17</span>.<span class="number">0.2</span> -container-port <span class="number">27017</span></div><div class="line">│ │ ├─<span class="number">1070</span> docker-containerd-shim bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span> /var/run/docker/libcontainerd/bca<span class="number">15</span>f<span class="number">3420e3218987314</span>e<span class="number">1</span>cbbf<span class="number">440120</span>ff<span class="number">880</span>af<span class="number">44844778293</span><span class="keyword">c</span><span class="number">4130526</span><span class="keyword">c</span><span class="number">85</span><span class="keyword">cc</span> docker-runc</div><div class="line">│ │ └─<span class="number">3703</span> docker-containerd-shim <span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span> /var/run/docker/libcontainerd/<span class="number">346</span><span class="keyword">c</span><span class="number">1</span>b<span class="number">7</span>bbb<span class="number">04</span>b<span class="number">760032557e1324</span>a<span class="number">4027</span>ec<span class="number">0055</span>ea<span class="number">84</span>dca<span class="number">109134</span><span class="keyword">c</span><span class="number">02e03</span>dc<span class="number">1242</span><span class="keyword">c</span> docker-runc</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker v1.11正式集成了runc（终于支持OCI了），并将原来的一个二进制文件拆分为多个，同时还保持docker CLI和API不变：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;docker&lt;/li&gt;
&lt;li&gt;docker-containerd&lt;/li&gt;
&lt;li&gt;docker-c
    
    </summary>
    
    
      <category term="docker" scheme="http://feisky.xyz/tags/docker/"/>
    
      <category term="runc" scheme="http://feisky.xyz/tags/runc/"/>
    
      <category term="container" scheme="http://feisky.xyz/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>DPDK Introduction</title>
    <link href="http://feisky.xyz/2016/04/24/DPDK-Introduction/"/>
    <id>http://feisky.xyz/2016/04/24/DPDK-Introduction/</id>
    <published>2016-04-24T11:43:07.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<h2 id="DPDK-Introduction"><a href="#DPDK-Introduction" class="headerlink" title="DPDK Introduction"></a>DPDK Introduction</h2><p>Intel DPDK全称Intel Data Plane Development Kit，是intel提供的数据平面开发工具集，为Intel architecture（IA）处理器架构下用户空间高效的数据包处理提供库函数和驱动的支持，它不同于Linux系统以通用性设计为目的，而是专注于网络应用中数据包的高性能处理。DPDK应用程序是运行在用户空间上利用自身提供的数据平面库来收发数据包，绕过了Linux内核协议栈对数据包处理过程。Linux内核将DPDK应用程序看作是一个普通的用户态进程，包括它的编译、连接和加载方式和普通程序没有什么两样。DPDK程序启动后只能有一个主线程，然后创建一些子线程并绑定到指定CPU核心上运行。</p>
<p>DPDK官方网站为<a href="http://dpdk.org/" target="_blank" rel="external">http://dpdk.org/</a>，官方文档为<a href="http://dpdk.org/doc/guides/index.html" target="_blank" rel="external">http://dpdk.org/doc/guides/index.html</a></p>
<p>DPDK基本组件包括：</p>
<p><img src="https://cloud.githubusercontent.com/assets/676637/14767274/70bb59c0-0a54-11e6-862d-2f19c721c45d.png" alt="dpdk_lib"></p>
<ul>
<li>EAL（Environment Abstraction Layer）即环境抽象层，为应用提供了一个通用接口，隐藏了与底层库与设备打交道的相关细节。EAL实现了DPDK运行的初始化工作，基于大页表的内存分配，多核亲缘性设置，原子和锁操作，并将PCI设备地址映射到用户空间，方便应用程序访问。</li>
<li>Buffer Manager API通过预先从EAL上分配固定大小的多个内存对象，避免了在运行过程中动态进行内存分配和回收来提高效率，常常用作数据包buffer来使用。</li>
<li>Queue Manager API以高效的方式实现了无锁的FIFO环形队列，适合与一个生产者多个消费者、一个消费者多个生产者模型来避免等待，并且支持批量无锁的操作。</li>
<li>Flow Classification API通过Intel SSE基于多元组实现了高效的hash算法，以便快速的将数据包进行分类处理。该API一般用于路由查找过程中的最长前缀匹配中，安全产品中根据Flow五元组来标记不同用户的场景也可以使用。</li>
<li>PMD则实现了Intel 1GbE、10GbE和40GbE网卡下基于轮询收发包的工作模式，大大加速网卡收发包性能。</li>
</ul>
<p>DPDK核心思想：</p>
<ul>
<li>PMD: DPDK针对Intel网卡实现了基于轮询方式的PMD（Poll Mode Drivers）驱动，该驱动由API、用户空间运行的驱动程序构成，该驱动使用无中断方式直接操作网卡的接收和发送队列（除了链路状态通知仍必须采用中断方式以外）。目前PMD驱动支持Intel的大部分1G、10G和40G的网卡。PMD驱动从网卡上接收到数据包后，会直接通过DMA方式传输到预分配的内存中，同时更新无锁环形队列中的数据包指针，不断轮询的应用程序很快就能感知收到数据包，并在预分配的内存地址上直接处理数据包，这个过程非常简洁。如果要是让Linux来处理收包过程，首先网卡通过中断方式通知协议栈对数据包进行处理，协议栈先会对数据包进行合法性进行必要的校验，然后判断数据包目标是否本机的socket，满足条件则会将数据包拷贝一份向上递交给用户socket来处理，不仅处理路径冗长，还需要从内核到应用层的一次拷贝过程。</li>
<li>hugetlbfs: 这样有两个好处：第一是使用hugepage的内存所需的页表项比较少，对于需要大量内存的进程来说节省了很多开销，像oracle之类的大型数据库优化都使用了大页面配置；第二是TLB冲突概率降低，TLB是cpu中单独的一块高速cache，采用hugepage可以大大降低TLB miss的开销。DPDK目前支持了2M和1G两种方式的hugepage。通过修改默认/etc/grub.conf中hugepage配置为“default_hugepagesz=1G hugepagesz=1G hugepages=32 isolcpus=0-22”，然后通过<code>mount –t hugetlbfs nodev /mnt/huge</code>就将hugepage文件系统hugetlbfs挂在/mnt/huge目录下，然后用户进程就可以使用mmap映射hugepage目标文件来使用大页面了。测试表明应用使用大页表比使用4K的页表性能提高10%~15%。</li>
<li>CPU亲缘性: 多核则是每个CPU核一个线程，核心之间访问数据无需上锁。为了最大限度减少线程调度的资源消耗，需要将Linux绑定在特定的核上，释放其余核心来专供应用程序使用。 同时还需要考虑CPU特性和系统是否支持NUMA架构，如果支持的话，不同插槽上CPU的进程要避免访问远端内存，尽量访问本端内存。</li>
<li>减少内存访问: 少用数组和指针，多用局部变量；少用全局变量；一次多访问一些数据；自己管理内存分配；进程间传递指针而非整个数据块</li>
<li>Cache有效性得益于空间局部性（附近的数据也会被用到）和时间局部性（今后一段时间内会被多次访问）原理，通过合理的使用cache，能够使得应用程序性能得到大幅提升</li>
<li>避免False Sharing: 多核CPU中每个核都拥有自己的L1/L2 cache，当运行多线程程序时，尽管算法上不需要共享变量，但实际执行中两个线程访问同一cache line的数据时就会引起冲突，每个线程在读取自己的数据时也会把别人的cacheline读进来，这时一个核修改改变量，CPU的cache一致性算法会迫使另一个核的cache中包含该变量所在的cache line无效，这就产生了false sharing（伪共享）问题. Falsing sharing会导致大量的cache冲突，应该尽量避免。 访问全局变量和动态分配内存是falsesharing问题产生的根源，当然访问在内存中相邻的但完全不同的全局变量也可能会导致false sharing，多使用线程本地变量是解决false sharing的根源办法。</li>
<li>内存对齐：根据不同存储硬件的配置来优化程序，性能也能够得到极大的提升。在硬件层次，确保对象位于不同channel和rank的起始地址，这样能保证对象并并行加载。字节对齐：众所周知，内存最小的存储单元为字节，在32位CPU中，寄存器也是32位的，为了保证访问更加高效，在32位系统中变量存储的起始地址默认是4的倍数（64位系统则是8的倍数），定义一个32位变量时，只需要一次内存访问即可将变量加载到寄存器中，这些工作都是编译器完成的，不需人工干预，当然我们可以使用<strong>attribute</strong>((aligned(n)))来改变对齐的默认值。</li>
<li>cache对齐，这也是程序开发中需要关注的。Cache line是CPU从内存加载数据的最小单位，一般L1 cache的cache line大小为64字节。如果CPU访问的变量不在cache中，就需要先从内存调入到cache，调度的最小单位就是cache line。因此，内存访问如果没有按照cache line边界对齐，就会多读写一次内存和cache了。</li>
<li>NUMA: NUMA系统节点一般是由一组CPU和本地内存组成。NUMA调度器负责将进程在同一节点的CPU间调度，除非负载太高，才迁移到其它节点，但这会导致数据访问延时增大。</li>
<li>减少进程上下文切换: 需要了解哪些场景会触发CS操作。首先就介绍的就是不可控的场景：进程时间片到期；更高优先级进程抢占CPU。其次是可控场景：休眠当前进程(pthread_cond_wait)；唤醒其它进程(pthread_cond_signal)；加锁函数、互斥量、信号量、select、sleep等非常多函数都是可控的。对于可控场景是在应用编程需要考虑的问题，只要程序逻辑设计合理就能较少CS的次数。对于不可控场景，首先想到的是适当减少活跃进程或线程数量，因此保证活跃进程数目不超过CPU个数是一个明智的选择；然后有些场景下，我们并不知道有多少个活跃线程的时候怎么来保证上下文切换次数最少呢？这是我们就需要使用线程池模型：让每个线程工作前都持有带计数器的信号量，在信号量达到最大值之前，每个线程被唤醒时仅进行一次上下文切换，当信号量达到最大值时，其它线程都不会再竞争资源了。</li>
<li>分组预测机制，如果预测的一个分支指令加入流水线，之后却发现它是错误的分支，处理器要回退该错误预测执行的工作，再用正确的指令填充流水线。这样一个错误的预测会严重浪费时钟周期，导致程序性能下降。《计算机体系结构：量化研究方法》指出分支指令产生的性能影响为10%~30%，流水线越长，性能影响越大。Core i7和Xen等较新的处理器当分支预测失效时无需刷新全部流水，当错误指令加载和计算仍会导致一部分开销。分支预测中最核心的是分支目标缓冲区（Branch Target Buffer，简称BTB），每条分支指令执行后，都会BTB都会记录指令的地址及它的跳转信息。BTB一般比较小，并且采用Hash表的方式存入，在CPU取值时，直接将PC指针和BTB中记录对比来查找，如果找到了，就直接使用预测的跳转地址，如果没有记录，必须通过cache或内存取下一条指令。</li>
<li>利用流水线并发: 像Pentium处理器就有U/V两条流水，并且可以独自独立读写缓存，循环2可以将两条指令安排在不同流水线上执行，性能得到极大提升。另外两条流水线是非对称的，简单指令（mpv,add,push,inc,cmp,lea等）可以在两条流水上并行执行、位操作和跳转操作并发的前提是在特定流水线上工作、而某些复杂指令却只能独占CPU。</li>
<li>为了利用空间局部性，同时也为了覆盖数据从内存传输到CPU的延迟，可以在数据被用到之前就将其调入缓存，这一技术称为预取Prefetch，加载整个cache即是一种预取。CPU在进行计算过程中可以并行的对数据进行预取操作，因此预取使得数据/指令加载与CPU执行指令可以并行进行。</li>
</ul>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img src="https://cloud.githubusercontent.com/assets/676637/14767276/7dfb9ed8-0a54-11e6-914f-b041ddcdd40d.png" alt="dpdk"></p>
<p>在最底部的内核态(Linux Kernel)DPDK 有两个模块:KNI 与 IGB_UIO。 其中,KNI 提供给用户一个使用 Linux 内核态的协议栈,以及传统的 Linux 网络工具(如ethtool, ifconfig)。IGB_UIO(igb_uio.ko 和 kni.ko. IGB_UIO)则借助了 UIO 技术,在初始化过程中将网卡硬件寄存器映射到用户态。</p>
<p>DPDK 的上层用户态由很多库组成,主要包括核心部件库(Core Libraries)、平台相关模块(Platform)、网卡轮询模式驱动模块(PMD-Natives&amp; Virtual)、QoS 库、报文转发分类算法(Classify)等几大类,用户应用程序可以使用这些库进行二次开发.</p>
<h2 id="ivshmem"><a href="#ivshmem" class="headerlink" title="ivshmem"></a>ivshmem</h2><p>The DPDK IVSHMEM library facilitates fast zero-copy data sharing among virtual machines (host-to-guest or guest-to-guest) by means of QEUMU’s IVSHMEM mechanism.</p>
<p>The library works by providing a command line for QEMU to map several hugepages into a single IVSHMEM device. For the guest to know what is inside any given IVSHMEM device (and to distinguish between DPDK and non-DPDK IVSHMEM devices), a metadata file is also mapped into the IVSHMEM segment. No work needs to be done by the guest application to map IVSHMEM devices into memory; they are automatically recognized by the DPDK Environment Abstraction Layer (EAL).</p>
<p>See <a href="http://dpdk.org/doc/guides/prog_guide/ivshmem_lib.html" target="_blank" rel="external">http://dpdk.org/doc/guides/prog_guide/ivshmem_lib.html</a></p>
<h2 id="vhost"><a href="#vhost" class="headerlink" title="vhost"></a>vhost</h2><p>The vhost library implements a user space vhost driver. It supports both vhost-cuse (cuse: user space character device) and vhost-user(user space socket server). It also creates, manages and destroys vhost devices for corresponding virtio devices in the guest. Vhost supported vSwitch could register callbacks to this library, which will be called when a vhost device is activated or deactivated by guest virtual machine.</p>
<p>See <a href="http://dpdk.org/doc/guides/prog_guide/vhost_lib.html" target="_blank" rel="external">http://dpdk.org/doc/guides/prog_guide/vhost_lib.html</a></p>
<h2 id="dpdk-model"><a href="#dpdk-model" class="headerlink" title="dpdk model"></a>dpdk model</h2><p>The DPDK implements a run to completion model for packet processing, where all resources must be allocated prior to calling Data Plane applications, running as execution units on logical processing cores. The model does not support a scheduler and all devices are accessed by polling. The primary reason for not using interrupts is the performance overhead imposed by interrupt processing.</p>
<p>In addition to the run-to-completion model, a pipeline model may also be used by passing packets or messages between cores via the rings. This allows work to be performed in stages and may allow more efficient use of code on cores.</p>
<p>更多参考</p>
<ul>
<li><a href="http://dpdk.org" target="_blank" rel="external">http://dpdk.org</a></li>
<li><a href="http://dpdk.org/doc/guides/" target="_blank" rel="external">http://dpdk.org/doc/guides/</a></li>
<li><a href="https://github.com/yanwushuang/mospan-hugo-blog/blob/d81411e1121ee94301e59ba78039c0efdf96b367/content/post/2016/2016-03-14-xns-on-dpdk.md" target="_blank" rel="external">https://github.com/yanwushuang/mospan-hugo-blog/blob/d81411e1121ee94301e59ba78039c0efdf96b367/content/post/2016/2016-03-14-xns-on-dpdk.md</a></li>
<li><a href="http://intel.com/go/dpdk" target="_blank" rel="external">http://intel.com/go/dpdk</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;DPDK-Introduction&quot;&gt;&lt;a href=&quot;#DPDK-Introduction&quot; class=&quot;headerlink&quot; title=&quot;DPDK Introduction&quot;&gt;&lt;/a&gt;DPDK Introduction&lt;/h2&gt;&lt;p&gt;Intel DPDK
    
    </summary>
    
    
      <category term="dpdk" scheme="http://feisky.xyz/tags/dpdk/"/>
    
  </entry>
  
  <entry>
    <title>Tips for cgo</title>
    <link href="http://feisky.xyz/2016/04/24/Tips-for-cgo/"/>
    <id>http://feisky.xyz/2016/04/24/Tips-for-cgo/</id>
    <published>2016-04-24T00:29:02.000Z</published>
    <updated>2016-12-15T00:14:54.373Z</updated>
    
    <content type="html"><![CDATA[<p>cgo的一些tips</p>
<h2 id="基本类型"><a href="#基本类型" class="headerlink" title="基本类型"></a>基本类型</h2><p>The standard C numeric types are available under the names C.char, C.schar (signed char), C.uchar (unsigned char), C.short, C.ushort (unsigned short), C.int, C.uint (unsigned int), C.long, C.ulong (unsigned long), C.longlong (long long), C.ulonglong (unsigned long long), C.float, C.double, C.complexfloat (complex float), and C.complexdouble (complex double). The C type void* is represented by Go’s unsafe.Pointer. The C types <code>__int128_t</code> and <code>__uint128_t</code> are represented by [16]byte.</p>
<p>To access a struct, union, or enum type directly, prefix it with struct<em>, union</em>, or enum_, as in C.struct_stat.</p>
<p>The size of any C type T is available as C.sizeof_T, as in C.sizeof_struct_stat.</p>
<p>As Go doesn’t have support for C’s union type in the general case, C’s union types are represented as a Go byte array with the same length.</p>
<p>Go structs cannot embed fields with C types.</p>
<p>Any C function (even void functions) may be called in a multiple assignment context to retrieve both the return value (if any) and the C errno variable as an error (use _ to skip the result value if the function returns void). For example:</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><div class="line"><span class="keyword">n</span>, <span class="keyword">err</span> := C.<span class="built_in">sqrt</span>(-1)</div><div class="line">_, <span class="keyword">err</span> := C.voidFunc()</div></pre></td></tr></table></figure>
<h2 id="字符串类型转换"><a href="#字符串类型转换" class="headerlink" title="字符串类型转换"></a>字符串类型转换</h2><p><code>C.CString</code>和<code>C.GoString</code>都会对原始数据做拷贝，不要忘记释放CString创建的内存：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="comment">// Go string to C string</span></div><div class="line"><span class="comment">// The C string is allocated in the C heap using malloc.</span></div><div class="line"><span class="comment">// It is the caller's responsibility to arrange for it to be</span></div><div class="line"><span class="comment">// freed, such as by calling C.free (be sure to include stdlib.h</span></div><div class="line"><span class="comment">// if C.free is needed).</span></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">C</span>.<span class="title">CString</span><span class="params">(<span class="keyword">string</span>)</span> *<span class="title">C</span>.<span class="title">char</span></span></div><div class="line"></div><div class="line">// <span class="title">C</span> <span class="title">string</span> <span class="title">to</span> <span class="title">Go</span> <span class="title">string</span></div><div class="line"><span class="title">func</span> <span class="title">C</span>.<span class="title">GoString</span><span class="params">(*C.char)</span> <span class="title">string</span></div><div class="line"></div><div class="line">// <span class="title">C</span> <span class="title">data</span> <span class="title">with</span> <span class="title">explicit</span> <span class="title">length</span> <span class="title">to</span> <span class="title">Go</span> <span class="title">string</span></div><div class="line"><span class="title">func</span> <span class="title">C</span>.<span class="title">GoStringN</span><span class="params">(*C.char, C.<span class="keyword">int</span>)</span> <span class="title">string</span></div><div class="line"></div><div class="line">// <span class="title">C</span> <span class="title">data</span> <span class="title">with</span> <span class="title">explicit</span> <span class="title">length</span> <span class="title">to</span> <span class="title">Go</span> []<span class="title">byte</span></div><div class="line"><span class="title">func</span> <span class="title">C</span>.<span class="title">GoBytes</span><span class="params">(unsafe.Pointer, C.<span class="keyword">int</span>)</span> []<span class="title">byte</span></div></pre></td></tr></table></figure>
<p><code>C.CString</code>使用示例：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line">ch := C.CString(str)</div><div class="line"><span class="keyword">defer</span> C.free(unsafe.Pointer(ch))</div><div class="line">....</div></pre></td></tr></table></figure>
<h2 id="数组的使用"><a href="#数组的使用" class="headerlink" title="数组的使用"></a>数组的使用</h2><p>Go切片转为C数组：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="comment">/*</span></div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">void foo(double *arr, int len) &#123;</div><div class="line">	for(int i=0;i&lt;len;i++) &#123;</div><div class="line">		printf("%f\n", arr[i]);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line">*/</div><div class="line"><span class="keyword">import</span> <span class="string">"C"</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">	arr := []<span class="keyword">float64</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</div><div class="line">	carr := (*C.double)(unsafe.Pointer(&amp;arr[<span class="number">0</span>]))</div><div class="line">	C.foo(carr, C.<span class="keyword">int</span>(<span class="built_in">len</span>(arr)))</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>C数组转为Go切片</p>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line"><span class="keyword">import</span> <span class="string">"unsafe"</span></div><div class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></div><div class="line"></div><div class="line"><span class="comment">/*</span></div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">double* get_array(int n) &#123;</div><div class="line">	double *arr;</div><div class="line">	arr = (double*)malloc(n*sizeof(arr));</div><div class="line">	for(int i=0;i&lt;n;i++)</div><div class="line">	&#123;</div><div class="line">		arr[i]=i;</div><div class="line">	&#125;</div><div class="line">	return arr;</div><div class="line">&#125;</div><div class="line">*/</div><div class="line"><span class="keyword">import</span> <span class="string">"C"</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</div><div class="line">	size := <span class="number">10</span></div><div class="line">	carr := C.get_array(C.<span class="keyword">int</span>(size))</div><div class="line">	<span class="keyword">defer</span> C.free(unsafe.Pointer(carr))</div><div class="line">	arr := (*[<span class="number">1</span> &lt;&lt; <span class="number">30</span>]<span class="keyword">float64</span>)(unsafe.Pointer(carr))[:size:size]</div><div class="line">	fmt.Println(arr)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>C指针操作</p>
<figure class="highlight go"><table><tr><td class="code"><pre><div class="line">size := <span class="number">10</span></div><div class="line">carr := C.get_array(C.<span class="keyword">int</span>(size))</div><div class="line"><span class="keyword">defer</span> C.free(unsafe.Pointer(carr))</div><div class="line"></div><div class="line"><span class="comment">// To go slice</span></div><div class="line">arr := (*[<span class="number">1</span> &lt;&lt; <span class="number">30</span>]<span class="keyword">float64</span>)(unsafe.Pointer(carr))[:size:size]</div><div class="line"><span class="keyword">for</span> index := <span class="number">0</span>; index &lt; size; index++ &#123;</div><div class="line">    <span class="comment">// get value by C pointer operation</span></div><div class="line">    value := *(*C.double)(unsafe.Pointer(<span class="keyword">uintptr</span>(unsafe.Pointer(carr)) + <span class="keyword">uintptr</span>(index)*unsafe.Sizeof(carr)))</div><div class="line">    <span class="comment">// get value by Go slice index</span></div><div class="line">    gvalue := arr[index]</div><div class="line">    fmt.Println(value, <span class="string">" == "</span>, gvalue)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>更多文档见<a href="https://golang.org/cmd/cgo/" target="_blank" rel="external">https://golang.org/cmd/cgo/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;cgo的一些tips&lt;/p&gt;
&lt;h2 id=&quot;基本类型&quot;&gt;&lt;a href=&quot;#基本类型&quot; class=&quot;headerlink&quot; title=&quot;基本类型&quot;&gt;&lt;/a&gt;基本类型&lt;/h2&gt;&lt;p&gt;The standard C numeric types are available u
    
    </summary>
    
    
      <category term="go" scheme="http://feisky.xyz/tags/go/"/>
    
  </entry>
  
</feed>
